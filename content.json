{"posts":[{"title":"简历","text":"男 1998 汉族 教育经历 上海交通大学 控制科学与工程 硕士 2020 年 09 月 - 2023 年 03 月 研究方向：机器视觉，视觉测量，激光 SLAM，2D-3D 数据融合 复旦大学 电子信息科学与技术 本科 2016 年 09 月 - 2020 年 06 月 研究方向：无人机路径规划与飞行控制，嵌入式 研究经历 上海交大 - 龙马环卫城市低速无人驾驶环卫车联合开发 2022 年 03 月 - 2022 年 08 月 负责基于 autoware 的无人驾驶定位模块与感知模块算法开发 激光雷达数据采集与扫描匹配，构建 3D 点云地图，绘制矢量地图 实现激光雷达实车定位，融合 GNSS 卫星定位进行定位初始化 完成图像和点云数据融合，生成 RGB 点云 基于 darknet 框架进行 YOLOv3 模型训练与部署，对图像进行目标检测，并与点云聚类结果进行融合过滤 自动化产线物料分拣 2021 年 07 月 - 2022 年 01 月 目标检测与位姿估计 基于自研三维扫描仪对自动化流水线上目标进行扫描，对图像进行分类与分割，重建出 ROI 区域三维点云 将目标点云与 CAD 数模进行配准得到目标物料的 6D 位姿 物料分拣 基于 WinSock2 实现上位机与机械臂控制器的数据通信与指令收发 基于机械臂坐标系与扫描仪坐标系下三维点集的刚体变换，完成手眼标定 将扫描仪获得的目标物料的类别与位姿发送给机械臂控制器，结合下位机程序完成目标自动分拣 结构光三维扫描仪研发 2020 年 10 月 - 2021 年 06 月 搭建三维扫描仪硬件系统 使用单个工业相机，分别搭配普通家用软触发投影仪和硬触发光机投影仪，搭建两套三维扫描仪硬件系统，完成安装调试 结构光三维重建算法开发 借助 YOLOv3 进行非对称圆点标定板检测，进行单目相机标定 实现相移码编解码算法，控制投影仪向目标区域投射相移码结构光，触发相机拍照并进行解码 完成相机和投影仪的立体标定，实现对目标区域的三维重建 基于 Qt 搭建三维扫描仪 GUI 界面，实现相机与投影仪的联调联控，对扫描得到的点云进行可视化 复旦大学曦源项目无人机路径规划 2018 年 06 月 - 2019 年 06 月 基于 Pixhawk 开源飞控搭建无人机系统，机载树莓派作为控制中心，在已知场景中用 RRT 算法进行路径规划，并使用双向 RRT 来加快搜索速度，控制无人机沿规划路径飞往指定地点 实习经历 RoboWay - 嵌入式开发 2019 年 04 月 - 2019 年 07 月 无人配送机器人电池健康监测模块开发 基于 STM32 工控板使用 RS485 总线协议获取电池模块的电压、充放电电流、温度等信息，进行 HMI 串口屏界面设计并显示电池健康状态信息 论文成果 Siyou Luo &amp; Jun-Guo Lu (2021). Robust stability and stabilization of fractional-order systems with polytopic uncertainties via homogeneous polynomial parameter-dependent matrix forms. International Journal of General Systems, 50:8, 891-914, DOI: 10.1080/03081079.2021.1976774 Siyou Luo, Jun-Guo Lu &amp; Xu-Yi Qiu (2022). Robust normalization and stabilization of descriptor fractional-order systems with uncertainties in all matrices. Journal of the Franklin Institute, 359, 1113-1129, DOI: 10.1016/j.jfranklin.2021.12.016 Siyou Luo &amp; Jun-Guo Lu (2022). Robust normalization and stabilization of descriptor fractional-order systems with polytopic uncertainties in all matrices. Asian Journal of Control. (Under Review) Ming Wei, Jun-guo Lu ,Siyou Luo, et al. Straight line detection algorithm of truck point cloud based on statistical line chart[C]. 2022 Chinese Control And Decision Conference (CCDC). 荣誉奖项 复旦大学优秀学生，信息学院十佳学生、优秀团员 2018-2019 复旦大学毕业生奖学金、优秀毕业生 2019-2020 本科连续三次获国家励志奖学金、校级优秀学生奖学金三等奖 2016-2020 信息学院运动会男子立定跳远金牌 2017.10 TI 杯全国大学生电子设计竞赛上海赛区二等奖 2019.11 第七届“互联网 +”大学生创新创业大赛上海赛区铜奖 2021.10 技能 专业技能 掌握计算机视觉的基本原理、相机成像模型，熟悉双目立体视觉重建的原理与实现 熟练掌握 C/C++，熟悉 Python 语言，能够熟练运用 QT 进行界面设计。熟悉 OpenCV3(计算机视觉库)、PCL（点云库）、Eigen (C++ 线性代数库)、openMVG (多视图几何库) 、WinSock2 （socket 网络接口）等 能够基于 CMake 进行大型软件工程构建，基于 Git Flow 进行团队项目协作 熟练掌握 ROS 系统上功能包的开发与调试，熟悉自动驾驶 Autoware 框架，能对各模块进行调试与二次开发，熟悉激光 SLAM 算法框架 cartographer 掌握嵌入式软硬件开发，熟悉 STM32 单片机，各种总线协议，以及基本外设的使用，能够使用 Altium Designer 软件进行 PCB 设计 语言技能 英语（CET-6） 547 其他证书 机动车驾驶证","link":"/about/"},{"title":"编译 VTK","text":"可视化工具包 (VTK) 是一种用于操作和显示科学数据的开源软件。它配备了最先进的 3D 渲染工具，一套用于 3D 交互的小部件，以及广泛的 2D 绘图功能。VTK 是 Kitware 软件开发 支持 平台集合的一部分。该平台在全球范围内用于商业应用和研发。例如，请参阅 VTK in Action。– https://www.vtk.org/about VTK 官网 VTK 官方文档 VTK 官方 WiKi VTK 下载 VTK 配置与编译 这里以 VTK 9.1.0 为例 Prerequisites参考 VTK Documentation &gt;&gt; build.md#prerequisites CMake &gt;= 3.12 (越新越好) Qt &gt;= 5.9 下载 下载完整仓库(不推荐)12345&gt; git clone --recursive https://gitlab.kitware.com/vtk/vtk.git&gt; cd .\\vtk\\&gt; git checkout v9.1.0 &gt; cd ThirdParty\\vtkm\\vtkvtkm\\vtk-m&gt; git checkout 4df064f37 精简下载1&gt; git clone --recursive --branch v9.1.0 --depth=1 https://gitlab.kitware.com/vtk/vtk.git 配置与编译 VTK 编译 Qt+PCL+VS 实现点云 Gui 界面显示 (private) 运行 CMake-GUI 并将源码目录设置为 clone 下来的 vtk 仓库目录, 并自行指定 build 目录. 使用 Add Entry 按钮添加缓存变量 CMAKE_DEBUG_POSTFIX，类型为 STRING，值设置为 -gd。这是为了将最后编译的 debug 文件与 release 文件区分开来。 点击 Configure, 选择安装的 Visual Studio 的版本，选择 x64 平台，选择平台工具集 v141(对应 VS2017 默认的平台工具集)，点击 Finish 开始配置。 修改 CMAKE_INSTALL_PREFIX 变量，指定安装目录。 可以选择需要构建的内容，这里 只勾选 BUILD_SHARED_LIBS，不对文档、示例和测试进行生成，这样可以节省生成和构建的时间。 BUILD_DOCUMENTATION, BUILD_EXAMPLES, BUILD_SHARED_LIBS, BUILD_TESTING。 使用 CMake-GUI 中的搜索框，输入 Qt，将自动过滤出与 Qt 相关的配置项：将 VTK_GROUP_ENABLE_Qt, VTK_MODULE_ENABLE_VTK_GUISupportQtSQL VTK_MODULE_ENABLE_VTK_GUISupportQt VTK_MODULE_ENABLE_VTK_GUISupportQtQuick VTK_MODULE_ENABLE_VTK_RenderingQt VTK_MODULE_ENABLE_VTK_ViewsQt设置为 WANT; VTK_QT_VERSION 设置为 5。注意，不同版本 VTK 在这里显示出来的选项可能不同，如果看到了 VTK_Group_Qt, 将其勾选即可。 再次点击 Configure, 然后通过搜索框过滤 Qt, 检查相关项的 _DIR 是否检测成功, 否则需手动指定。完成后点击 Configure, 然后点击 Generate 生成 VS 解决方案。点击 Open Project, 将自动通过 VS 打开。 点击 CMake-GUI &gt;&gt; Tools &gt;&gt; Show My Changes 可以看到自己所做的修改如下 My Changes12345678910111213Commandline options:-DVTK_GROUP_ENABLE_Qt:STRING=&quot;WANT&quot; -DVTK_MODULE_ENABLE_VTK_GUISupportQtSQL:STRING=&quot;WANT&quot; -DVTK_MODULE_ENABLE_VTK_GUISupportQt:STRING=&quot;WANT&quot; -DVTK_MODULE_ENABLE_VTK_GUISupportQtQuick:STRING=&quot;WANT&quot; -DVTK_MODULE_ENABLE_VTK_RenderingQt:STRING=&quot;WANT&quot; -DVTK_MODULE_ENABLE_VTK_ViewsQt:STRING=&quot;WANT&quot; -DVTK_QT_VERSION:STRING=&quot;5&quot; Cache file:VTK_GROUP_ENABLE_Qt:STRING=WANTVTK_MODULE_ENABLE_VTK_GUISupportQtSQL:STRING=WANTVTK_MODULE_ENABLE_VTK_GUISupportQt:STRING=WANTVTK_MODULE_ENABLE_VTK_GUISupportQtQuick:STRING=WANTVTK_MODULE_ENABLE_VTK_RenderingQt:STRING=WANTVTK_MODULE_ENABLE_VTK_ViewsQt:STRING=WANTVTK_QT_VERSION:STRING=5 在 VS 中点击 生成 &gt;&gt; 批生成: 勾选如下选项后点击 生成 , 等待 VS 自动完成生成与安装。 ALL_BUILD,Debug,x64 ALL_BUILD,Release,x64 INSTALL,Debug,x64 INSTALL,Release,x64 在安装目录可以看到如下库文件结构 show-tree -depth 212345678910D:\\ProgramFiles\\VTK\\VTK9.1.0├──bin├──include│ └──vtk-9.1├──lib│ ├──cmake│ ├──qml│ └──vtk└──share └──licenses 作为第三方库使用 在 CMakeLists.txt 中加入如下内容, 并且在 Configure 时可能需要指定安装目录-DVTK_DIR:PATH=&quot;D:/ProgramFiles/VTK/VTK9.1.0/lib/cmake/vtk-9.1&quot; CMakeLists.txt12345678910111213141516...find_package(VTK REQUIRED) add_executable(${PROJECT_NAME} ...) target_link_libraries(${PROJECT_NAME} ${VTK_LIBRARIES} ) vtk_module_autoinit( TARGETS ${PROJECT_NAME} MODULES ${VTK_LIBRARIES}) 程序运行时需确保 vtk 相关 dll 能够被找到。 参考 VTK9.1.0 在 Windows10+VS2019+Qt 5.15.2 环境下编译安装以及 VTK 应用于 QT VTK9.1.0 + VS2022 + Qt5.12 编译 Qt6.0.1 + vtk9.1.0 + Cmake 编译运行","link":"/blogs/build_vtk/"},{"title":"Ceres 优化库","text":"官方文档: http://ceres-solver.org/ 官方仓库: https://github.com/ceres-solver/ceres-solver Ceres Solver 是一个用于求解大型复杂优化问题的 C++ 开源库, 主要用于如下两类优化问题的求解: 带边界约束的非线性最小二乘问题 通用的无约束优化问题 德国数学家高斯 (Carl Fredrich Gauss, 1777 – 1855) 基于 22 次观测数据, 使用最小二乘法正确地预测了谷神星 (Ceres) 的轨迹, 因此谷歌用 Ceres 来命名该优化库. https://www.actuaries.digital/2021/03/31/gauss-least-squares-and-the-missing-planet/ https://doi.org/10.1214/aos/1176345451 环境 Windows Visual Studio 2022 + Toolset v141 Ceres 2.1.0 安装 http://ceres-solver.org/installation.html#windows 创建项目顶层目录 ceres/; 准备依赖库: Eigen 3.3 下载 eigen-3.3.7.zip 放到 ceres/ 文件夹下解压, 得到 ceres/eigen-3.3.7/ 文件夹; 配置 Eigen, 如下配置过程将在 ceres/eigen-3.3.7/build/ 文件夹下得到一个 Eigen3Config.cmake 文件. 我们仅需得到该文件即可, 无需编译.configure1234&gt; cd ceres/eigen-3.3.7/&gt; mkdir build&gt; cd build&gt; cmake .. -T v141 Eigen 是一个完全用头文件编写的模板库, 如果要调用 Eigen, 只需要直接添加头文件依赖即可, 无需链接任何二进制库. 某些场景下编译 Eigen 仅仅是为了生成文档、单元测试和自动化安装. 准备依赖库: gflags gflags 是 glog 的依赖库, 因此要先安装 官方代码库: https://github.com/gflags/gflags 官方文档: https://gflags.github.io/gflags/ 下载 gflags-2.2.2.zip 放到 ceres/ 文件夹下解压, 得到 ceres/gflags-2.2.2/ 文件夹; 修改 ceres/gflags-2.2.2/src/defines.h.in, 将第 33 行注释掉12// Define if you have the &lt;shlwapi.h&gt; header file (Windows 2000/XP).// #cmakedefine HAVE_SHLWAPI_H 打开 CMake-gui, 将 source 和 build 目录分别设置为 ceres/gflags-2.2.2 和 ceres/gflags-2.2.2/build_dir/, 点击 Configure 后将平台选为 x64, toolset 处填 v141(表示使用 VS2017 默认的平台工具集进行编译), 完成后再做如下修改, 设置安装路径 ceres/gflags-2.2.2/install, 并按如下设置复选框: BUILD_STATIC_LIBS BUILD_TESTING BUILD_SHARED_LIBS BUILD_PACKAGINGcmake-gui/Tools/Show My Changes12345678910Commandline options:-DBUILD_STATIC_LIBS:BOOL=&quot;1&quot; -DCMAKE_INSTALL_PREFIX:PATH=&quot;D:/Data/ceres/gflags-2.2.2/install&quot; -DBUILD_TESTING:BOOL=&quot;1&quot; -DBUILD_PACKAGING:BOOL=&quot;0&quot; -DBUILD_SHARED_LIBS:BOOL=&quot;1&quot; Cache file:BUILD_STATIC_LIBS:BOOL=1CMAKE_INSTALL_PREFIX:PATH=D:/Data/ceres/gflags-2.2.2/installBUILD_TESTING:BOOL=1BUILD_PACKAGING:BOOL=0BUILD_SHARED_LIBS:BOOL=1 cmake-gui 中点击 Genetate 后点击 Open Project, 将通过 Visual Studio 打开 解决方案, 配置为 Release|x64, 点击 生成 -&gt; 生成解决方案 , 成功后右键 INSTALL 项目, 点击 生成 . 然后分别在 ceres/gflags-2.2.2/build_dir/ 文件夹 和 ceres/gflags-2.2.2/install/文件夹下可以看到编译结果和安装结果. 准备依赖库: glog 0.6.0 官方代码库: https://github.com/google/glog 下载 glog-0.6.0.zip 放到 ceres/ 文件夹下解压, 得到 ceres/glog-0.6.0/ 文件夹; 打开 CMake-gui, 将 source 和 build 目录分别设置为 ceres/glog-0.6.0/ 和 ceres/glog-0.6.0/build/, 点击 Configure 后将平台选为 x64, toolset 处填 v141(表示使用 VS2017 默认的平台工具集进行编译), 完成后再做如下修改, 设置安装路径 ceres/glog-0.6.0/install, 并设置依赖库路径 gflags_DIR 和安装目录 CMAKE_INSTALL_PREFIX 如下.cmake-gui/Tools/Show My Changes12345678Commandline options:-Dgflags_DIR:PATH=&quot;D:/Data/ceres/gflags-2.2.2/install/lib/cmake/gflags&quot; -DCMAKE_INSTALL_PREFIX:PATH=&quot;D:/Data/ceres/glog-0.6.0/install&quot; Cache file:gflags_DIR:PATH=D:/Data/ceres/gflags-2.2.2/install/lib/cmake/gflagsCMAKE_INSTALL_PREFIX:PATH=D:/Data/ceres/glog-0.6.0/install 点击 Open Project 通过 Visual Studio 打开 解决方案, 配置为 Release|x64, 生成解决方案, 成功后再生成 INSTALL 项目. (可选)准备依赖库 SuiteSparse 下载 suitesparse-metis-for-windows-1.7.0.zip 放到 ceres/ 文件夹下解压, 得到 ceres/suitesparse-metis-for-windows-1.7.0/ 文件夹; 打开 CMake-gui, 将 source 和 build 目录分别设置为 ceres/suitesparse-metis-for-windows-1.7.0/ 和 ceres/suitesparse-metis-for-windows-1.7.0/build/, 点击 Configure 后将平台选为 x64, toolset 处填 v141(表示使用 VS2017 默认的平台工具集进行编译), 默认情况下安装路径 CMAKE_INSTALL_PREFIX 为ceres/suitesparse-metis-for-windows-1.7.0/build/install, 不必修改. 点击 Open Project 通过 Visual Studio 打开 解决方案, 配置为 Release|x64, 生成解决方案, 成功后再生成 INSTALL 项目. 开始编译 ceres-solver 下载 ceres-solver-2.1.0.tar.gz 放到 ceres/ 文件夹下解压, 得到 ceres/ceres-solver-2.1.0/ 文件夹; 打开 CMake-gui, 将 source 和 build 目录分别设置为 ceres/ceres-solver-2.1.0/ 和 ceres/ceres-solver-2.1.0/ceres-bin/, 点击 Configure, 确保 cmake 可以找到上面的依赖库, 否则需要手动指定, 具体配置如下.cmake-gui/Tools/Show My Changes1234567891011Commandline options:-DEigen3_DIR:PATH=&quot;D:/Data/ceres/eigen-3.3.7/build&quot; -DSuiteSparse_DIR:PATH=&quot;D:/Data/ceres/suitesparse-metis-for-windows-1.7.0/build/install/lib/cmake/suitesparse-5.4.0&quot; -Dgflags_DIR:PATH=&quot;D:/Data/ceres/gflags-2.2.2/install/lib/cmake/gflags&quot; -DCMAKE_INSTALL_PREFIX:PATH=&quot;D:/Data/ceres/ceres-solver-2.1.0/install&quot; -Dglog_DIR:PATH=&quot;D:/Data/ceres/glog-0.6.0/install/lib/cmake/glog&quot; -DBUILD_SHARED_LIBS:BOOL=&quot;1&quot; Cache file:Eigen3_DIR:PATH=D:/Data/ceres/eigen-3.3.7/buildSuiteSparse_DIR:PATH=D:/Data/ceres/suitesparse-metis-for-windows-1.7.0/build/install/lib/cmake/suitesparse-5.4.0gflags_DIR:PATH=D:/Data/ceres/gflags-2.2.2/install/lib/cmake/gflagsCMAKE_INSTALL_PREFIX:PATH=D:/Data/ceres/ceres-solver-2.1.0/installglog_DIR:PATH=D:/Data/ceres/glog-0.6.0/install/lib/cmake/glogBUILD_SHARED_LIBS:BOOL=1 点击 Open Project 通过 Visual Studio 打开 解决方案, 配置为 Release|x64, 生成解决方案, 成功后再生成 RUN_TESTS 项目进行测试.1234567891011121&gt;------ 已启动生成: 项目: RUN_TESTS, 配置: Release x64 ------1&gt;Test project D:/Data/ceres/ceres-solver-2.1.0/ceres-bin1&gt; Start 1: cuda_memcheck_dense_qr_test1&gt; 1/183 Test #1: cuda_memcheck_dense_qr_test ................................... Passed 4.35 sec...1&gt; Start 183: ba_iterschur_acceleratesparse_clusttri_user_threads_test1&gt;183/183 Test #183: ba_iterschur_acceleratesparse_clusttri_user_threads_test ...... Passed 0.02 sec1&gt;1&gt;100% tests passed, 0 tests failed out of 1831&gt;1&gt;Total Test time (real) = 175.21 sec========== “生成”: 1 成功，0 失败，1 更新，0 已跳过 ========== 测试全部通过后生成 INSTALL 项目 将某些示例项目 (例如 helloworld ) 设为启动项, 然后直接运行, 终端输出如下.1234567iter cost cost_change |gradient| |step| tr_ratio tr_radius ls_iter iter_time total_time 0 4.512500e+01 0.00e+00 9.50e+00 0.00e+00 0.00e+00 1.00e+04 0 3.35e-04 2.82e-03 1 4.511598e-07 4.51e+01 9.50e-04 9.50e+00 1.00e+00 3.00e+04 1 1.52e-04 3.10e-03 2 5.012552e-16 4.51e-07 3.17e-08 9.50e-04 1.00e+00 9.00e+04 1 5.20e-06 3.16e-03Ceres Solver Report: Iterations: 3, Initial cost: 4.512500e+01, Final cost: 5.012552e-16, Termination: CONVERGENCEx : 0.5 -&gt; 10 教程 Ceres Solver/Tutorial: http://ceres-solver.org/tutorial.html 例程代码: https://github.com/ceres-solver/ceres-solver/tree/master/examples Ceres 主要用于求解 带边界约束的非线性最小二乘 和 通用的无约束优化 两类问题, 下面对官方教程中的部分示例进行简单介绍. 带边界约束的非线性最小二乘 对于一类带边界约束的非线性最小二乘问题可建模为如下的数学形式 其中 表达式 $\\rho_i(\\cdot)$ 是损失函数(LossFunction), 是一个标量函数, 构成残差块(ResidualBlock), 在优化过程中用于减小离群值的影响; 函数 $f_i(\\cdot)$ 是代价函数(CostFunction); $[x_{i_1},\\cdots,x_{i_k}]$ 是参数块(ParameterBlock), 在大多数优化问题中, 参数变量都是多个一组出现的, 例如平移向量中三个一组, 四元数四个一组; $l_j$ 和 $u_j$ 分别是参数块 $x_j$ 的下界和上界. 这类问题常见于统计学中的曲线拟合、计算机视觉中的摄影测量与建模等场景. 特别的, 当 $\\rho_i(x)=x$ 为恒等函数, 且 $l_j=-\\infty$, $u_j=+\\infty$ 时, 该问题退化为更常见的非线性最小二乘问题, 如下. Hello World! 官方教程: Tutorial&gt;&gt;Non-linear Least Squares&gt;&gt;hello-world examples/helloworld.cc 通过一个简单的优化问题来介绍 Ceres 的使用, 求如下表达式的最小值:$$\\frac{1}{2}(10-x)^2$$ 首先可以写出代价函数 $f(x) = 10-x$, 在 Ceres 中通过一个重载了 函数调用运算符 的模板类来定义它. 函数调用运算符 参考 C++ Primer 第 5 版 14.8 节 定义类, 并重载函数调用运算符, 以描述代价函数1234567struct CostFunctor { template &lt;typename T&gt; bool operator()(const T* const x, T* residual) const { residual[0] = 10.0 - x[0]; return true; }}; 其中 operator() 是一个模板方法, 以指针的形式传入参数数组 x 和代价函数数组 residual, 这里都是只有一个元素. 在定义了代价函数以后就可以通过 Ceres 构造最小二乘问题并求解了.helloworld.cc >foldedlink123456789101112131415161718192021222324252627int main(int argc, char** argv) { google::InitGoogleLogging(argv[0]); // The variable to solve for with its initial value. It will be // mutated in place by the solver. double x = 0.5; const double initial_x = x; // Build the problem. Problem problem; // Set up the only cost function (also known as residual). This uses // auto-differentiation to obtain the derivative (jacobian). CostFunction* cost_function = new AutoDiffCostFunction&lt;CostFunctor, 1, 1&gt;(new CostFunctor); problem.AddResidualBlock(cost_function, nullptr, &amp;x); // Run the solver! Solver::Options options; options.minimizer_progress_to_stdout = true; Solver::Summary summary; Solve(options, &amp;problem, &amp;summary); std::cout &lt;&lt; summary.BriefReport() &lt;&lt; &quot;\\n&quot;; std::cout &lt;&lt; &quot;x : &quot; &lt;&lt; initial_x &lt;&lt; &quot; -&gt; &quot; &lt;&lt; x &lt;&lt; &quot;\\n&quot;; return 0;} 通过前面定义的 CostFunctor 类构造了一个能够自动求导的代价函数cost_function, 构造的模板参数包括: 代价函数类, 残差块的个数, 每个参数块中参数的个数(通过可变参数指定) AutoDiffCostFunction 的模板参数12345template &lt;typename CostFunctor, int kNumResiduals, // Number of residuals, or ceres::DYNAMIC. int... Ns&gt; // Number of parameters in each parameter block.class AutoDiffCostFunction ... 定义了 ceres::Problem problem, 然后在 problem 中添加一个残差块, 需要的参数包括该残差块的: 代价函数, 损失函数 以及 参数块中的参数 添加残差块的几种方式(需要提供的参数)1234567891011121314151617template &lt;typename... Ts&gt;ResidualBlockId AddResidualBlock(CostFunction* cost_function, LossFunction* loss_function, double* x0, Ts*... xs)// Add a residual block by providing a vector of parameter blocks.ResidualBlockId AddResidualBlock( CostFunction* cost_function, LossFunction* loss_function, const std::vector&lt;double*&gt;&amp; parameter_blocks);// Add a residual block by providing a pointer to the parameter block array// and the number of parameter blocks.ResidualBlockId AddResidualBlock(CostFunction* cost_function, LossFunction* loss_function, double* const* const parameter_blocks, int num_parameter_blocks); 配置求解器的选项: 将优化过程打印出来 12Solver::Options options;options.minimizer_progress_to_stdout = true; 开始求解, 求解过程的报告位于 summary 中, 具体各参数的最优解直接在参数块本地设置. 12Solver::Summary summary;Solve(options, &amp;problem, &amp;summary); 终端输出如下, 表示已经收敛, 且参数从初始值 0.5 被优化到 10, 最终的代价函数为 5.012552e-16. 1234567iter cost cost_change |gradient| |step| tr_ratio tr_radius ls_iter iter_time total_time 0 4.512500e+01 0.00e+00 9.50e+00 0.00e+00 0.00e+00 1.00e+04 0 3.35e-04 2.82e-03 1 4.511598e-07 4.51e+01 9.50e-04 9.50e+00 1.00e+00 3.00e+04 1 1.52e-04 3.10e-03 2 5.012552e-16 4.51e-07 3.17e-08 9.50e-04 1.00e+00 9.00e+04 1 5.20e-06 3.16e-03Ceres Solver Report: Iterations: 3, Initial cost: 4.512500e+01, Final cost: 5.012552e-16, Termination: CONVERGENCEx : 0.5 -&gt; 10 求导 官方教程: Tutorial&gt;&gt;Non-linear Least Squares&gt;&gt;Derivatives 官方教程: Tutorial&gt;&gt;On Derivatives 和大多数优化库一样, Ceres 的优化求解过程依赖于计算代价函数值和求代价函数对参数块的导数.在 上面的示例 中, 通过构造 AutoDiffCostFunction 来自动求导. Ceres 还提供了另外两种求导方式: 数值求导(Numeric Derivatives): 如果代价函数中调用了其他库函数, 这时既无法自动求导, 也无法给出解析解, 就只能通过数值计算, 用差分来近似导数. 但使用该方法容易产生数值错误, 且计算量更大, 收敛更慢. http://ceres-solver.org/nnls_tutorial.html#numeric-derivatives http://ceres-solver.org/numerical_derivatives.html 解析求导(Analytic Derivatives): 自动求导是通过链式法则计算的, 但有时我们手动求导可以得到闭式解, 且更加简洁, 那么就可以在定义代价函数的时候手动写出导数的代码. http://ceres-solver.org/nnls_tutorial.html#analytic-derivatives http://ceres-solver.org/analytical_derivatives.html 光束平差 官方教程: Tutorial&gt;&gt;Non-linear Least Squares&gt;&gt;Bundle Adjustment 谷歌开发 Ceres 优化库的主要目的就是他们需要求解大规模的光束平差问题. 其他 http://ceres-solver.org/nnls_tutorial.html#other-examples slam/pose_graph_2d/pose_graph_2d.cc https://github.com/OpenSLAM-org/openslam_vertigo https://openslam-org.github.io/vertigo 下载数据集openslam_vertigo-master.zip 放到 ceres/ 文件夹下解压, 得到 ceres/openslam_vertigo-master/ 文件夹, 其中的 datasets 文件夹下有多个位姿图数据集, 如下: 123456789101112131415161718ceres/openslam_vertigo-master/datasets├─city10000│ └─originalDataset├─intel│ └─originalDataset├─manhattan│ ├─groundTruth│ └─originalDataset│ ├─g2o│ └─Olson├─ring│ ├─groundTruth│ └─originalDataset├─ringCity│ ├─groundTruth│ └─originalDataset└─sphere2500 └─originalDataset ceres 官方文档中的 pose_graph_2d 使用的是其中的 manhattan\\originalDataset\\g2o\\manhattanOlson3500.g2o; 在 Visual Studio 中右键 pose_graph_2d 项目, 点击 属性 , 然后在 配置属性 / 调试 / 命令参数 中填入-input=&quot;D:\\Data\\ceres\\openslam_vertigo-master\\datasets\\manhattan\\originalDataset\\g2o\\manhattanOlson3500.g2o&quot;, 并将该项目设置为启动项, 执行该项目. 或者在终端中切换到可执行文件所在路径, 并执行如下命令12cd D:\\Data\\ceres\\ceres-solver-2.1.0\\ceres-bin\\bin\\Release.\\pose_graph_2d.exe -input=&quot;D:\\Data\\ceres\\openslam_vertigo-master\\datasets\\manhattan\\originalDataset\\g2o\\manhattanOlson3500.g2o&quot; 终端输出 >folded12345678910111213141516171819202122232425262728293031323334353637383940414243Number of poses: 3500Number of constraints: 5598Solver Summary (v 2.1.0-eigen-(3.3.7)-no_lapack-eigensparse-no_openmp-cuda-(11070)) Original ReducedParameter blocks 10500 10497Parameters 10500 10497Residual blocks 5598 5598Residuals 16794 16794Minimizer TRUST_REGIONSparse linear algebra library EIGEN_SPARSETrust region strategy LEVENBERG_MARQUARDT Given UsedLinear solver SPARSE_NORMAL_CHOLESKY SPARSE_NORMAL_CHOLESKYThreads 1 1Linear solver ordering AUTOMATIC 10497Cost:Initial 3.457147e+04Final 7.303833e+01Change 3.449843e+04Minimizer iterations 17Successful steps 17Unsuccessful steps 0Time (in seconds):Preprocessor 0.016229 Residual only evaluation 0.016077 (17) Jacobian &amp; residual evaluation 0.048274 (17) Linear solver 0.107716 (17)Minimizer 0.196507Postprocessor 0.000366Total 0.213103Termination: CONVERGENCE (Function tolerance reached. |cost_change|/cost: 2.743214e-07 &lt;= 1.000000e-06) 除了终端输出之外, 该脚本还会在当前目录下生成两个文件 poses_original.txt和poses_optimized.txt, 分别是优化之前的位姿和优化之后的位姿 在 ceres/ceres-solver-2.1.0/examples/slam/pose_graph_2d/ 文件夹下有一个plot_results.py 可以对生成的 poses_original.txt 和poses_optimized.txt 进行可视化. 将这两个文件拷贝到 plot_results.py 所在路径下. 安装 numpy 和 matplotlib: pip install numpy matplotlib 在终端中执行 plot_results.py 即可打印出优化前后的 2d 地图. 1python .\\plot_results.py --optimized_poses ./poses_optimized.txt --initial_poses ./poses_original.txt slam/pose_graph_3d/pose_graph_3d.cc与 pose_graph_2d 类似, 只是需要使用的数据集为 ceres/openslam_vertigo-master/datasets/sphere2500/originalDataset/sphere2500.g2o终端输出 >folded12345678910111213141516171819202122232425262728293031323334353637383940414243Number of poses: 2500Number of constraints: 4949Solver Summary (v 2.1.0-eigen-(3.3.7)-no_lapack-eigensparse-no_openmp-cuda-(11070)) Original ReducedParameter blocks 5000 4998Parameters 17500 17493Effective parameters 15000 14994Residual blocks 4949 4949Residuals 29694 29694Minimizer TRUST_REGIONSparse linear algebra library EIGEN_SPARSETrust region strategy LEVENBERG_MARQUARDT Given UsedLinear solver SPARSE_NORMAL_CHOLESKY SPARSE_NORMAL_CHOLESKYThreads 1 1Linear solver ordering AUTOMATIC 4998Cost:Initial 1.292357e+06Final 6.757562e+02Change 1.291681e+06Minimizer iterations 14Successful steps 14Unsuccessful steps 0Time (in seconds):Preprocessor 0.005670 Residual only evaluation 0.011906 (14) Jacobian &amp; residual evaluation 0.107149 (14) Linear solver 2.324161 (14)Minimizer 2.470840Postprocessor 0.000254Total 2.476764Termination: CONVERGENCE (Function tolerance reached. |cost_change|/cost: 2.318092e-07 &lt;= 1.000000e-06) 通用的无约束优化问题 参考资料 Ceres 入门 | 简书 Windows 系统下 Ceres Solver 库的安装 | CSDN Windows 安装 Ceres | CSDN win10 安装 ceres 环境 | CSDN Ceres 库，从入门到放弃 | CSDN OpenSLAM: https://openslam-org.github.io/","link":"/blogs/ceres/"},{"title":"Clash","text":"科学上网 Linux详细步骤说明 到官方网站 https://github.com/Dreamacro/clash/releases/tag/v1.8.0 下载 clash-linux-amd64-v1.8.0.gz, 解压后得到clash-linux-amd64; 重命名 123mv clash-linux-amd64 clash chmod a+x clash mkdir ~/.config/clash Clash 正确运行首先需要一个 Country.mmdb 的文件，这个是全球 ip 数据库文件，没有这个文件 clash 是无法运行的. 默认情况下执行 ./clash 也是可以得到，但是往往会因为网络原因下载不了, 因此可以从其他地方手动下载该文件. Gitee: GeoLite2-Country.mmdb. 接下来就要准备机场提供的 clash 订阅的配置文件了，也就是 config.yaml 文件，这个文件可以通过 clash for windows 客户端中的 profile 中保存下来. 我买的梯子直接提供了该文件的网址, 可以通过 wget 命令下载得到(其中的 &lt;url&gt; 替换为卖家提供的网址). 1wget -O config.yaml &lt;url&gt; 把 Country.mmdb 和config.yaml移动到 ~/.config/clash/ 目录下. 12mv Country.mmdb ~/.config/clash/mv config.yaml ~/.config/clash/ 在 ubuntu 系统设置 -&gt; 网络 -&gt; 网络代理中配置 方法: 手动http 代理: 127.0.0.1 7890https 代理: 127.0.0.1 7890socks 主机: 127.0.0.1 7891 启动 1./clash # 可以用 [-d &lt;dir&gt;]来指定参数文件的路径, 默认为 `~/.config/clash/` 打开网页 http://clash.razord.top/ 选择代理服务器即可. 简易操作 安装 以上关于可执行文件和配置文件的操作都被写到了 setup.bash,update_config.bash,run_clash.bash 三个脚本中, 安装时只需将 install_clash.zip(private) 下载到本地 如果是 armv8 平台 (树莓派 4B)，下载clash-linux-armv8-v1.8.0.gz 替换clash-linux-amd64-v1.8.0.gz. 1wget https://github.com/Dreamacro/clash/releases/download/v1.8.0/clash-linux-armv8-v1.8.0.gz 然后运行如下指令进行安装, 并重启终端使 .bashrc 生效. 12chmod a+x setup.bash./setup.bash 如果确认安装成功了,clone 到本地的仓库可以直接删除. 更新代理服务器 如果需要更新代理服务器的配置文件 config.yaml 则新建终端执行如下指令 1update_config.bash 一般而言, 无需更新代理服务器, 只有当使用过程中发现大部分服务器都超时无法使用时可以尝试更新配置文件. 启动 每次要启动代理时, 运行如下指令, 并保持所在终端不被关闭: 1run_clash.bash 在设置中配置网络代理并设置为 手动. Windows 访问 release 下载对应版本的安装包, 例如 Clash.for.Windows.Setup.0.20.11.exe, 双击安装即可. 汉化补丁: https://github.com/BoyceLig/Clash_Chinese_Patch/releases 官方文档: https://docs.cfw.lbyczf.com/ 参考链接 clash 代理工具详细使用方法","link":"/blogs/clash/"},{"title":"CUDA + cuDNN 安装教程","text":"Windows 10, CUDA 10.2 cuDNN 7.6 下载 cuda 10.2, 访问链接: https://developer.nvidia.com/cuda-10.2-download-archive, 该页面会有几个选项, 分别配置为 Operating System: Windows Architecture: x86_64 Version: 10 Installer Type: exe (local) 或者也可以直接访问: https://developer.nvidia.com/cuda-10.2-download-archive?target_os=Windows&amp;target_arch=x86_64&amp;target_version=10&amp;target_type=exelocal. 需要下载的包括一个安装包和两个补丁文件包: cuda_10.2.89_441.22_win10.exe cuda_10.2.1_win10.exe cuda_10.2.2_win10.exe 下载 cuDNN, 访问链接: https://developer.nvidia.com/rdp/cudnn-archive#a-collapse765-102, 定位到如下位置. Download cuDNN v7.6.5 (November 18th, 2019), for CUDA 10.2Library for Windows, Mac, Linux, Ubuntu and RedHat/Centos(x86_64architecture)cuDNN Library for Windows 10 下载一个库文件压缩包: cudnn-10.2-windows10-x64-v7.6.5.32.zip 安装 https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#installwindows CUDA 直接依次双击安装即可 安装完成后打开 powershell 验证 123456(base) PS C:\\Users\\username&gt; nvcc -Vnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2019 NVIDIA CorporationBuilt on Wed_Oct_23_19:32:27_Pacific_Daylight_Time_2019Cuda compilation tools, release 10.2, V10.2.89(base) PS C:\\Users\\username&gt; cuDNN 安装只需解压后把库文件复制到 CUDA 安装目录即可. Copy &lt;unzip path&gt;\\cuda\\bin\\cudnn*.dll to &lt;CUDA PATH&gt;\\bin. Copy &lt;unzip path&gt;\\cuda\\include\\cudnn*.h to &lt;CUDA PATH&gt;\\include. Copy &lt;unzip path&gt;\\cuda\\lib\\x64\\cudnn*.lib to &lt;CUDA PATH&gt;\\lib\\x64. 复制完成后打开 powershell 验证, 到如下路径运行程序,Result = PASS表示安装成功. 1234567891011121314151617181920212223242526(base) PS D:\\CUDA\\extras\\demo_suite&gt; bandwidthTest.exe[CUDA Bandwidth Test] - Starting...Running on... Device 0: GeForce MX250 Quick Mode Host to Device Bandwidth, 1 Device(s) PINNED Memory Transfers Transfer Size (Bytes) Bandwidth(MB/s) 33554432 3067.2 Device to Host Bandwidth, 1 Device(s) PINNED Memory Transfers Transfer Size (Bytes) Bandwidth(MB/s) 33554432 3224.2 Device to Device Bandwidth, 1 Device(s) PINNED Memory Transfers Transfer Size (Bytes) Bandwidth(MB/s) 33554432 47884.9Result = PASSNOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.(base) PS D:\\CUDA\\extras\\demo_suite&gt; 环境变量 CUDA 安装好后系统环境变量中会出现CUDA_PATH,CUDA_PATH_V10_2 两个系统变量. 如果要在 VS 工程里使用 CUDA+cuDNN, 则最好在系统路径(Path) 里增加: D:\\CUDA\\include D:\\CUDA\\lib\\x64 D:\\CUDA\\bin D:\\CUDA\\libnvvp (其中 D:\\CUDA\\ 就是我安装 cuda 的路径) 卸载 如果要更换 cuda/cudnn 版本, 或者是单纯想要卸载 cuda/cudnn, 可以直接在控制面板里操作, 卸载掉其中以 NVIDIA CUDA * 开头的几个即可. Refer https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html https://docs.nvidia.com/deploy/cuda-compatibility/index.html","link":"/blogs/cuda_cudnn/"},{"title":"g2o 优化库","text":"g2o: A General Framework for Graph Optimization 主页: https://openslam-org.github.io/g2o.html 官方仓库: https://github.com/RainerKuemmerle/g2o 参考 深入理解图优化与 g2o：图优化篇 - 高翔 | 博客园 深入理解图优化与 g2o：g2o 篇 - 高翔 | 博客园 win10+vs2019+g2o 安装教程 | 简书 https://www.cnblogs.com/flyinggod/p/14949766.html","link":"/blogs/g2o/"},{"title":"CMake 学习笔记","text":"为了写出更加专业规范的工程项目，有必要学习一下 CMake 工具。这里主要参考Modern CMake, 一般指 CMake 3.4+ ，甚至是 CMake 3.21+. 本项目主要基于 Windows 平台进行讲解，并通过 VS 2017 来进行编译. 相关代码托管在 Github: https://github.com/siyouluo/learn_cmake 环境: Windows 10 Visual Studio Community 2017 CMake 3.18.5 安装 Install cmake - Download binary 预定义变量 含义 CMAKE_MAJOR_VERSION cmake 主版本号 CMAKE_MINOR_VERSION cmake 次版本号 CMAKE_C_FLAGS 设置 C 编译选项 CMAKE_CXX_FLAGS 设置 C++ 编译选项 PROJECT_SOURCE_DIR 工程的根目录 PROJECT_BINARY_DIR 运行 cmake 命令的目录 CMAKE_CURRENT_SOURCE_DIR 当前 CMakeLists.txt 所在路径 CMAKE_CURRENT_BINARY_DIR 目标文件编译目录 EXECUTABLE_OUTPUT_PATH 重新定义目标二进制可执行文件的存放位置 LIBRARY_OUTPUT_PATH 重新定义目标链接库文件的存放位置 CMAKE_ROOT cmake 安装目录 我的示例 通用编译流程 Configure &amp; Generate 123&gt; mkdir build&gt; cd build&gt; cmake .. 在 build 目录下找到 ${PROJECT_NAME}.sln，双击打开，点击 生成解决方案 进入生成的 *.exe 文件目录下，执行 12&gt; .\\demo.exe 2 32 ^ 3 is 8 如果要删除编译生成的 build 文件夹，可在 powershell 执行: Remove-Item -Path build -Recurse Demo1 - 基本框架 本项目仅包含一个 main.cpp 和一个 CMakeLists.txt. 其中 main.cpp 的功能是读入两个浮点数 a,b，计算a^b 并在终端输出.本项目中演示 CMakeLists.txt 的最基础版本，如下. 1234567891011121314# cmake 语法关键字 -- 大 / 小写无关，一般用小写的 cmake_minimum_required# cmake 的最低版本号，注意 VERSION 需要大写cmake_minimum_required(VERSION 3.18)# 设置一个工程名字project(Demo1 VERSION 0.1.0 # 语义化版本 https://semver.org/lang/zh-CN/ DESCRIPTION &quot;demo project&quot; # CMake&gt;=3.9 才可以使用 DESCRIPTION LANGUAGES CXX)# 目标可执行程序 demo， 需要编译 main.cppadd_executable(demo main.cpp) Demo2 - 多文件编译 本项目包含三个代码文件 main.cpp my_power.cpp my_power.h 和一个 CMakeLists.txt. 相比于 Demo1，这里需要修改的只有add_executable 中添加源文件的方式，共有如下几种，选择任意一种即可. 手动列出所有文件 只需在编译目标后面列出所需的全部源文件和头文件即可. 1add_executable(demo main.cpp my_power.cpp my_power.h) 请注意，这里添加头文件不是必须的，但是在用 cmake 配合 IDE 使用 (例如通过 cmake 配置并生成 visual studio 解决方案) 时，添加头文件列表可以显式地把自己的头文件放到一个 Header Files 分组内，如下是 VS 的 解决方案资源管理器 中显示的样子。如果 add_executable 没有添加头文件，那么用户自己的头文件 my_power.h 就会被放在 外部依赖项 里面。 12345678910111213141516解决方案 'Demo2'(3 个项目)- ALL_BUILD- demo - 引用 - 外部依赖项 - iostream - stdio.h - stdlib.h ... - Header Files - my_power.h - Source Files - main.cpp - my_power.cpp - CMakeLists.txt- ZERO_CHECK 自动列出目录下所有源文件 使用 aux_source_directory(&lt;dir&gt; &lt;variable&gt;) 将指定路径下的’cpp/cc/c’源文件全部绑定到 SRC_LIST，然后在添加目标时使用该变量. 123aux_source_directory(. SRC_LIST)message(STATUS &quot;SRC_LIST=${SRC_LIST}&quot;) # 在配置的时候打印输出变量 SRC_LISTadd_executable(demo ${SRC_LIST}) 注意这样不会添加头文件, 配置时终端输出如下, 其中 SRC_LIST 只有源文件，没有头文件. 12345build&gt; cmake ..-- Selecting Windows SDK version 10.0.17763.0 to target Windows 10.0.19044.-- SRC_LIST=./main.cpp;./my_power.cpp-- Configuring done-- Generating done 使用通配符设置文件列表 通过 file(GLOB VAR &quot;*.cpp&quot;) 来将所有 cpp 文件放到变量 VAR 中，然后在添加目标时使用该变量. 12345678file(GLOB ALL_SOURCES &quot;*.cpp&quot;) # 查找指定目录下的所有.cpp, 并存放到指定变量名 ALL_SOURCES 中file(GLOB ALL_INCLUDES &quot;*.h&quot;) # 查找指定目录下的所有.cpp, 并存放到指定变量名 ALL_INCLUDES 中# 将变量 ALL_SRCS 设置为 ALL_SOURCES + ALL_INCLUDESset(ALL_SRCS ${ALL_SOURCES} ${ALL_INCLUDES})add_executable(demo ${ALL_SRCS}) 在一条 file() 语句中可以添加多个匹配项，中间用空格隔开即可, 如: file(GLOB VAR &quot;*.cpp&quot; &quot;*.cc&quot; &quot;*.h&quot; &quot;./FOLDER/*.cpp&quot;) 匹配方法： file(GLOB SRC_LIST &quot;*.cpp&quot;)只匹配当前路径下的所有 cpp 文件 file(GLOB_RECURSE SRC_LIST &quot;*.cpp&quot;)递归搜索所有路径下的所有 cpp 文件 file(GLOB SRC_COMMON_LIST RELATIVE &quot;common&quot; &quot;*.cpp&quot;)在 common 目录下搜索 cpp 文件 在 Modern CMake 行为准则 中提到应该避免使用这种方法，因为在执行 cmake .. 之后如果新添加了源文件，该文件不会被编译系统感知到，也就不会被编译，除非重新再执行一次cmake ..(虽然我觉得这不是件什么大不了的事). 文件模块化管理 一个良好的工程项目必然包含多个不同功能模块，同样在 cmake 中也可以将其按照功能的不同进行分组管理。 123456789file(GLOB MY_POWER_FILES &quot;my_power.cpp&quot; &quot;my_power.h&quot;) # 将 my_power 模块的源文件和头文件, 设置到指定变量名 MY_POWER_FILES 中# source_group(common/math FILES ${MY_POWER_FILES}) # 将 my_power 的源文件和头文件分组到 common/math 组里# 将变量 ALL_SRCS 设置为 main.cpp + MY_POWER_FILESset(ALL_SRCS main.cpp ${MY_POWER_FILES})add_executable(demo ${ALL_SRCS}) 如果希望在 解决方案资源管理器 也对文件按模块分组，那么可以添加 source_group 指令: source_group(common/math FILES ${MY_POWER_FILES}), 效果如下: 12345678910111213解决方案 'Demo2'(3 个项目)- ALL_BUILD- demo - 引用 - 外部依赖项 - common - math - my_power.cpp - my_power.h - Source Files - main.cpp - CMakeLists.txt- ZERO_CHECK 注意： 在添加 source_group 函数并重新执行 cmake .. 后，VS 不会提示重新加载解决方案，需要关闭 VS 重新打开项目. [CMake 笔记] CMake 向解决方案添加源文件兼头文件 CMAKE（3）—— aux_source_directory 包含目录下所有文件以及自动构建系统 CMake » Documentation » cmake-commands(7) » aux_source_directory 初识 CMake，如何编写一个 CMake 工程（上） CMakeLists.txt 语法介绍与实例演练 Demo3 - 多目录模块化编译 本项目演示如何管理多个目录下的文件, 文件结构如下: 12345678Demo3| CMakeLists.txt| main.cpp\\---math CMakeLists.txt my_power.cpp my_power.h 事实上，如果仅仅是简单的将文件分目录存放，那么 Demo2 中的方法也够用了.本项目在子目录 math/ 下也新建了一个 CMakeLists.txt 用来管理子目录下的文件，然后在上层目录下的 CMakeLists.txt 里面调用它. 注意：子路径下 CMakeLists.txt 中的变量名在上层 CMakeLists.txt 里面不再有效。 两个文件分别如下所示: 1234# math/CMakeLists.txtfile(GLOB MY_POWER_FILES &quot;my_power.cpp&quot; &quot;my_power.h&quot;) # 将 my_power 模块的源文件和头文件, 设置到指定变量名 MY_POWER_FILES 中add_library(my_power ${MY_POWER_FILES}) # 将本目录下的文件编译成静态库 12345678910# CMakeLists.txt...# 编译其他目录下的文件，如 mathadd_subdirectory(math)# 编译当前目录下的文件add_executable(demo main.cpp)# 把其他目录下的静态、动态库链接进来target_link_libraries(demo my_power) 注意子目录下的 CMakeLists.txt 不需要也不可以指定 cmake 的版本要求和工程名.子目录下的 CMakeLists.txt 将my_power.cpp/.h编译成静态链接库，然后再将其链接到目标 demo 上. 由于是静态库，最后编译得到的目标 demo.exe 是可以单独运行的. 生成的 VS 解决方案资源管理器如下: 12345678910111213141516171819202122解决方案 'Demo3'(4 个项目)- ALL_BUILD- demo - 引用 - 外部依赖项 - iostream - stdio.h - stdlib.h - my_power.h ... - Source Files - main.cpp - CMakeLists.txt- my_power - 引用 - 外部依赖项 - Header Files - my_power.h - Source Files - my_power.cpp - CMakeLists.txt- ZERO_CHECK 点击 生成解决方案 后得到如下编译输出: 123456789build+---Debug| demo.exe| demo.ilk| demo.pdb+---math \\---Debug my_power.lib my_power.pdb Demo4 - 自定义编译选项 在一个大工程中可能包含多个不同的模块，有时可能希望选择其中一些模块进行编译，而另一些模块不编译，也就是对工程进行裁剪。或者工程中的两个模块是可以相互替代的，我们希望能让用户自己选择使用哪一个模块。 要实现这种功能需要考虑两个方面: CMakeLists.txt和源代码. 在 CMakeLists.txt 中可以根据 option() 参数来决定是否执行某些 cmake 语句. 123456789101112131415option(USE_MYMATH &quot;use provided math implementation&quot; ON) # 设置为 ON 或 OFF，默认为 OFFmessage(STATUS &quot;USE_MYMATH is ${USE_MYMATH}&quot;)...# 是否加入 math 目录下的模块if (USE_MYMATH) # include_directories(&quot;${PROJECT_SOURCE_DIR}/math&quot;) add_subdirectory(math) # 编译其他文件夹的源代码 set(EXTRA_LIBS ${EXTRA_LIBS} my_power)endif(USE_MYMATH)# 编译当前目录下的文件add_executable(demo main.cpp)# 把其他目录下的静态、动态库链接进来target_link_libraries(demo ${EXTRA_LIBS}) 已定义 option 选项会缓存在 CMakeCache.txt 中, 除非在命令行通过 -D 参数显式地执行cmake .. -DUSE_MYMATH=OFF/ON, 或者删除缓存文件，否则配置一次后就不再改变(即便修改CMakeLists.txt). 当 USE_MYMATH 为OFF时，编译目标没有链接到 my_power 库，无法使用自己定义的函数，因此源码中必然需要进行相应的修改。为了更通用，cmake 提供了 configure_file() 函数，可以在执行 cmake .. 时根据 option() 参数将一个 config.h.in 文件转换为头文件config.h.123456789# CMakeLists.txt...# 加入一个配置头文件 config.h.in，用于编译选项的设置，注意这个文件必须用户提前建立，否则编译错误 -- 找不到该文件configure_file( &quot;${PROJECT_SOURCE_DIR}/config.h.in&quot; &quot;${PROJECT_BINARY_DIR}/config.h&quot;)include_directories(&quot;${PROJECT_BINARY_DIR}&quot;)... 注意, config.h.in是自己编写的, 如下 12// 表示启用宏名 USE_MYMATH，而且会在 config.h 中自动加入对应代码#cmakedefine USE_MYMATH 而 build/config.h 是 cmake 自动生成的，根据 USE_MYMATH 取值不同而不同 当 USE_MYMATH 为ON: 12// 表示启用宏名 USE_MYMATH，而且会在 config.h 中自动加入对应代码#define USE_MYMATH 当 USE_MYMATH 为OFF: 12// 表示启用宏名 USE_MYMATH，而且会在 config.h 中自动加入对应代码/* #undef USE_MYMATH */ 因此可以在 main.cpp 中根据是否定义了 USE_MYMATH 宏，来使用不同的代码参与运算.注意在 main.cpp 中要 #include &quot;config.h&quot;, 因此需要让编译器知道该头文件的位置，在CMakeLists.txt 中需要添加头文件路径include_directories(&quot;${PROJECT_BINARY_DIR}&quot;). 123456789101112131415161718// main.cpp#include &quot;config.h&quot;#ifdef USE_MYMATH #include &quot;math/my_power.h&quot;#else #include &lt;math.h&gt;#endif...#ifdef USE_MYMATH printf(&quot;Now we use our own Math library. \\n&quot;); double result = my_power(base, exponent);#else printf(&quot;Now we use the standard library. \\n&quot;); double result = pow(base, exponent);#endif CMake » Documentation » cmake-commands(7) » configure_file Demo5 - 安装和测试 安装 设置安装目录 安装目录由 CMAKE_INSTALL_PREFIX 指定，windows 下默认为CMAKE_INSTALL_PREFIX=C:/Program Files (x86)/${PROJECT_NAME} 要修改安装目录可以直接在 CMakeLists.txt 中通过 set() 指令实现:set(CMAKE_INSTALL_PREFIX ${PROJECT_SOURCE_DIR}/install) 后续所有 install() 指令安装的目标路径都是相对于 CMAKE_INSTALL_PREFIX 的. 安装文件 所谓 安装 实际上就是把编译生成的文件拷贝到安装目录中，整合成一个可以直接运行的软件包.本例程文件结构如下: 12345678Demo5| CMakeLists.txt| main.cpp\\---math CMakeLists.txt my_power.cpp my_power.h 首先安装子目录下的库 子目录 math/ 中有头文件，并且在 CMakeLists.txt 中还设置了要生成库文件. 这两部分需要被安装到指定目录中去.修改math/CMakeLists.txt 1234567# math/CMakeLists.txt...# 指定 my_power 库的安装路径install(TARGETS my_power DESTINATION bin)install(FILES my_power.h DESTINATION include) 安装编译目标和相关头文件 修改CMakeLists.txt 12345678# CMakeLists.txt...# 指定 demo.exe 安装路径install(TARGETS demo DESTINATION bin)install(FILES &quot;${PROJECT_BINARY_DIR}/config.h&quot; DESTINATION include) 执行 cmake .. 之后通过 VS 打开解决方案，可以看到解决方案资源管理器如下所示 12345678910111213141516171819202122232425解决方案 'Demo5'(5 个项目)- ALL_BUILD- demo - 引用 - 外部依赖项 - config.h - my_power.h ... - Source Files - main.cpp - CMakeLists.txt- INSTALL - 引用 - 外部依赖项 - CMake Rules - INSTALL_force.rule- my_power - 引用 - 外部依赖项 - Header Files - my_power.h - Source Files - my_power.cpp - CMakeLists.txt- ZERO_CHECK 其中 INSTALL 项目就是用于安装的, 在直接点击 生成解决方案 时会被跳过，输出如下: 1234...5&gt;------ 已跳过生成: 项目: INSTALL, 配置: Debug Win32 ------5&gt; 没有为此解决方案配置选中要生成的项目 ========== 生成: 成功 4 个，失败 0 个，最新 0 个，跳过 1 个 ========== 此时如果要安装，需要选中 INSTALL 项目，右键，点击 生成, 输出如下, 表示相关文件已经被拷贝到了对应的目录中了: 12345671&gt;------ 已启动生成: 项目: INSTALL, 配置: Debug Win32 ------1&gt;-- Install configuration: &quot;Debug&quot;1&gt;-- Installing: &lt;path&gt;/Demo5/install/bin/my_power.lib1&gt;-- Installing: &lt;path&gt;/Demo5/install/include/my_power.h1&gt;-- Installing: &lt;path&gt;/Demo5/install/bin/demo.exe1&gt;-- Installing: &lt;path&gt;/Demo5/install/include/config.h========== 生成: 成功 1 个，失败 0 个，最新 4 个，跳过 0 个 ========== 可以查看 install 目录如下: 12345678Demo5\\install+---bin| demo.exe| my_power.lib|\\---include config.h my_power.h 测试 为了验证代码正确性，可以事先给出几个样例，在生成目标后运行测试样例，判断其输出是否正确, 从而判断程序是否正确.CMake提供了一个称为 CTest 的测试工具。我们要做的只是在项目根目录的 CMakeLists.txt 文件中调用一系列的 add_test() 命令. 要添加测试，首先在 CMakeLists.txt 中添加: enable_testing()然后就可以通过 add_test(&lt;name&gt; &lt;command&gt; [&lt;arg&gt;...]) 来添加测试. 其中 &lt;name&gt; 可以随便，但不要重复；&lt;command&gt;是编译生成的目标文件, 后面 &lt;arg&gt; 给出可执行文件需要的参数. 测试程序是否可以运行: add_test (test_run demo 5 2) 测试帮助信息是否可以正常提示 123add_test (test_usage demo) # 测试时不指定参数，main 函数中会检查发现参数个数不对，然后输出帮助信息set_tests_properties (test_usagePROPERTIES PASS_REGULAR_EXPRESSION &quot;Usage: .* base exponent&quot;) # 通过正则表达式检查程序输出是否正确 测试 5 的平方 123add_test (test_5_2 demo 5 2) # 测试时指定参数 5 和 2，程序会计算 5^2, 然后在终端输出set_tests_properties (test_5_2PROPERTIES PASS_REGULAR_EXPRESSION &quot;is 25&quot;) # 通过正则表达式检查程序输出是否正确 如果要执行更多的测试样例，使用 add_test() 效率就太低了，可以通过编写宏来简化操作: 1234567891011# 定义一个宏，用来简化测试工作macro (do_test arg1 arg2 result) add_test (test_${arg1}_${arg2} demo ${arg1} ${arg2}) set_tests_properties (test_${arg1}_${arg2} PROPERTIES PASS_REGULAR_EXPRESSION ${result})endmacro (do_test) # 使用该宏进行一系列的数据测试do_test (5 2 &quot;is 25&quot;)do_test (10 5 &quot;is 100000&quot;)do_test (2 10 &quot;is 1024&quot;) 执行 cmake .. 之后通过 VS 打开解决方案，可以看到解决方案资源管理器如下所示 1234567891011121314解决方案 'Demo5'(6 个项目)- ALL_BUILD- demo ...- INSTALL ...- RUN_TESTS - 引用 - 外部依赖项 - CMake Rules - RUN_TESTS_force.rule- my_power ...- ZERO_CHECK 其中 RUN_TESTS 项目就是用于测试的, 在直接点击 生成解决方案 时会被跳过，需要在生成解决方案之后单独生成一次，输出如下: 12345678910111213141516171819202122231&gt;------ 已启动生成: 项目: RUN_TESTS, 配置: Debug Win32 ------1&gt;Test project &lt;path&gt;/Demo5/build1&gt; Start 1: test_run1&gt;1/8 Test #1: test_run ......................... Passed 0.02 sec1&gt; Start 2: test_usage1&gt;2/8 Test #2: test_usage ....................... Passed 0.01 sec1&gt; Start 3: test_5_21&gt;3/8 Test #3: test_5_2 ......................... Passed 0.01 sec1&gt; Start 4: test_10_51&gt;4/8 Test #4: test_10_5 ........................ Passed 0.01 sec1&gt; Start 5: test_2_101&gt;5/8 Test #5: test_2_10 ........................ Passed 0.01 sec1&gt; Start 6: test_5_31&gt;6/8 Test #6: test_5_3 ......................... Passed 0.02 sec1&gt; Start 7: test_10_21&gt;7/8 Test #7: test_10_2 ........................ Passed 0.01 sec1&gt; Start 8: test_2_51&gt;8/8 Test #8: test_2_5 ......................... Passed 0.01 sec1&gt;1&gt;100% tests passed, 0 tests failed out of 81&gt;1&gt;Total Test time (real) = 0.20 sec========== 生成: 成功 1 个，失败 0 个，最新 1 个，跳过 0 个 ========== CMake » Documentation » cmake-commands(7) » add_test Demo6 - 添加版本号 1234567 版本格式：主版本号. 次版本号. 修订号，版本号递增规则如下： 1. 主版本号：当你做了不兼容的 API 修改， 2. 次版本号：当你做了向下兼容的功能性新增， 3. 修订号：当你做了向下兼容的问题修正。先行版本号及版本编译信息可以加到“主版本号. 次版本号. 修订号”的后面，作为延伸。 语义化版本 2.0.0 要在 CMakeLists.txt 中指定版本号只需在设置工程名时顺带用 VERSION 属性设置即可: 12345project(Demo6 VERSION 0.1.0 # 语义化版本 https://semver.org/lang/zh-CN/ DESCRIPTION &quot;demo project&quot; # CMake&gt;=3.9 才可以使用 DESCRIPTION LANGUAGES CXX) 这里虽然只设置了一个属性VERSION，但同时如下四个变量会被 cmake 自动进行设置. 1234${PROJECT_NAME}_VERSION${PROJECT_NAME}_VERSION_MAJOR${PROJECT_NAME}_VERSION_MINOR${PROJECT_NAME}_VERSION_PATCH 可以通过 message() 来查看它们的值: 12345# 查看程序版本是否设置正确message(STATUS &quot;${PROJECT_NAME}_VERSION=${${PROJECT_NAME}_VERSION}&quot;)message(STATUS &quot;${PROJECT_NAME}_VERSION_MAJOR=${${PROJECT_NAME}_VERSION_MAJOR}&quot;)message(STATUS &quot;${PROJECT_NAME}_VERSION_MINOR=${${PROJECT_NAME}_VERSION_MINOR}&quot;)message(STATUS &quot;${PROJECT_NAME}_VERSION_PATCH=${${PROJECT_NAME}_VERSION_PATCH}&quot;) 执行 cmake .. 时终端输出如下: 123456PS &lt;path&gt;\\Demo6\\build&gt; cmake ..-- Selecting Windows SDK version 10.0.17763.0 to target Windows 10.0.19044.-- Demo6_VERSION=0.1.0-- Demo6_VERSION_MAJOR=0-- Demo6_VERSION_MINOR=1-- Demo6_VERSION_PATCH=0 如果希望在 *.cpp 源文件也能访问到这些变量，可以通过编写 Version.h.in 并用 configure_file() 指令实现, 此处略.可参考如下资料: CMake 入门实战 Modern CMake 简体中文版 » 基础知识简介 » 与你的代码交互 Demo7 - 生成安装包(未实现) 本项目学习如何配置生成各种平台上的安装包，包括二进制安装包和源码安装包。为了完成这个任务，我们需要用到 CPack ，它同样也是由 CMake 提供的一个工具，专门用于打包。 首先在顶层的 CMakeLists.txt 文件尾部添加下面几行： 123456789# 构建一个 CPack 安装包include (InstallRequiredSystemLibraries)set (CPACK_RESOURCE_FILE_LICENSE &quot;${CMAKE_CURRENT_SOURCE_DIR}/LICENSE&quot;)set (CPACK_PACKAGE_VERSION_MAJOR &quot;${${PROJECT_NAME}_VERSION_MAJOR}&quot;)set (CPACK_PACKAGE_VERSION_MINOR &quot;${${PROJECT_NAME}_VERSION_MINOR}&quot;)set (CPACK_PACKAGE_VERSION_PATCH &quot;${${PROJECT_NAME}_VERSION_PATCH}&quot;)include (CPack) 上面的代码做了以下几个工作： 导入 InstallRequiredSystemLibraries 模块，以便之后导入 CPack 模块； 设置一些 CPack 相关变量，包括版权信息和版本信息，其中版本信息用了上一节定义的版本号； 导入 CPack 模块 执行 cmake .. 后用 vs 打开解决方案，点击生成解决方案，然后单独生成 INSTALL 项目，单独生成 PACKAGE 项目 123456789101112解决方案 'Demo7'(7 个项目)- ALL_BUILD- demo- INSTALL- RUN_TESTS- PACKAGE - 引用 - 外部依赖项 - CMake Rules - PACKAGE_force.rule- my_power- ZERO_CHECK 终端输出如下, 似乎是没有安装NSIS(该问题暂未解决, 先搁置): 12341&gt;------ 已启动生成: 项目: PACKAGE, 配置: Debug Win32 ------1&gt;EXEC : CPack error : Cannot find NSIS compiler makensis: likely it is not installed, or not in your PATH1&gt;EXEC : CPack error : Could not read NSIS registry value. This is usually caused by NSIS not being installed. Please install NSIS from http://nsis.sourceforge.net1&gt;EXEC : CPack error : Cannot initialize the generator NSIS 参考: CMake 入门实战 Modern CMake 简体中文版 » Exporting and Installing » Packaging Demo8 - 编写 FindXXX.cmake(待完善)如果要在自己的项目中引用第三方库，可以通过 find_package(pkg-name) 来方便地实现，例如 OpenCV 和PCL等常用库都提供了相应的 OpenCVConfig.cmake 和PCLConfig.cmake, 调用者只需要让 CMake 能找到这类文件的路径即可方便地调用.但有些小众的第三方库可能并没有提供这类文件，或者自己编写的某些简单的库没有提供相应的文件，为了通过 cmake 调用，可以编写一个 FindXXX.cmake 来帮助查找库文件，从而将库的查找与使用进行解耦。 本项目包含两个部分: export和 import. 其中export 部分负责编译生成库文件，而 import 部分通过 Findxxx.cmake 的形式来引用这些库. 生成库 使用库 当移动了 MyMath 库的路径之后，只需要修改 cmake/FindMyMath.cmake 中的 MyMath_ROOT_DIR 即可. 如何为 cmake 提供 package 以便于 find_package, 以及用 VCPKG 补充 CMake 实现快速下载集成 Demo9 - 为自己的库生成 XXXConfig.cmake 项目文件结构 >folded12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758D:\\RESEARCH\\MACHINEVISION\\CODE\\LEARN_CMAKE\\CODES\\DEMO9+---export| | CMakeLists.txt| | Config.cmake.in| | LICENSE| || +---build| +---install| | +---bin| | | test_myplus.exe| | | test_mypower.exe| | || | +---cmake| | | MyMathConfig.cmake| | | MyMathConfigVersion.cmake| | | myplusTargets-debug.cmake| | | myplusTargets.cmake| | | mypowerTargets-debug.cmake| | | mypowerTargets.cmake| | || | +---include| | | myplus.h| | | mypower.h| | || | \\---lib| | myplus.lib| | mypower.lib| || +---mymath| | +---myplus| | | myplus.cpp| | || | \\---mypower| | mypower.cpp| | mypower.h| || \\---samples| +---myplus| | test_myplus.cpp| || \\---mypower| test_mypower.cpp|\\---import | CMakeLists.txt | +---build +---install | \\---bin | test_myplus.exe | test_mypower.exe | \\---samples +---myplus | test_myplus.cpp | \\---mypower test_mypower.cpp CMake Tutorial: Code Step 11: Adding Export Configuration CMakePackageConfigHelpers Modern CMake: Exporting and Installing 如何为 cmake 提供 package 以便于 find_package, 以及用 VCPKG 补充 CMake 实现快速下载集成 CMake 库打包以及支持 find_package Demo10 - 通过 CMake 管理 Qt GUI 项目 Get started with CMake - doc.qt.io Build with CMake cmake-qt(7) CMake Introduction CMake 管理 C/C++ 工程的一点心得 在 Qt 项目中调用 OpenCV: 访问 usb 摄像头并实时绘制到 QLabel (CMake + VSCode) Using CMake with Qt 5 Qt and CMake: The Past, the Present and the Future 参考 Modern CMake 简体中文版 An Introduction to Modern CMake CMake 3.18 Documentation CMake Tutorial CMake 入门实战 ve2102388688/myCmakeDemos - Github BrightXiaoHan/CMakeTutorial - Github CMake Tutorial - ltslam-doc CMake 教程 - CSDN C++ 工程目录结构规范示例 - Github","link":"/blogs/cmake/"},{"title":"搭建博客","text":"基于 Hexo 搭建静态博客网站，使用 ICARUS 主题，并部署在 Github Pages 上。 在 Github 创建网站 参考 GitHub Pages 快速入门 在 Github 创建一个带有自己用户名的仓库 username.github.io, 例如 siyouluo.github.io.然后在该仓库下新建一个 index.html 文件 index.html1hello world 稍等片刻, 即可访问 https://siyouluo.github.io 打开网站。 具体的网址可以在仓库的 Settings -&gt; Pages -&gt; GitHub Pages 页面看到: Your site is live at &lt;some url&gt;. 自定义域名 (可选)GitHub Pages 提供的域名是用户名后跟着 .github.io, 如果自己有域名, 可以使用自己的域名来访问该网站. 登录自己的域名管理页面 (例如腾讯云域名解析 https://console.dnspod.cn/dns/), 添加两条记录, 其中 @ 主机的记录值是通过 ping siyouluo.github.io 显示出来的 ip 地址. 主机记录 记录类型 记录值 @ A 185.199.111.153 www CNAME siyouluo.github.io 补充 实际上, 通过 ping 得到的 ip 地址总是在如下四个地址之间变动, 在进行域名解析时可以添加四条 A 记录, 分别指向四个 ip.实测中, 至少需要有一条 A 记录指向如下之一的 ip 地址即可. ping siyouluo.github.io1234185.199.108.153185.199.109.153185.199.110.153185.199.111.153 参考 Managing a custom domain for your GitHub Pages site 在 Github 仓库 Settings -&gt; Pages -&gt; GitHub Pages: Custom domain 填入自己的域名 (例如 luosiyou.cn), 并等待域名解析完成后, 勾选 [√] Enforce HTTPS, 等待片刻后, 该页面上方将更新网站的地址: Your site is live at https://luosiyou.cn/. 此时将发现 Github 仓库下多了一个 CNAME 文件, 事实上我们也可以在仓库中手动添加这个文件来启用自定义域名 CNAME1luosiyou.cn 使用 Hexo 搭建网站 参考 Hexo 文档 安装 Git 访问 https://nodejs.org/en/download/ 下载 node.js, 双击 node-v16.18.0-x64.msi 文件安装, 默认下一步, 并勾选 [√] Automatically install the necessary tools.; 启动终端运行如下指令, 查看安装是否成功 12&gt; node -v&gt; npm -v 运行示例 >folded12345678910111213141516171819202122PS C:\\Users\\siyou&gt; hexo -vhexo-cli: 4.3.0os: win32 10.0.22000node: 16.18.0v8: 9.4.146.26-node.22uv: 1.43.0zlib: 1.2.11brotli: 1.0.9ares: 1.18.1modules: 93nghttp2: 1.47.0napi: 8llhttp: 6.0.10openssl: 1.1.1q+quiccldr: 41.0icu: 71.1tz: 2022bunicode: 14.0ngtcp2: 0.8.1nghttp3: 0.7.0PS C:\\Users\\siyou&gt; npm -v8.19.2 注意 在 Windows Terminal 内可以使用 cmd 或 PowerShell 运行 而在 PowerShell 中执行时, 可能会报错 无法加载文件，因为在此系统中禁止执行脚本，此时以管理员身份打开 PowerShell 并修改执行策略即可 Windows PowerShell1&gt; Set-ExecutionPolicy RemoteSigned 安装 Hexo 12&gt; npm install -g hexo-cli&gt; npm install hexo-deployer-git --save # 用于网站部署 建站 执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 123&gt; hexo init &lt;folder&gt;&gt; cd &lt;folder&gt;&gt; npm install 新建完成后，指定文件夹的目录如下： 12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 各文件及文件夹用途可以参考 Hexo 建站 示例 12345678910111213PS D:\\Data&gt; hexo init hexo-icarus-pagesINFO Cloning hexo-starter https://github.com/hexojs/hexo-starter.gitINFO Install dependenciesINFO Start blogging with Hexo!PS D:\\Data&gt; cd .\\hexo-icarus-pages\\PS D:\\Data\\hexo-icarus-pages&gt; npm installup to date, audited 240 packages in 1s22 packages are looking for funding run `npm fund` for detailsfound 0 vulnerabilities 自定义域名 (可选)如果前面配置了自己的域名, 那么在下一步部署之前, 先在 source/ 文件夹下添加 CNAME 文件,否则部署上去之后, Github 仓库内本来存在的该文件会被删去, 导致域名解析失效. CNAME1luosiyou.cn 修改配置文件 编辑 _config.yml 配置文件 _config.yml123456# Deployment## Docs: https://hexo.io/docs/one-command-deploymentdeploy: type: git repo: https://github.com/siyouluo/siyouluo.github.io.git branch: master 个性化配置 修改 _config.yml 配置文件中的 title, author, url, permalink 等配置项 具体各配置项含义参考 https://hexo.io/zh-cn/docs/configuration 生成博客并部署到 Github Pages 123456789&gt; hexo clean # 清除上一次生成的静态网站文件, 可简写为 hexo c&gt; hexo generate # 生成静态网站, 可简写为 hexo g # 参考 https://hexo.io/zh-cn/docs/generating&gt; hexo server # 在本地启动 hexo 服务, 可通过 http://localhost:4000 预览网站, # 并且修改源文件后刷新浏览器会自动更新页面 # 可简写为 hexo s # 参考 https://hexo.io/zh-cn/docs/server&gt; hexo deploy # 将 public/ 文件夹下的静态网站部署到 Github, 可简写为 hexo d # 参考 https://hexo.io/zh-cn/docs/one-command-deployment 创建新的博客文章 初始化站点时, 存在一个默认的 source/_posts/hello-world.md 文件可以生成第一条博客, 后续如果需要创建新的博客, 使用如下命令. 1&gt; hexo new &quot;My New Post&quot; # 参考 https://hexo.io/zh-cn/docs/writing 在主页中仅显示文章的一部分. 参考 Hexo 文档 &gt;&gt; 标签插件 &gt;&gt; 文章摘要和截断 创建草稿与发布 12&gt; hexo new draft &lt;title&gt; # 创建一个草稿&gt; hexo publish draft &lt;title&gt; # 将草稿发布到 post 使用 ICARUS 主题 安装 icarus 主题12&gt; npm install -S hexo-renderer-inferno&gt; git clone https://github.com/ppoffice/hexo-theme-icarus themes/icarus 使用 hexo 命令修改主题为 Icarus1&gt; hexo config theme icarus 生成站点123&gt; hexo c&gt; hexo g&gt; hexo s 个性化配置 修改 _config.icarus.yml 文件, 例如更改其中某些链接, 注释掉一些不需要的组件 更换图片: themes/icarus/source/img/ 图标: http://www.fontawesome.com.cn/faicons/ 目录粘性定位: Icarus 主题自定义 &gt;&gt; 目录粘性定位 添加 latex 支持: 在_config.icarus.yml 文件中设置 mathjax: true 参考链接 Hexo 官方文档 Hexo Github 仓库 Icarus 快速上手 Hexo 插入代码块 改图鸭 照片变漫画","link":"/blogs/hexo/"},{"title":"Darknet 训练与部署 YoLov3 模型","text":"基于 YoLo 的目标检测 本项目主要针对灰度图像 .bmp 进行目标检测, 要求高效、准确地从灰度图像中检测出目标物体. 环境 Windows 10 Visual Studio 2017 NVIDIA Geforce RTX 2060 CUDA 10.2 cuDNN 数据集构建 首先需要采集足够多的图片, 然后使用 labelImg 工具进行图片标注. 从 Github 官方仓库 https://github.com/tzutalin/labelImg/releases/tag/v1.8.1 下载 windows_v1.8.1.zip, 解压后可以直接运行其中的labelImg.exe 打开软件, 解压路径不可以有中文. 软件使用可以参考 labelImg 使用教程 图像标定工具 注意, 软件中存储格式要从 PascalVOC(标签文件存储为 xml 格式) 改为yolo(标签文件存储为 txt 格式). 构建好的数据集包括若干张 .bmp 图片及其对应的同名 .txt 文件. YoLo 模型训练 darknet 框架 官方版本(作者: Joseph Redmon) Darknet 是一个用 C 和 CUDA 编写的开源神经网络框架。速度快，安装方便，支持 CPU 和 GPU 计算. 官网: https://pjreddie.com/darknet/官网安装教程: https://pjreddie.com/darknet/install/ 123456Darknet is easy to install with only two optional dependancies: OpenCV if you want a wider variety of supported image types. CUDA if you want GPU computation.Both are optional so lets start by just installing the base system. I've only tested this on Linux and Mac computers. If it doesn't work for you, email me or something? 该框架的作者 Joseph Redmon 仅在 linux 和 mac 系统中测试过, 要在 windows 系统下使用还要想其他办法. windows 适配版(作者: AlexeyAB)AlexeyAB 在原项目的基础上增加了darknet 在 windows 上的适配. 官方 Github 仓库: https://github.com/AlexeyAB/darknetRelease 版: https://github.com/AlexeyAB/darknet/releases/tag/darknet_yolo_v3AlexeyAB-DarkNet 源码解析: https://github.com/BBuf/Darknet 从上述 Release 地址下载 darknet.zip 解压后即可运行. 各类博客编译版 在网上看到很多帖子都是下载了整个仓库后通过 Visual Studio 编译的, 这些帖子都写得好复杂的样子, 我之前就安装过 CUDA 和cuDNN, 再配置一下 OpenCV 就编译通过了, 唯一的问题是要把配置管理器设置为Release+x64, 也没遇到他们那么多 bug, 不知道怎么回事，先记录在这里. WIN10 下配置 Yolov3(VS2019,GPU)+opencv 训练自己的数据集（绝对详细，小白型记录） Yolov3：win10 下训练自己的数据（GPU 版）（详细步骤） AlexeyAB Release 版 既然 AlexeyAB 提供了他构建好的二进制包, 那么我们直接用就好了 There are attached compiled binary files of Darknet for Windows x64 (559 MB): https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3/darknet.zip 从上述网址下载 darknet.zip 文件, 解压缩后在 darknet\\build\\ 路径下的 darknet 就是编译好的包, 其子目录 x64\\ 下的 darknet.exe 和darknet_no_gpu.exe就是编译得到的可执行文件. 在该路径下同时还有一个 yolov3.weights 文件就是预训练的权重, 以便直接用于模型推理, 同时该文件也可以在 darknet 官网找到. 另一个 darknet53.conv.74 也是权重文件, 在训练自己的数据集时会用到. 预训练权重: https://pjreddie.com/media/files/yolov3.weightshttps://pjreddie.com/media/files/darknet53.conv.74 测试 打开 Powershell, 进入 darknet\\build\\darknet\\x64\\ 路径下, 运行如下命令: .\\darknet.exe detect .\\cfg\\yolov3.cfg .\\yolov3.weights .\\data\\dog.jpg 运行结束后会弹出一张图, 其中框选出了图中的truck,bicycle,dog. 训练自己的数据集 可以参考 AlexeyAB 的 github 仓库:https://github.com/AlexeyAB/darknet或者他的中文翻译版:https://github.com/BBuf/Darknet 数据集组织 开始训练之前需要准备: 数据集图片文件、使用 LabelImg 标注的标签文件、训练集和验证集划分文件、预训练模型参数、数据集类别文件、数据集说明文件、yolov3 配置文件. 例如对于一个从 .bmp 格式图片中提取出标定板 board 的项目来说, 需要组织如下结构的文件, 其中大多数文件名其实是可以自定义的，但是务必要统一. 12345678910111213141516- darknet_data\\ - dataset\\ - image1.bmp #相机拍照产生 - image1.txt #labelImg 标注得到 - image2.bmp - image2.txt - ... - train.txt # 由 Generatefilename.py 脚本生成 - val.txt # 由 Generatefilename.py 脚本生成 - pretrainedweight\\ # 预训练模型权重 - darknet53.conv.74 - trainedweights\\ # 即将要训练得到的模型权重文件 - board.data # 数据集说明文件 - board.names # 数据集标签名文件 - Generatefilename.py # 自动化脚本, 读取数据集中图片文件名，将其中一部分作为训练集写入 train.txt, 另一部分作为验证集写入 val.txt - yolov3-board.cfg # yolov3 配置文件，由官方配置文件复制修改而成 其中部分文件是从官方文件复制修改而来的, 根据实际情况, 作如下修改: train.txt/val.txt 如下所示的文本文件, 每行列出一张图片相对 darknet.exe 的路径. 当然也可以写出绝对路径. 后面将用 python 脚本来自动生成. 1234./darknet_data/dataset/image1.bmp./darknet_data/dataset/image10.bmp./darknet_data/dataset/image11.bmp./darknet_data/dataset/image12.bmp board.data 总类别数 classes=1 train 和 valid 描述了训练接和验证集的文件名, 写出其相对于 darknet.exe 的路径 (注意,darknet_data 整个文件夹要放置到和darknet.exe 相同路径下). names 指出标签名文件位置 backup 表示训练后的权重文件放置位置, 模型每迭代 100 次保存当前最好的参数, 每 1000 次保存一下当前参数. 123456classes= 1train = darknet_data/dataset/train.txtvalid = darknet_data/dataset/val.txt#difficult = darknet_data/dataset/difficult_2007_test.txtnames = darknet_data/board.namesbackup = darknet_data/trainedweights/ board.names 标签文件, 文件内每个标签名占一行 1board Generatefilename.py 将图片文件名分成训练集和验证集两类, 分别写入 train.txt 和 val.txt 文件内. 可以用绝对路径表示, 也可以用相对于 darknet.exe 的相对路径表示. 如下的 python 脚本可以自动化地生成这两个文件. 注意根据实际情况修改 rootdir 的路径和分类时的阈值. 123456789101112131415161718192021222324import osfrom os import listdir, getcwdfrom os.path import joinif __name__ == '__main__': rootdir = 'E:\\RobotArm\\deeplearning\\yolo\\darknet_data' source_folder= join(rootdir,'dataset') train_dest=join(rootdir,'dataset/train.txt') val_dest= join(rootdir,'dataset/val.txt') file_list=os.listdir(source_folder) train_file=open(train_dest,'w') val_file=open(val_dest,'w') for file_obj in file_list: file_path=os.path.join(source_folder,file_obj) file_name,file_extend=os.path.splitext(file_obj) if(file_extend!=&quot;.bmp&quot;): continue file_name = file_name.replace(&quot;image&quot;,&quot;&quot;) file_num = int(file_name) if(file_num&lt;40): train_file.write(&quot;./darknet_data/dataset/image&quot;+file_name+'.bmp\\n') else : val_file.write(&quot;./darknet_data/dataset/image&quot;+file_name+'.bmp\\n') train_file.close()val_file.close() yolov3-board.cfg 从官方 yolov3-voc.cfg 文件复制修改而来. 要修改的地方包括 1234567891011121314151617181920212223242526subdivisions=32 # 这里可以设置为 16,32 或 64. 如果设置得太小则可能会内存不足. 视情况增大即可.max_batches = 4000 # 最大迭代次数, 视情况而定, 一般可以设置为 classes*2000 但是不要低于 4000.steps=3200,3600 #一般为 80% 和 90% 的 max_batches# 然后全文检索 yolo, 可以检索到三个地方. # 每个地方下方有个 classes 设置为 1 # 对应的上方有个 filters 设置为(classes+5)*3=18. 如下所示.[convolutional]size=1stride=1pad=1filters=18activation=linear[yolo]mask = 6,7,8anchors = 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326classes=1num=9jitter=.3ignore_thresh = .5truth_thresh = 1random=1 训练 在 powershell 中执行如下命令: 1PS C:\\Users\\Username&gt; .\\darknet.exe detector train .\\darknet_data\\board.data .\\darknet_data\\yolov3-board.cfg .\\darknet_data\\pretrainedweight\\darknet53.conv.74 .\\darknet_data\\trainedweights &gt;&gt; .\\darknet_data\\yolov3-board.log 测试 基于 OpenCV 的模型部署123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159#include &lt;fstream&gt;#include &lt;sstream&gt;#include &lt;iostream&gt;#include &lt;opencv2/dnn.hpp&gt;#include &lt;opencv2/imgproc.hpp&gt;#include &lt;opencv2/highgui.hpp&gt;#include&lt;vector&gt;using namespace std;using namespace cv;using namespace dnn;vector&lt;string&gt; classes;vector&lt;String&gt; getOutputsNames(Net&amp;net){ static vector&lt;String&gt; names; if (names.empty()) { //Get the indices of the output layers, i.e. the layers with unconnected outputs vector&lt;int&gt; outLayers = net.getUnconnectedOutLayers(); //get the names of all the layers in the network vector&lt;String&gt; layersNames = net.getLayerNames(); // Get the names of the output layers in names names.resize(outLayers.size()); for (size_t i = 0; i &lt; outLayers.size(); ++i) names[i] = layersNames[outLayers[i] - 1]; } return names;}void drawPred(int classId, float conf, int left, int top, int right, int bottom, Mat&amp; frame){ //Draw a rectangle displaying the bounding box rectangle(frame, Point(left, top), Point(right, bottom), Scalar(255, 178, 50), 3); //Get the label for the class name and its confidence string label = format(&quot;%.5f&quot;, conf); if (!classes.empty()) { CV_Assert(classId &lt; (int)classes.size()); label = classes[classId] + &quot;:&quot; + label; } //Display the label at the top of the bounding box int baseLine; Size labelSize = getTextSize(label, FONT_HERSHEY_SIMPLEX, 0.5, 1, &amp;baseLine); top = max(top, labelSize.height); rectangle(frame, Point(left, top - round(1.5*labelSize.height)), Point(left + round(1.5*labelSize.width), top + baseLine), Scalar(255, 255, 255), FILLED); putText(frame, label, Point(left, top), FONT_HERSHEY_SIMPLEX, 0.75, Scalar(0, 0, 0), 1);}void postprocess(Mat&amp; frame, const vector&lt;Mat&gt;&amp; outs, float confThreshold, float nmsThreshold){ vector&lt;int&gt; classIds; vector&lt;float&gt; confidences; vector&lt;Rect&gt; boxes; for (size_t i = 0; i &lt; outs.size(); ++i) { // Scan through all the bounding boxes output from the network and keep only the // ones with high confidence scores. Assign the box's class label as the class // with the highest score for the box. float* data = (float*)outs[i].data; for (int j = 0; j &lt; outs[i].rows; ++j, data += outs[i].cols) { Mat scores = outs[i].row(j).colRange(5, outs[i].cols); Point classIdPoint; double confidence; // Get the value and location of the maximum score minMaxLoc(scores, 0, &amp;confidence, 0, &amp;classIdPoint); if (confidence &gt; confThreshold) { int centerX = (int)(data[0] * frame.cols); int centerY = (int)(data[1] * frame.rows); int width = (int)(data[2] * frame.cols); int height = (int)(data[3] * frame.rows); int left = centerX - width / 2; int top = centerY - height / 2; classIds.push_back(classIdPoint.x); confidences.push_back((float)confidence); boxes.push_back(Rect(left, top, width, height)); } } } // Perform non maximum suppression to eliminate redundant overlapping boxes with // lower confidences vector&lt;int&gt; indices; NMSBoxes(boxes, confidences, confThreshold, nmsThreshold, indices); for (size_t i = 0; i &lt; indices.size(); ++i) { int idx = indices[i]; Rect box = boxes[idx]; drawPred(classIds[idx], confidences[idx], box.x, box.y, box.x + box.width, box.y + box.height, frame); }}int main(){ string darknet_path = &quot;..\\\\darknet_data\\\\&quot;; string names_file = darknet_path + &quot;board.names&quot;; String model_def = darknet_path + &quot;yolov3-board.cfg&quot;; String weights = darknet_path + &quot;trainedweights\\\\yolov3-board_last.weights&quot;; int in_w, in_h; double thresh = 0.5; double nms_thresh = 0.25; in_w = in_h = 608; string img_path = darknet_path + &quot;dataset\\\\image45.bmp&quot;; //read names ifstream ifs(names_file.c_str()); string line; while (getline(ifs, line)) classes.push_back(line); //init model Net net = readNetFromDarknet(model_def, weights); net.setPreferableBackend(DNN_BACKEND_OPENCV); net.setPreferableTarget(DNN_TARGET_CPU); //read image and forward //VideoCapture capture(2);// VideoCapture:OENCV 中新增的类，捕获视频并显示出来 Mat frame, blob; //capture &gt;&gt; frame; frame = cv::imread(img_path, cv::IMREAD_COLOR); blobFromImage(frame, blob, 1 / 255.0, Size(in_w, in_h), Scalar(), true, false); vector&lt;Mat&gt; mat_blob; imagesFromBlob(blob, mat_blob); //Sets the input to the network net.setInput(blob); // Runs the forward pass to get output of the output layers vector&lt;Mat&gt; outs; net.forward(outs, getOutputsNames(net)); postprocess(frame, outs, thresh, nms_thresh); vector&lt;double&gt; layersTimes; double freq = getTickFrequency() / 1000; double t = net.getPerfProfile(layersTimes) / freq; string label = format(&quot;Inference time for a frame : %.2f ms&quot;, t); putText(frame, label, Point(0, 15), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 0, 255)); imshow(&quot;res&quot;, frame); waitKey(); return 0;} C++ 调用 yolov3 模型 -opencv3.4.2 C++ 调用 yolov3 模型 -opencv3.4.2","link":"/blogs/darknet_yolov3/"},{"title":"levmar 优化库","text":"levmar 是一个基于 C/C++ 实现的 Levenberg-Marquardt 非线性最小二乘算法的优化库。 levmar 官网 Levenberg-Marquardt 算法 Gauss-Newton 算法是一个古老的处理非线性最小二乘问题的方法。该方法在迭代过程中要求矩阵 J(x) 满秩。为了克服这个困难，Levenberg(1944)提出了一种新的方法，但未受到重视。后来 Marquardt(1963)又重新提出，并在理论上进行了探讨，得到 Levenberg-Marquardt 方法，简称 LM 方法。在此基础上，Fletcher(1971)对其实现策略进行了改进，得到了 Levenberg-Marquardt-Fletcher 方法（LMF）。再后来，More(1978)将 LM 方法与信赖域方法结合，建立了带信赖域的 LM 方法。 LM 算法的产生主要是解决曲线最小二乘拟合问题，现在很多软件使用 LM 算法来解决通用的曲线拟合问题。 Download 从官网下载levmar-2.6.tgz: http://users.ics.forth.gr/~lourakis/levmar/levmar-2.6.tgz 下载 levmar 的依赖库LAPACK: http://www.netlib.org/clapack/clapack-3.2.1-CMAKE.tgz 分别解压得到两个文件夹: levmar-2.6,clapack-3.2.1-CMAKE BuildBuild LAPACK 打开 CMake-Gui, Where is the source code:填 clapack-3.2.1-CMAKE 文件夹, 并在该文件夹内新建 BUILD 文件夹, 将 Where to build the binaries: 填为该 BUILD 文件夹. 点击Configure, 配置Visual Studio 15 2017,x64,Use default native compilers, 会有一些红色的 warning, 可直接忽略 点击Generate-&gt;Open Project. 可以将解决方案依次配置为 Debug\\MinSizeRel\\Release\\RelWithDebInfo, 然后生成解决方案. 也可以点击 生成 -&gt; 批生成 -&gt; 勾选前四个ALL_BUILD-&gt; 生成. 在 BUILD 目录下生成了一系列库文件, 将其复制出来，后续将添加到 levmar 库中 1234[clapack-3.2.1-CMAKE\\BUILD]\\BLAS\\SRC\\Debug: blas.lib[clapack-3.2.1-CMAKE\\BUILD]\\F2CLIBS\\libf2c\\Debug: libf2c.lib -&gt; copy and rename to f2c.lib[clapack-3.2.1-CMAKE\\BUILD]\\SRC\\Debug: lapack.lib[clapack-3.2.1-CMAKE\\BUILD]\\Testing\\MATGEN\\Debug: tmglib.lib 其中除了 Debug, 也可能生成了其他配置的对应库文件, 都可以复制到相应的文件夹中. 头文件 blaswrap.h,clapack.h,f2c.h 复制到 INCLUDE 文件夹中. Build levmar 打开 CMake-Gui,Where is the source code:填 levmar-2.6 文件夹, 并在该文件夹内新建 build 文件夹, 将 Where to build the binaries: 填为该 build 文件夹. 点击Configure, 配置Visual Studio 15 2017,x64,Use default native compilers, 将 LAPACKBLAS_DIR 的 Value 从默认的 usr/lib 文件夹路径改成之前放置 LAPACK 的 lib 库的路径.(levmar也可以不依赖于 lapack 进行编译, 只需将 HAVE_LAPACK 取消勾选即可, 但部分功能将不可用) 点击Generate-&gt;Open Project. 可以将解决方案依次配置为 Debug\\MinSizeRel\\Release\\RelWithDebInfo, 然后生成解决方案. 也可以点击 生成 -&gt; 批生成 -&gt; 勾选前四个ALL_BUILD-&gt; 生成. 将解决方案下的 lmdemo 设置为启动项目，运行测试. 得到如下测试结果 12345678910111213Covariance of the fit:0.00483514 -0.00162445 -0.000548114-0.00162445 0.000546079 0.000184356-0.000548114 0.000184356 6.22705e-05Results for Meyer's (reformulated) problem:Levenberg-Marquardt returned 215 in 215 iter, reason 2Solution: 2.481778 6.181346 3.502236Minimization info:1308.25 8.79459e-05 5.8718e-08 5.01074e-31 2106.35 215 2 282 22 216按任意键关闭此窗口... 在 BUILD 目录下生成了一系列库文件, 将其复制出来. RelWithDebInfo levmar.lib lmdemo.ilk lmdemo.pdb Debug xxx Release xxx MinSizeRel xxx 另外将几个头文件复制到 include 文件夹下: compiler.h, levmar.h, lm.h, misc.h Reference levmar : Levenberg-Marquardt nonlinear least squares algorithms in C/C++ Levmar:Levenberg-Marquardt 非线性最小二乘算法 Levmar 配置 - CSDN 64 位 WIN 7/8 下 VS2010 配置 CLAPCAK3.2.1 和 Levmar2.6","link":"/blogs/levmar/"},{"title":"C++ 路径管理类","text":"使用 Windows SDK 实现的 PathManager https://github.com/siyouluo/Storage/tree/master/PathManager OpenCV cv::utils::fs https://docs.opencv.org/3.4.11/d1/d85/filesystem_8hpp.html CPP17 文件系统库 https://zh.cppreference.com/w/cpp/filesystem","link":"/blogs/filesystem/"},{"title":"OpenCV","text":"OpenCV 3.4.11 文档 Download OpenCV Releases 点击OpenCV 3.4.11 download, 直接下载 OpenCV 3.4.11 windows 版本. Install下载 opencv-3.4.11-vc14_vc15.exe 文件，双击安装(其实只是一个解压过程)。 有的教程中会建议将解压后的 OpenCV 下的某些路径添加到系统环境变量中；这里换一种方法，仅修改 VS 的工程属性，无需添加系统环境变量。 VS2017 配置 参考OpenCV 4.1.0 + Visual Studio 2019 开发环境搭建 超级简单 准备文件12345678910111213141516171819202122232425- &lt;sln&gt; 解决方案文件夹 - x64 - Debug // 将 opencv\\build\\x64\\vc15\\bin 路径下的 3 个.dll 文件拷贝到这里 - &lt;proj&gt;.exe - opencv_world3411.dll - opencv_world3411d.dll - opencv_ffmpeg3411_64.dll - Release - &lt;proj&gt;.exe - opencv_world3411.dll - opencv_world3411d.dll - opencv_ffmpeg3411_64.dll - &lt;proj&gt; 项目文件夹 - Debug - include - opencv2 // 从 opencv\\build\\include 路径下将整个 opencv2 文件夹拷贝到这里 - lib // 将 opencv\\build\\x64\\vc15\\lib 路径下的两个.lib 文件拷贝到这里 - opencv_world3411.lib - opencv_world3411d.lib - src - main.cpp - x64 - Debug - Debug 配置 LIB在 解决方案资源管理器 右击项目名 -&gt;属性 -&gt; 链接器 -&gt; 常规 -&gt; 附加库目录 : 将 lib 文件夹路径添加到这里，或者直接用相对路径表示，添加lib 即可.在 解决方案资源管理器 右击项目名 -&gt;属性 -&gt; 链接器 -&gt; 输入 -&gt; 附加依赖项: 将 lib 文件名添加到这里, 例如 opencv_world3411d.lib. INCLUDE在 解决方案资源管理器 右击项目名 -&gt;属性 -&gt;C/C++-&gt; 常规 -&gt; 附加包含目录 : 将 include 文件夹路径添加到这里，或者直接用相对路径表示，添加include 即可. 测试123456789101112131415161718#include&lt;iostream&gt;#include&quot;opencv2/opencv.hpp&quot;using namespace std;using namespace cv;int main(){ cout &lt;&lt; &quot;OpenCV Test:&quot; &lt;&lt; endl; /********************* * 这个图片需要自己准备，放在 images 文件夹下 * 注意这里的 &quot;./&quot; 表示相对路径，指相对于工程文件 &lt;demo_proj.vcxproj&gt; 的路径 *********************/ Mat img = imread(&quot;./images/demo.jpg&quot;); // imshow(&quot;demo&quot;, img);// 显示图片 6 秒 waitKey(6000); return 0;} 在图片中写入中文字符 OpenCV 显示中文 | 知乎 使用 OpenCV 自带的 cv::putText() 函数往图片里写入中文字符时无法正常显示，而是显示为 “???”. 要解决这个问题, 在 Windows 平台上可以调用 Windows API 里的 HDC 系列函数来完成字符绘制，封装后提供的接口为 cv::putTextZH(). 具体代码见: https://github.com/siyouluo/Storage/tree/master/cv_puttextzh 打包下载: https://github.com/siyouluo/Storage/releases/download/v1.0.0/cv_puttextzh.zip main.cpp1234567891011121314151617#include &quot;cv_puttextzh.h&quot;int main() { cv::Mat image = cv::Mat(500, 500,CV_8UC3, cv::Scalar(144, 238, 144)); cv::putTextZH( image, &quot; 你好！OpenCV&quot;, cv::Point(image.cols/3, image.rows / 2), CV_RGB(255, 255, 0), 30 ); cv::imshow(&quot; 中文图窗 &quot;, image); cv::waitKey(0); return 0;} 12345&gt; lsCMakeLists.txt main.cpp cv_puttextzh.h&gt; mkdir build&gt; cd build&gt; cmake .. -A x64 -DOpenCV_DIR=D:/OpenCV/opencv/build/x64/vc15/lib 如果是其他平台，在 OpenCV 显示中文 | 知乎 中也有解决方案，但需要结合 freetype 和 harfbuzz 重新编译 opencv_contrib. 常用颜色 BGR 值cv_color_def.h >folded12345678910111213141516171819202122232425262728293031// OpenCV 常用颜色 BGR 值#ifndef CV_COLOR_DEF_H#define CV_COLOR_DEF_H#include &lt;opencv2/core/types.hpp&gt;#define CV_COLOR_RED cv::Scalar(0,0,255) // 纯红#define CV_COLOR_GREEN cv::Scalar(0,255,0) // 纯绿#define CV_COLOR_BLUE cv::Scalar(255,0,0) // 纯蓝#define CV_COLOR_DARKGRAY cv::Scalar(169,169,169) // 深灰色#define CV_COLOR_DARKRED cv::Scalar(0,0,139) // 深红色#define CV_COLOR_ORANGERED cv::Scalar(0,69,255) // 橙红色#define CV_COLOR_CHOCOLATE cv::Scalar(30,105,210) // 巧克力#define CV_COLOR_GOLD cv::Scalar(10,215,255) // 金色#define CV_COLOR_YELLOW cv::Scalar(0,255,255) // 纯黄色#define CV_COLOR_OLIVE cv::Scalar(0,128,128) // 橄榄色#define CV_COLOR_LIGHTGREEN cv::Scalar(144,238,144) // 浅绿色#define CV_COLOR_DARKCYAN cv::Scalar(139,139,0) // 深青色#define CV_COLOR_SKYBLUE cv::Scalar(230,216,173) // 天蓝色#define CV_COLOR_INDIGO cv::Scalar(130,0,75) // 藏青色#define CV_COLOR_PURPLE cv::Scalar(128,0,128) // 紫色#define CV_COLOR_PINK cv::Scalar(203,192,255) // 粉色#define CV_COLOR_DEEPPINK cv::Scalar(147,20,255) // 深粉色#define CV_COLOR_VIOLET cv::Scalar(238,130,238) // 紫罗兰#endif // CV_COLOR_DEF_H OpenCV Contrib在 OpenCV 中有部分模块 (modules) 通常没有稳定的 API, 并且未经充分测试, 因此, 它们不应该作为 OpenCV 正式发行版的一部分发布.这些模块被单独开发, 并首先在 opencv_contrib 存储库中发布. 直至模块成熟并普及时, 才将其移至中央 OpenCV 存储库. 下载 要使用 opencv_contrib 必须将其与 OpenCV 主体部分联合编译, 因此需要下载具有相同版本号的源码. 这里统一使用 3.4.11. 从以下地址下载 OpenCV 和opencv_contrib的源码包, 如果 github 下载太慢可以尝试 gitee 极速下载. 将源码包解压到统一目录下，分别命名为 sources 和opencv_contrib. 并新建 build 文件夹. 1234- &lt;OpenCV_Contrib&gt; - sources # opencv-3.4.11.zip 解压并重命名得到 - opencv_contrib # opencv_contrib-3.4.11.zip 解压得到 - build # 新建空文件夹 OpenCV 3.4.11 OpenCV 3.4.11 - Github branch OpenCV 3.4.11 Release OpenCV 3.4.11 source code Gitee 极速下载 / opencv opencv_contrib 3.4.11 opencv_contrib 3.4.11 - Github branch opencv_contrib 3.4.11 Release opencv_contrib 3.4.11 source code Gitee 极速下载 / opencv_contrib 编译安装 打开CMake-Gui, 配置如下: Where is the source code: &lt;OpenCV_Contrib&gt;/sources Where to build the binaries: &lt;OpenCV_Contrib&gt;/build点击一次 Configure 修改配置: BUILD_opencv_world [√] OPENCV_ENABLE_NONFREE [√] OPENCV_EXTRA_MODULES_PATH: &lt;OpenCV_Contrib&gt;/opencv_contrib/modules并再次点击 Configure. 之后 CMake 会从网上下载部分文件, 但往往因为网速问题而下载失败，输出红色 warning，此时可以按照提示去查看 &lt;OpenCV_Contrib&gt;/build/CMakeDownloadLog.txt, 其中记录了 CMake 试图从某些网址下载文件放到&lt;OpenCV_Contrib&gt;/sources/.cache/ 相应路径下. 以如下片段为例. 123456789101112131415#do_copy &quot;face_landmark_model.dat&quot; &quot;7505c44ca4eb54b4ab1e4777cb96ac05&quot; &quot;https://raw.githubusercontent.com/opencv/opencv_3rdparty/8afa57abc8229d611c4937165d20e2a2d9fc5a12/face_landmark_model.dat&quot; &quot;D:/OpenCV/opencv/build_contrib/testdata/cv/face/&quot;#missing &quot;D:/OpenCV/opencv/build_contrib/testdata/cv/face//face_landmark_model.dat&quot;#check_md5 &quot;D:/OpenCV/opencv/sources/.cache/data/7505c44ca4eb54b4ab1e4777cb96ac05-face_landmark_model.dat&quot;#mismatch_md5 &quot;D:/OpenCV/opencv/sources/.cache/data/7505c44ca4eb54b4ab1e4777cb96ac05-face_landmark_model.dat&quot; &quot;cbe7f803f749dbe38cf6445036349412&quot;#delete &quot;D:/OpenCV/opencv/sources/.cache/data/7505c44ca4eb54b4ab1e4777cb96ac05-face_landmark_model.dat&quot;#cmake_download &quot;D:/OpenCV/opencv/sources/.cache/data/7505c44ca4eb54b4ab1e4777cb96ac05-face_landmark_model.dat&quot; &quot;https://raw.githubusercontent.com/opencv/opencv_3rdparty/8afa57abc8229d611c4937165d20e2a2d9fc5a12/face_landmark_model.dat&quot;#try 1# timeout on name lookup is not supported# Trying 185.199.108.133:443...# TCP_NODELAY set# connect to 185.199.108.133 port 443 failed: Timed out# Failed to connect to raw.githubusercontent.com port 443: Timed out# Closing connection 0# 在该段日志中,CMake 试图从 “https://raw.githubusercontent.com/opencv/opencv_3rdparty/8afa57abc8229d611c4937165d20e2a2d9fc5a12/face_landmark_model.dat&quot; 下载 “face_landmark_model.dat” 文件放到 “D:/OpenCV/opencv/build_contrib/testdata/cv/face/“ 路径下.但是因为下载失败,&lt;...&gt;/cv/face/&quot;路径下没有找到该文件. 并且去 D:/OpenCV/opencv/sources/.cache/data/路径下查看, 发现其中有一个命名为 7505c44ca4eb54b4ab1e4777cb96ac05-face_landmark_model.dat 的空文件，大小为 0Kb. 因为是空的，所以在接下来的 md5 校验中不匹配.CMake delete 了该文件, 又尝试去网络上下载，但由于网络超时, 下载失败. 通过分析以上日志, 可以得出解决办法: 手动从以上路径下载相应文件，重命名后放到 &lt;OpenCV_Contrib&gt;/sources/.cache/ 相应路径下，放到该路径下的文件名应当类似于7505c44ca4eb54b4ab1e4777cb96ac05-face_landmark_model.dat, 文件名前是一段 md5 校验码. 或者: 直接下载文件复制到 &lt;OpenCV_Contrib&gt;/build/testdata/cv/face//face_landmark_model.dat, 此时文件名前不用加 md5 码. 所有文件手动下载后，再次点击Configure，应当不再输出红色的 warning 信息, 否则还应再次检查日志文件. 点击 Generate 生成 VS2017 解决方案, 点击 Open Project 打开. 在 VS2017 工具栏选择: 生成 -&gt; 批生成 ，勾选ALL_BUILD Debug,ALL_BUILD Release, INSTALL Debug, INSTALL Release 四项, 点击 生成 . 等待编译并安装, 之后在build/install/ 路径下会生成相应的库文件用于调用. Reference opencv_contrib 安装笔记 【OpenCV】 opencv_contrib 安装教程 InputArray/OutputArray 形参类型说明 在写 OpenCV C++ 程序时经常会看到其内置函数的形参是 cv::InputArray,cv::OutputArray 等类型; 如果仅仅是调用这些函数, 直接传入 cv::Mat,std::vector&lt;cv::Mat&gt; 等类型的实参即可.因为 OpenCV 定义的这些类型可以方便地看出形参是输入参数还是输出参数, 看起来比 const cv::Mat&amp;,cv::Mat&amp; 要专业些, 所以有些自己写的函数也想用这种类型, 本项目就简单介绍一下这些类型如何使用. cv::InputArraycv::InputArray是输入参数, 一般可以对标 const cv::Mat&amp; 类型, 在函数定义中使用的时候可以通过 cv::_InputArray::getMat() 获取到真正的 cv::Mat. 如下函数默认实参为cv::noArray(), 如果没有显式地传入有效实参, 则src.empty() 为true. 1234567891011121314void test_InputArray(cv::InputArray src = cv::noArray()){ CV_Assert(src.kind()==cv::_InputArray::MAT); cv::Mat src_mat; if(src.empty()) { src_mat = cv::Mat::eye(100,100,CV_8UC1)*255; } else{ src_mat = src.getMat(); } //do something...} cv::InputArrayOfArrayscv::InputArrayOfArrays实际上就是 cv::InputArray, 但既然类型名为InputArrayOfArrays, 一般用于表示const std::vector&lt;cv::Mat&gt;&amp;, 可以通过getMatVector() 获取到实际的数据. cv::OutputArraycv::OutputArray是输出参数, 该类型的变量并没有默认分配内存空间, 需要在函数定义中显式地申请空间.以下函数默认实参为 cv::noArray(), 如果用户实际上不需要该数据, 则可以使用该实参, 在函数定义中通过cv::_OutputArray::needed() 判断是否需要, 然后执行相应的操作. 12345678void test_OutputArray(cv::OutputArray dst = cv::noArray()){ if(dst.needed()) { cv::Mat mat = cv::Mat::eye(50,50,CV_8UC1)*255; dst.assign(mat); }} 以上函数定义中通过定义 cv::Mat mat 来分配了空间, 然后再通过 assign() 即可将其通过 dst 输出.还有另一种分配空间的方式:create, 此时无需 assign 即可输出. 123456789void test_OutputArray(cv::OutputArray dst = cv::noArray()){ if(dst.needed()) { dst.create(cv::Size(50,50),CV_8UC1); cv::Mat mat = dst.getMat(); mat = cv::Mat::eye(50,50,CV_8UC1)*255; }} cv::OutputArrayOfArrayscv::OutputArrayOfArrays实际上就是 cv::OutputArray, 但既然类型名为OutputArrayOfArrays, 一般用于表示std::vector&lt;cv::Mat&gt;&amp;.assign 前要先通过 create 为其分配空间. 12345678910111213141516171819202122232425262728void test_OutputArrayofArrays(cv::OutputArrayOfArrays dst){ std::vector&lt;cv::Mat&gt; outImages; outImages.push_back(cv::Mat::eye(500,500,CV_8UC1)*255); outImages.push_back(cv::Mat::eye(600,600,CV_8UC1)*255); // 以下三种实现任意一种都是可行的 #if 1 // 表示 dst 是 outImages.size() 行 1 列的 array, 其中每个元素都是 CV_8UC1 类型的 cv::Mat dst.create((int)outImages.size(), 1, CV_8UC1);#endif#if 0 // 表示 dst 是 1 维的 array, 该维度长度是 outImages.size(),array 内每个元素都是 CV_8UC1 类型的 cv::Mat int size = (int)outImages.size(); dst.create(1, &amp;size, CV_8UC1);#endif#if 0 // 表示 dst 是 2 维的 array, 两个维度长度分别是 1 和 outImages.size(),array 内每个元素都是 CV_8UC1 类型的 cv::Mat // 由于我们这里实际用的是 `std::vector&lt;cv::Mat&gt;` 类型的变量, 因此交换两个维度的长度也是可以的. // 即 int size[2] = {1,(int)outImages.size()}; int size[2] = {(int)outImages.size(),1}; dst.create(2, size, CV_8UC1);#endif dst.assign(outImages);} 分辨 cv::Mat 和std::vector&lt;cv::Mat&gt;由于 cv::InputArray 与cv::InputArrayOfArrays实际上是同一种类型, 因此尽管我们约定前者表示 cv::Mat, 后者表示std::vector&lt;cv::Mat&gt;, 但这并不是强制的. 为了确保用户传入的实参符合预期, 可以用kind() 来获取实参的类型. 1CV_Assert(src.kind()==cv::_InputArray::MAT); Reference cv::_InputArray Class Reference - OpenCV docs cv::_InputArray Class Reference - OpenCV docs cv::_InputArray cv::_OutputArray - 博客园 OpenCV 学习笔记（五十六）——InputArray 和 OutputArray 的那些事 core 如何使用 opencv 中的 OutputArray 来接受 Mat 和 vector＜Mat＞ enum cv::_InputArray::KindFlag - OpenCV docs access&amp;return vector via InputArray/OutputArray - Github return vector&lt;vector &gt; via OutputArrayOfArrays - Github","link":"/blogs/opencv/"},{"title":"开源协议","text":"GitHub 开源协议详解及常用协议介绍 什么是 Apache License 2.0 开源协议","link":"/blogs/licenses/"},{"title":"ONNX 部署 PyTorch 模型","text":"ONNX RUNTIME 官网主页 ONNX RUNTIME 官网文档 官方托管 Github 仓库: Microsoft/onnxruntime ONNX Model Zoo: 预训练的 onnx 模型库 onnx/models# 目标检测与图像分割 onnx 模型 (可选）将模型从 PyTorch 导出到 ONNX 并使用 ONNX Runtime 运行 torch.onnx - 官方文档 Others torchvision 官方 Mask RCNN 转 ONNX onnxruntime 调用 AI 模型的 python 和 C++ 编程 深度学习模型转换与部署那些事(含 ONNX 格式详细分析) tenglike1997/onnxruntime-projects - Github ONNX 动态输入和动态输出问题 onnxruntime 的 c++ 使用(含多输入多输出问题) MIMO 模型的导入与运行 - Github ONNX C++ API 说明 对每个输入节点需要创建一个 Ort::Value 类型的变量, 该变量可以是具有动态维度的张量. 例如可以一次性输入 1 张图片, 也可以一次性输入 batch_size=100 张图片. 创建 Ort::Value 类型的变量需要通过 Ort::Value::CreateTensor 函数来创建, 该函数有几种重载形式, 对于如下这种 CreateTensor 形式而言 1static Ort::Value Ort::Value::CreateTensor&lt;T&gt;(const OrtMemoryInfo* info, T* p_data, size_t p_data_element_count, const int64_t* shape, size_t shape_len); 创建张量就需要将具体的数据组织成一维数组, 将首地址传入 T* p_data, 数据元素总数传入 size_t p_data_element_count, 张量形状组织成一维数组, 首地址传入 const int64_t* shape, 张量总维数传入size_t shape_len. 例如:要将 100 张 32*64 的 RGB 图片创建为张量, 那么原始数据形状可能为 [100,3,32,64], 需要将其变成一维的数组std::vector&lt;float&gt; p_data(100*3*32*64), 然后将数组首地址p_data 传入. 那么元素总数就是 p_data_element_count=100*3*32*64=614400. 为了让ONNX RUNTIME 明确数据的原始格式, 需要创建 std::vector&lt;int64_t&gt; shape = {100,3,32,64}, 然后将shape 作为维度数组的首地址传入. 最后该数据原本是 4 维的, 因此shape_len=4. 如果是多输入的, 那么首先创建多个 Ort::Value 类型的变量, 然后创建 std::vector&lt;Ort::Value&gt; ort_inputs, 再通过移动构造将这些变量压入vector 容器中. 12ort_inputs.push_back(std::move(Tensor_1));ort_inputs.push_back(std::move(Tensor_2)); 这样, 形式上可以将任意多个 Ort::Value 变量在内存中放在一起了. 在进行模型推理时, 调用 session.Run() 函数. 该函数有 三种重载版本 . 第一种是只需要给输入变量预分配内存, 将输出变量通过函数返回值返回;第二种需要给输入输出变量都预分配内存, 没有返回值;第三种将输入输出进行IoBinding&amp;, 没有返回值. 对于第一种版本: 12std::vector&lt;Value&gt; Run(const RunOptions&amp; run_options, const char* const* input_names, const Value* input_values, size_t input_count, const char* const* output_names, size_t output_count); input_names是输入节点名的字符串数组的首地址, 例如 std::vector&lt;const char*&gt; names = {&quot;input_1, &quot;input_2&quot;}. 那么将names 传入即可. input_values是要传入的若干个张量的首地址, 如果只传入一个张量, 那就对这个张量取地址 &amp;Tensor_1 传入即可; 如果要传入多个张量, 那么将这多个张量放在一个 vector 中, 并将该 vector 首地址传入即可 (二者实际是一致的).input_count 是要输入张量的个数.output_names,output_count同理. 在对输出变量进行解码时, 首先要按照输出节点数分为多个张量, 视该张量数据类型不同, 以不同数据类型取出其中的数据.例如下面代码块中,type就是数据类型.123456// print output node typesOrt::TypeInfo type_info = session.GetOutputTypeInfo(i);auto tensor_info = type_info.GetTensorTypeAndShapeInfo();ONNXTensorElementDataType type = tensor_info.GetElementType();printf(&quot;Output %d : type=%d\\n&quot;, i, type); 其中 ONNXTensorElementDataType 是一个枚举类型, 具体定义如下: 1234567891011121314151617181920212223// https://github.com/microsoft/onnxruntime/blob/master/include/onnxruntime/core/session/onnxruntime_c_api.h#L93// Copied from TensorProto::DataType// Currently, Ort doesn't support complex64, complex128typedef enum ONNXTensorElementDataType { ONNX_TENSOR_ELEMENT_DATA_TYPE_UNDEFINED, ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT, // maps to c type float ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT8, // maps to c type uint8_t ONNX_TENSOR_ELEMENT_DATA_TYPE_INT8, // maps to c type int8_t ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT16, // maps to c type uint16_t ONNX_TENSOR_ELEMENT_DATA_TYPE_INT16, // maps to c type int16_t ONNX_TENSOR_ELEMENT_DATA_TYPE_INT32, // maps to c type int32_t ONNX_TENSOR_ELEMENT_DATA_TYPE_INT64, // maps to c type int64_t ONNX_TENSOR_ELEMENT_DATA_TYPE_STRING, // maps to c++ type std::string ONNX_TENSOR_ELEMENT_DATA_TYPE_BOOL, ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT16, ONNX_TENSOR_ELEMENT_DATA_TYPE_DOUBLE, // maps to c type double ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT32, // maps to c type uint32_t ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT64, // maps to c type uint64_t ONNX_TENSOR_ELEMENT_DATA_TYPE_COMPLEX64, // complex with float32 real and imaginary components ONNX_TENSOR_ELEMENT_DATA_TYPE_COMPLEX128, // complex with float64 real and imaginary components ONNX_TENSOR_ELEMENT_DATA_TYPE_BFLOAT16 // Non-IEEE floating-point format based on IEEE754 single-precision} ONNXTensorElementDataType; 对于不同的数据类型, 对应的内存块中存储的是整型变量或者浮点型变量, 应当进行不同形式的解码, 如下. 12float* boxes_ptr = output_tensors[0].GetTensorMutableData&lt;float&gt;();int* labels_ptr = output_tensors[1].GetTensorMutableData&lt;int&gt;(); 解码后得到的是一维数据, 还应当依据输出张量的维度信息进行重新组织, 得到合理的输出. 线性回归例程 这里通过一个简单的线性回归模型来说明 onnx 模型文件的保存与加载 上图所示是一个简单的线性回归模型, 用 python+pytorch 创建并训练, 真实的回归模型为 y1 = 12*x+9, y2 = 4*x+9. 通过大量的随机数进行训练使其能够稳定预测输出值. 然后通过torch.onnx 将模型输出为 model.onnx 文件, 并再次通过 python+onnxruntime 读取该模型以验证模型文件是没有问题的. 然后通过 CPP+onnxruntime_cxx_api 读取该模型文件, 并输入 batch_size=6 个数据, 从得到的 [batch_size=6,2] 个数据来看, 可以较为准确地预测输出值. 123标量输入:x, 向量输出 y = [y1,y2]y1 = k1*x+b1y2 = k2*x+b2 通过 pytorch 创建模型、训练并保存 onnx 模型文件 Python 脚本: linear_regression2d.py 运行输出: linear_regression2d_py_output.txt 通过 cpp 加载 onnx 模型文件, 并进行推理 CPP 程序: linear_regression2d.cpp 运行输出: linear_regression2d_cpp_output.txt MaskRCNN 例程 当前有一个任务是要将 python+pytorch 编写的 maskrcnn 模型部署到 C++ 环境中, 主要路线是用 pytorch 内置的 torch.onnx 将模型输出为 *.onnx 文件, 然后再用 onnxruntime_cxx_api 导入模型进行推理. 示例图片如下: demo.jpg 调用 pytorch 内置模型 maskrcnn_resnet50_fpn(包括预训练参数). 使用torch.jit.script 直接输出序列化模型文件 model.pt. 如果用 C++ 版本的 libtorch+torchvision 也许是可以直接导入该模型文件并进行推理的, 但是 torchvision 的编译过程踩坑不断, 已弃疗! 创建并输出 pt 模型文件 调用 torch.onnx 输出序列化模型文件 model.onnx, 输出时需要提供一个示例样本, 理论上可以用随机数torch.randn, 这不影响模型导出以及后续的加载. 只是随机生成的样本可能经过模型推理后输出为空, 在python 环境中也许还比较容易发现异样, 但在用 C++ 编程加载模型并进行推理的时候如果也用随机样本, 并且输出为空, 会让人怀疑人生的! requirements: 1&gt; conda install -c conda-forge onnx 创建并输出 ONNX 模型文件 仍旧是用 python 加载模型文件 model.onnx, 并用onnxruntime 进行模型推理. 原始模型推理得到的输出是 batch_size 个字典组成的列表. 每个字典是对应某张图片的四个输出: &quot;boxes&quot;,&quot;labels&quot;,&quot;scores&quot;,&quot;masks&quot;. 而 onnxruntime 推理得到的输出似乎直接就全都是列表(待证!). Requirements: 1&gt; pip install onnxruntime Python 导入模型前向推理 以上是在 python 中进行模型导出与加载, 接下来要换用 C++ 接口实现. 环境: Visual Studio 2017, Windows 10 x64. 新建 VS 工程 -&gt; 项目 -&gt; 管理 NuGet 程序包 (N)-&gt; 浏览 -&gt; 输入 onnx: 选择 Microsoft.ML.OnnxRuntime+Microsoft.ML.OnnxRuntime.MKLML 进行安装 (每新建一个工程就要安装一次). 如果要用GPU 加速, 则应该下载 GPU 版本, 并且似乎 CPU 与GPU版本不可共存. 并且 Python 环境中也要对应, 使用一个就要卸载另一个.(这个后续再去仔细研究, 暂且仅用 CPU 版本) 参考: 如何在 VS 项目中添加 onnx runtime 包 读取图片 Note: 我首先将 demo_maskrcnn.jpg resize 成了 500*667 大小的图片demo_resize.jpg, 且此后所有操作都是针对处理后的图片进行的. 1234from PIL import Imageimg = Image.open('demo.jpg')img = img.resize((500,667))img.save('demo_resize.jpg') 图片读取与处理 .cpp 图片读取与处理 .h ONNX C++ API调用模型进行前向推理 C++ 模型前向推理 用 python(左) 和cpp(右)推理得到的模型输出结果依次如下图所示, 虽然有所区别, 但如果将置信度设置在 90% 以上, 则二者都检测出了图片中人物的全身. 此外, 这里试验用的模型是 pytorch预训练模型, 并没有针对此类图片进行专门训练. 测试出现偏差也情有可原. CPP 模型推理代码封装 main.cpp MaskRCNN_Session.cpp MaskRCNN_Session.h 本文例程打包下载: https://github.com/siyouluo/Storage/releases/download/v1.0.0/onnx.zip","link":"/blogs/onnx/"},{"title":"Qt","text":"Qt 5.12.10 MSVC 2017 QT 在 windows 平台不提供 64 位安装包, 但可以安装 32 位的 qt 和 64 位的编译组件用于编译出 64 位的程序. qt 镜像站 Index of /qtproject/archive/qt/5.12/5.12.10/ 国内 Qt 镜像网站 中国科学技术大学：http://mirrors.ustc.edu.cn/qtproject/清华大学：https://mirrors.tuna.tsinghua.edu.cn/qt/北京理工大学：http://mirror.bit.edu.cn/qtproject/中国互联网络信息中心：https://mirrors.cnnic.cn/qt/ 安装 首先到 镜像站 下载 qt 安装包, 选择合适的版本(例如 5.12.10), 点击下载qt-opensource-windows-x86-5.12.10.exe. 安装时要注册账号, 安装组件建议勾选: 123456789101112- Qt 5.12.10 - MSVC 2017 64-bit - MinGW 7.3.0 64-bit - Qt Charts - Qt Data Visualization - Qt Purchasing - Qt Virtual Keyboard - Qt WebEngine - Qt Network Authorization - Developer and Designer Tools - Qt Creator 4.13.1 CDB Debug - MinGW 7.3.0 64-bit QT+VS安装完成后到 VS2017 中点击 工具 -&gt; 扩展和更新 . 搜索Qt Visual Studio Tools 下载安装, 重启 VS2017, 然后 VS 上方菜单栏多出一个Qt VS Tools. 点击 Qt VS Tools-&gt;Qt Versions-&gt;&lt;add new Qt version&gt;, 设置Path 时选择 (QT 安装路径)\\5.12.10\\msvc2017_64\\bin\\qmake.exe 文件即可. 在 VS 中新建项目时就可以选择 qt-&gt;Qt Wigdgets Application. 新建的工程下默认出现如下文件 123456789- Form Files - xxx.ui- Header Files - xxx.h- Resource Files - xxx.qrc- Source Files - main.cpp - xxx.cpp 踩坑 若直接编译运行可能报错,VS 无法搜索到 qt 相关头文件, 在工程属性下查看 C/C++ 的附加包含目录发现继承了$(Qt_INCLUDEPATH_), 然而实际上搜索不到. 因此可以再新建一个包含目录, 将这个宏再添加一次即可. 如果直接在 VS 中双击 Form Files/xxx.ui 文件, 本应该跳转到 Qt Designer 打开该文件, 实际上可能出现闪退. 因此需要在 VS 中右键该文件, 选择打开方式, 其中有一个默认的Qt Designer. 该值可能无效, 点击添加, 程序选择(QT 安装路径)\\5.12.10\\msvc2017_64\\bin\\designer.exe, 并设置为默认值即可. 编译运行时报错: 1This application failed to start because it could not find or load the Qt platform plugin &quot;windows&quot; in &quot;&quot;. 可能是相关 dll 库文件没有加载成功, 将 Qt5Core.dll,Qt5Gui.dll,Qt5Widgets.dll 复制到生成的可执行文件所在路径即可. VS2017+Qt5.12 编译报错 E2512 功能测试宏的参数必须是简单标识符 的解决方法 vs 编译 报错 E2512 功能测试宏的参数必须是简单标识符 点击这个错误可以定位到出问题的代码, 将文件 #1348-1356# 行改为如下: 12345678910111213#if defined(__cplusplus)#if defined(__clang__)#if QT_HAS_CPP_ATTRIBUTE(clang::fallthrough)# define Q_FALLTHROUGH() [[clang::fallthrough]]#endif#elif defined(__GNUC__)#if QT_HAS_CPP_ATTRIBUTE(gnu::fallthrough)# define Q_FALLTHROUGH() [[gnu::fallthrough]]#endif#elif QT_HAS_CPP_ATTRIBUTE(fallthrough)# define Q_FALLTHROUGH() [[fallthrough]]#endif#endif 生成的程序在其他设备运行 VS+Qt 项目要在其他电脑上运行需要相关 dll 库文件, 其中 qt 相关库可以用 qt 自带的命令windeployqt [*].exe 补全 (注意这里需要在 Qt 自带的Qt 5.12.10(MSVC 2017 64-bit) 里运行，而不能在 cmd 或powershell里运行)，而其他运行库可以用 VS 自带的 dumpbin 命令检索到:dumpbin /IMPORTS [*]exe &gt; output.txt，然后再找到相关文件复制到 exe 所在路径. qt5+vs2017 程序打包发布，在其他电脑上运行 Qt 程序打包发布总结 Reference Qt 教程，Qt5 编程入门教程（非常详细）- C 语言中文网 QTCN 论坛 Qt 5 攻略 无法打开源文件 QtWidgets/QApplication QT 在 VS 环境下双击 *.ui 打不开 Qt designer(Qt 设计师)的解决方法","link":"/blogs/qt/"},{"title":"Point Cloud Library","text":"软件 版本号 文件名 os windows10-x64 - Visual Studio VS2017 - PCL PCL-1.8.1 PCL-1.8.1-AllInOne-msvc2017-win64.exe; pcl-1.8.1-pdb-msvc2017-win64.zip Download从官方 github 仓库 Point Cloud Library - Github Release 下载两个文件: PCL-1.8.1-AllInOne-msvc2017-win64.exe pcl-1.8.1-pdb-msvc2017-win64.zip 参考 windows 系统下 PCL 的安装与配置 Install 双击 PCL-1.8.1-AllInOne-msvc2017-win64.exe 文件进行安装,建议勾选 Add PCl to the system PATH for all users. 安装位置为 D:\\PCL\\. 安装时会顺带安装一些第三方库到子目录3rdParty 下 安装过程中会弹出一个第三方库 OpenNI2 的安装: OpenNI 2.2 SDK for Windows 64-bit Setup，建议设置路径到子目录 3rdParty 下.最终在 D:\\PCL\\3rdParty\\ 路径下有: Boost,Eigen,FLANN,OpenNI2,Qhull,VTK共 6 个第三方库.其中 VTK 库是”万恶之源”, 会导致后续许多 bug. 网上有的帖子建议删除 PCL 自带的 VTK, 转而通过源码自行编译, 待议! 将 pcl-1.8.1-pdb-msvc2017-win64.zip 解压后的所有 *.pdb 文件复制到 D:\\PCL\\bin\\ 路径下. Configure安装完成后需要对系统以及 VS2017 进行适当的配置才能成功使用PCL. 之前安装过程中如果勾选了 Add PCl to the system PATH for all users, 那么在系统变量中应当会有一个名为: PCL_ROOT, 值为: D:\\PCL 的系统变量. 如果没有, 自行添加也可以:系统属性 -&gt; 环境变量 -&gt; 系统变量 -&gt; 新建 -&gt; .... 新建 VS2017 项目 在 VS2017 中添加用户宏: 视图 (V) -&gt; 其他窗口 (E) -&gt; 属性管理器 (M) -&gt; Debug | x64 -&gt; Microsoft.Cpp.x64.user -&gt; 用户宏 -&gt; 添加宏 -&gt; 名称:PCL_3rdParty_ROOTDIR, 值:D:\\PCL\\3rdParty, 勾选 将此宏设置为生成环境中的环境变量. 添加头文件目录 C/C++ -&gt; 常规 -&gt; 附加包含目录 1234567$(PCL_ROOT)\\include\\pcl-1.8$(PCL_3rdParty_ROOTDIR)\\Boost\\include\\boost-1_64$(PCL_3rdParty_ROOTDIR)\\Eigen\\eigen3$(PCL_3rdParty_ROOTDIR)\\FLANN\\include$(PCL_3rdParty_ROOTDIR)\\OpenNI2\\Include$(PCL_3rdParty_ROOTDIR)\\Qhull\\include$(PCL_3rdParty_ROOTDIR)\\VTK\\include\\vtk-8.0 添加 lib 文件目录 链接器 -&gt; 常规 -&gt; 附加库目录 123456$(PCL_ROOT)\\lib$(PCL_3rdParty_ROOTDIR)\\Boost\\lib$(PCL_3rdParty_ROOTDIR)\\FLANN\\lib$(PCL_3rdParty_ROOTDIR)\\OpenNI2\\Lib$(PCL_3rdParty_ROOTDIR)\\Qhull\\lib$(PCL_3rdParty_ROOTDIR)\\VTK\\lib Note: 这里 Eigen 没有附加库 添加 lib 文件名 链接器 -&gt; 输入 -&gt; 附加依赖项 需要添加的 *.lib 文件名太多了, 这里参考 VS 中 PCL 库附加依赖项配置 - 博客园 通过批处理程序来完成. 在 D:\\PCL 下新建一个批处理文件echo.bat, 双击运行该文件, 将所有 lib 文件名分为 debug 和 release 两类, 并写入两个文本文件内. 对于不同版本的软件，也许文件名会不同, 需要仔细核实匹配字符串与对应路径下的文件是否匹配. echo.bat 文件如下 123456789101112131415161718192021222324252627282930313233343536@echo offecho &quot;all *.lib files:&quot;&gt; lib_all.txtecho &quot;all *.lib files for debug:&quot;&gt; lib_debug.txtecho &quot;all *.lib files for release:&quot;&gt; lib_release.txtrem lib files of pclfor %%I in (lib/*.lib) do echo %%I&gt;&gt;lib_all.txt % 解释：对每一个(*.lib) 通配符匹配到的文件名 I，显示 I 到文件 all.txt，之后的语句类似理解就可 %for %%I in (lib/*debug.lib) do echo %%I&gt;&gt;lib_debug.txtfor %%I in (lib/*release.lib) do echo %%I&gt;&gt;lib_release.txtrem lib files of Boostfor %%I in (3rdParty/Boost/lib/*.lib) do echo %%I&gt;&gt;lib_all.txtfor %%I in (3rdParty/Boost/lib/*mt-gd-1_64.lib) do echo %%I&gt;&gt;lib_debug.txtfor %%I in (3rdParty/Boost/lib/*mt-1_64.lib) do echo %%I&gt;&gt;lib_release.txtrem lib files of Qhullfor %%I in (3rdParty/Qhull/lib/*.lib) do echo %%I&gt;&gt;lib_all.txtfor %%I in (3rdParty/Qhull/lib/*_d.lib) do echo %%I&gt;&gt;lib_debug.txtfor %%I in (3rdParty/Qhull/lib/*l.lib) do echo %%I&gt;&gt;lib_release.txtfor %%I in (3rdParty/Qhull/lib/*p.lib) do echo %%I&gt;&gt;lib_release.txtfor %%I in (3rdParty/Qhull/lib/*r.lib) do echo %%I&gt;&gt;lib_release.txtfor %%I in (3rdParty/Qhull/lib/*c.lib) do echo %%I&gt;&gt;lib_release.txtrem lib files of VTKfor %%I in (3rdParty/VTK/lib/*.lib) do echo %%I&gt;&gt;lib_all.txtfor %%I in (3rdParty/VTK/lib/*-gd.lib) do echo %%I&gt;&gt;lib_debug.txtfor %%I in (3rdParty/VTK/lib/*8.0.lib) do echo %%I&gt;&gt;lib_release.txtfor %%I in (3rdParty/VTK/lib/*c++.lib) do echo %%I&gt;&gt;lib_release.txtrem lib files of FLANNfor %%I in (3rdParty/FLANN/lib/*.lib) do echo %%I&gt;&gt;lib_all.txtfor %%I in (3rdParty/FLANN/lib/*-gd.lib) do echo %%I&gt;&gt;lib_debug.txtfor %%I in (3rdParty/FLANN/lib/*n.lib) do echo %%I&gt;&gt;lib_release.txtfor %%I in (3rdParty/FLANN/lib/*p.lib) do echo %%I&gt;&gt;lib_release.txtfor %%I in (3rdParty/FLANN/lib/*s.lib) do echo %%I&gt;&gt;lib_release.txtrem lib files of OPENNI2for %%I in (3rdParty/OpenNI2/Lib/*.lib) do echo %%I&gt;&gt;lib_all.txtfor %%I in (3rdParty/OpenNI2/Lib/*.lib) do echo %%I&gt;&gt;lib_debug.txtfor %%I in (3rdParty/OpenNI2/Lib/*.lib) do echo %%I&gt;&gt;lib_release.txtrem pause 添加 DLL将如下路径下的所有 *.dll 文件复制到新建目录 dll\\ 路径下:12345$(PCL_ROOT)\\bin$(PCL_3rdParty_ROOTDIR)\\Qhull\\bin$(PCL_3rdParty_ROOTDIR)\\FLANN\\bin$(PCL_3rdParty_ROOTDIR)\\VTK\\bin$(PCL_3rdParty_ROOTDIR)\\OpenNI2\\Tools 并将该路径添加到 VS2017 的项目环境下.在 解决方案资源管理器 右击项目名 -&gt;属性 -&gt; 调试 -&gt; 环境-&gt;PATH=.\\dll;%PATH%. 或者参考 pcl1.8.0+vs2013 环境配置（详细）- CSDN 将以下路径添加到系统路径中,系统属性 -&gt; 环境变量 -&gt; 系统变量 -&gt; Path -&gt; 编辑 -&gt; 添加 12345;%PCL_ROOT%\\bin;%PCL_ROOT%\\3rdParty\\Qhull\\bin;%PCL_ROOT%\\3rdParty\\FLANN\\bin;%PCL_ROOT%\\3rdParty\\VTK\\bin;%PCL_ROOT%\\3rdParty\\OpenNI2\\Tools 属性配置好以后，可以右键属性表，将其保存，以后用的时候直接”添加现有属性表”就可以，不用每次使用 PCL 都重新配置了 Test1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// main.cpp#include &lt;iostream&gt;#include &lt;pcl/common/common_headers.h&gt;#include &lt;pcl/io/pcd_io.h&gt;#include &lt;pcl/visualization/pcl_visualizer.h&gt;#include &lt;pcl/visualization/cloud_viewer.h&gt;#include &lt;pcl/console/parse.h&gt;int main(int argc, char **argv) { std::cout &lt;&lt; &quot;Test PCL !!!&quot; &lt;&lt; std::endl; pcl::PointCloud&lt;pcl::PointXYZRGB&gt;::Ptr point_cloud_ptr(new pcl::PointCloud&lt;pcl::PointXYZRGB&gt;); uint8_t r(255), g(15), b(15); for (float z(-1.0); z &lt;= 1.0; z += 0.05) { for (float angle(0.0); angle &lt;= 360.0; angle += 5.0) { pcl::PointXYZRGB point; point.x = 0.5 * cosf(pcl::deg2rad(angle)); point.y = sinf(pcl::deg2rad(angle)); point.z = z; uint32_t rgb = (static_cast&lt;uint32_t&gt;(r) &lt;&lt; 16 | static_cast&lt;uint32_t&gt;(g) &lt;&lt; 8 | static_cast&lt;uint32_t&gt;(b)); point.rgb = *reinterpret_cast&lt;float*&gt;(&amp;rgb); point_cloud_ptr-&gt;points.push_back(point); } if (z &lt; 0.0) { r -= 12; g += 12; } else { g -= 12; b += 12; } } point_cloud_ptr-&gt;width = (int)point_cloud_ptr-&gt;points.size(); point_cloud_ptr-&gt;height = 1; pcl::visualization::CloudViewer viewer(&quot;test&quot;); viewer.showCloud(point_cloud_ptr); while (!viewer.wasStopped()) {}; return 0;} 踩坑 错误 C4996 严重性 代码 说明 项目 文件 行 禁止显示状态 错误 C4996 ‘std::fpos&lt;_Mbstatet&gt;::seekpos’: warning STL4019: The member std::fpos::seekpos() is non-Standard, and is preserved only for compatibility with workarounds for old versions of Visual C++. It will be removed in a future release, and in this release always returns 0. Please use standards-conforming mechanisms to manipulate fpos, such as conversions to and from streamoff, or an integral type, instead. If you are receiving this message while compiling Boost.IOStreams, a fix has been submitted upstream to make Boost use standards-conforming mechanisms, as it does for other compilers. You can define _SILENCE_FPOS_SEEKPOS_DEPRECATION_WARNING to acknowledge that you have received this warning, or define _REMOVE_FPOS_SEEKPOS to remove std::fpos::seekpos entirely. demo_Proj d:\\pcl\\3rdparty\\boost\\include\\boost-1_64\\boost\\iostreams\\positioning.hpp 96 解决办法: 属性 -&gt; 配置属性 -&gt; C/C++ -&gt; 高级 -&gt; 禁用特定警告 -&gt; 4996;. 也可以关闭 SDL 检查 来解决这一问题: 属性 -&gt; 配置属性 -&gt; C/C++ -&gt; 常规 -&gt; SDL 检查: 否(/sdl-) no override found for ‘vtkPolyDataMapper’ 参考:https://github.com/PointCloudLibrary/pcl/issues/1797 将 $(PCL_3rdParty_ROOTDIR)\\OpenNI2\\Samples\\SimpleViewer\\ 添加到 附加包含目录 , 该路径下有头文件GL/glut.h 需要在源文件中包含; 该路径下的 glut32.lib 需要链接到 附加库 ; 对应的glut32.dll 文件复制到相应的位置.在主程序最开始的地方添加如下代码段: 1234#include &lt;GL/glut.h&gt;#include &lt;vtkAutoInit.h&gt;VTK_MODULE_INIT(vtkRenderingOpenGL);VTK_MODULE_INIT(vtkInteractionStyle); 运行 PCL 代码出现 C2988,C2143,C2913 等错误的解决方法 运行 PCL 代码出现 C2988,C2143,C2913 等错误的解决方法 PCL 点云格式转换ply 文件可以用 windows 自带的 3d 查看器打开,pcd 文件可以用 CloudViewer 打开 这是目标工件生产时参考的标准 ply 模型文件, 通过 pcl 工具转换为 pcd 文件 12345678910111213.\\pcl_mesh_sampling_release.exe ..\\model.ply ..\\model.pcdConvert a CAD model to a point cloud using uniform sampling. For more information, use: D:\\PCL\\bin\\pcl_mesh_sampling_release.exe -hSyntax is: D:\\PCL\\bin\\pcl_mesh_sampling_release.exe input.{ply,obj} output.pcd &lt;options&gt; where options are: -n_samples X = number of samples (default: 100000) -leaf_size X = the XYZ leaf size for the VoxelGrid -- for data reduction (default: 0.010000 m) -write_normals = flag to write normals to the output pcd -no_vis_result = flag to stop visualizing the generated pcd(base) PS D:\\PCL\\bin&gt; .\\pcl_mesh_sampling_release.exe ..\\model.ply ..\\model.pcd -leaf_size 0.001 补充说明 : 我一开始在命令行中运行pcl_mesh_sampling_release.exe 时，命令行直接毫无显示，也没报错。双击该可执行文件时弹窗说找不到 OpenNI2.dll，于是把该文件拷贝到 pcl_mesh_sampling_release.exe 同一路径下，就可以在命令行中执行转换了。 参考 PCL 从 CAD 模型（STL，OBJ） 采样得到点云 （renderViewTesselatedSphere 函数详解） PCL 学习（二）三维模型转点云 obj 转 pcd—-PCL 实现 3d 模型如何生成点云数据？ - ZOUZOU 的回答 - 知乎 Reference windows 系统下 PCL 的安装与配置 https://github.com/PointCloudLibrary/pcl/issues/1797 pcl::visualization::PCLVisualizer::addSphere 运行报错“no override found for ‘vtkPolyDataMapper’解决办法参考 Win10+VS2015 环境下安装编译 PCL1.8.1 和 VTK8.0.0（踩坑大全） VS2017 安装 PCL1.8.1 PCL 配置环境 遇到的问题 pcl1.8.0+vs2013 环境配置（详细） 安全开发生命周期检查(SDL, Security Development Lifecycle) windows 安全警告与 SDL 检查 代码段示例 统计滤波: 去除离群点123456789#include &lt;pcl/filters/statistical_outlier_removal.h&gt;pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr cloud_filtered(new pcl::PointCloud&lt;pcl::PointXYZ&gt;);pcl::StatisticalOutlierRemoval&lt;pcl::PointXYZ&gt; sor;sor.setInputCloud(cloud);sor.setMeanK(50);sor.setStddevMulThresh(1.0);sor.filter(*cloud_filtered); 体素滤波: 降采样123456789101112#include &lt;pcl/filters/voxel_grid.h&gt;pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr downsample(pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr cloud){ pcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr cloud_filter(new pcl::PointCloud&lt;pcl::PointXYZ&gt;); pcl::VoxelGrid&lt;pcl::PointXYZ&gt; voxel_filter; voxel_filter.setInputCloud(cloud); float leafsz = 0.3f; voxel_filter.setLeafSize(leafsz, leafsz, leafsz); voxel_filter.filter(*cloud_filter); return cloud_filter;} 可视化123456visualization::PCLVisualizer viewer(&quot;PPF Object Recognition - Results&quot;);viewer.setBackgroundColor(0, 0, 0);viewer.addPointCloud(cloud_scene);viewer.spinOnce(10);visualization::PointCloudColorHandlerRandom&lt;PointXYZ&gt; random_color(cloud_output-&gt;makeShared());viewer.addPointCloud(cloud_output, random_color, mode_name); 平移旋转123456789101112Eigen::Affine3f transform = Eigen::Affine3f::Identity();// Define a translation of 0 meters on the x axis.transform.translation() &lt;&lt; 0.0, 0.0, 0.0;// The same rotation matrix as before; theta radians arround Z axistransform.rotate(Eigen::AngleAxisf(M_PI_2, Eigen::Vector3f::UnitZ()));// Print the transformationstd::cout &lt;&lt; transform.matrix() &lt;&lt; std::endl;// Executing the transformationpcl::PointCloud&lt;pcl::PointXYZ&gt;::Ptr transformed_cloud(new pcl::PointCloud&lt;pcl::PointXYZ&gt;());// You can either apply transform_1 or transform_2; they are the samepcl::transformPointCloud(*cloud, *transformed_cloud, transform); 聚类123456789101112131415161718192021222324252627282930/***********************************************************************************// 提取出最大的点云聚类#include &lt;pcl/kdtree/kdtree.h&gt;#include &lt;pcl/filters/extract_indices.h&gt;#include &lt;pcl/segmentation/extract_clusters.h&gt;typedef pcl::PointXYZ PointT;typedef pcl::PointCloud&lt;PointT&gt; PointCloudT;*************************************************************************************/PointCloudT::Ptr largestClusterCloud(const PointCloudT::Ptr&amp; cloud){ // 为提取点云时使用的搜素对象利用输入点云 cloud_filtered 创建 Kd 树对象 tree。 pcl::search::KdTree&lt;PointT&gt;::Ptr tree(new pcl::search::KdTree&lt;PointT&gt;); tree-&gt;setInputCloud(cloud);// 创建点云索引向量，用于存储实际的点云信息 std::vector&lt;pcl::PointIndices&gt; cluster_indices; pcl::EuclideanClusterExtraction&lt;pcl::PointXYZ&gt; ec; ec.setClusterTolerance(5); // 设置近邻搜索的搜索半径为 5mm ec.setMinClusterSize(1000); // 设置一个聚类需要的最少点数目为 1000 ec.setMaxClusterSize(50000); // 设置一个聚类需要的最大点数目为 50000 ec.setSearchMethod(tree); // 设置点云的搜索机制 ec.setInputCloud(cloud); // 设置原始点云 ec.extract(cluster_indices); // 从点云中提取聚类 clusters have been sorted based on their size (largest one first) if (cluster_indices.size() == 0) { return cloud; } PointCloudT::Ptr cloud_max_cluster(new PointCloudT); pcl::copyPointCloud(*cloud, cluster_indices[0], *cloud_max_cluster); return cloud_max_cluster;} 区域生长分割12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;pcl/point_types.h&gt;#include &lt;pcl/point_cloud.h&gt;#include &lt;pcl/filters/statistical_outlier_removal.h&gt;#include &lt;pcl/filters/voxel_grid.h&gt;#include &lt;pcl/kdtree/kdtree.h&gt;#include &lt;pcl/filters/extract_indices.h&gt;#include &lt;pcl/segmentation/extract_clusters.h&gt;#include &lt;pcl/segmentation/region_growing.h&gt;#include &lt;pcl/search/search.h&gt;#include &lt;pcl/search/kdtree.h&gt;#include &lt;pcl/features/normal_3d.h&gt;#include &lt;pcl/visualization/cloud_viewer.h&gt;// #include &lt;opencv2/opencv.hpp&gt;// #include &lt;ctime&gt; typedef pcl::PointCloud&lt;pcl::PointXYZ&gt; PointCloudT;std::vector&lt;pcl::PointIndices&gt; region_growing_segmentation(const PointCloudT::Ptr&amp; cloud,bool viewflag){pcl::search::Search&lt;pcl::PointXYZ&gt;::Ptr tree(new pcl::search::KdTree&lt;pcl::PointXYZ&gt;);pcl::PointCloud &lt;pcl::Normal&gt;::Ptr normals(new pcl::PointCloud &lt;pcl::Normal&gt;);pcl::NormalEstimation&lt;pcl::PointXYZ, pcl::Normal&gt; normal_estimator;normal_estimator.setSearchMethod(tree);normal_estimator.setInputCloud(cloud);normal_estimator.setKSearch(50);normal_estimator.compute(*normals);pcl::RegionGrowing&lt;pcl::PointXYZ, pcl::Normal&gt; reg;reg.setMinClusterSize(5000);reg.setMaxClusterSize(50000);reg.setSearchMethod(tree);reg.setNumberOfNeighbours(30);reg.setInputCloud(cloud);//reg.setIndices (indices);reg.setInputNormals(normals);reg.setSmoothnessThreshold(6.0 / 180.0 * M_PI);reg.setCurvatureThreshold(6.0);std::vector &lt;pcl::PointIndices&gt; clusters;reg.extract(clusters);// Sort the clusters based on their size (largest one first)std::sort(clusters.rbegin(), clusters.rend(), [](pcl::PointIndices a, pcl::PointIndices b){return a.indices.size()&gt;b.indices.size();});// 按照点数由多到少排序if (viewflag){ pcl::PointCloud &lt;pcl::PointXYZRGB&gt;::Ptr colored_cloud = reg.getColoredCloud(); pcl::visualization::CloudViewer viewer(&quot;Cluster viewer&quot;); viewer.showCloud(colored_cloud); while (!viewer.wasStopped()) { }}return clusters;} 显示多个坐标系 12345678910111213141516171819202122232425262728#include &lt;pcl/visualization/pcl_visualizer.h&gt;/************************************// 调用 addText3D 时需添加该段代码，否则报错 Error:no override found for 'vtkPolyDataMapper'// https://stackoverflow.com/questions/40086584/errorno-override-found-for-vtkpolydatamapper#include &lt;vtkAutoInit.h&gt;VTK_MODULE_INIT(vtkRenderingOpenGL);VTK_MODULE_INIT(vtkInteractionStyle);#pragma comment(lib,&quot;OpenGL32.Lib&quot;)// pcl 中 setCameraPosition 的参数说明// https://blog.csdn.net/nicai41/article/details/98726465// 为了在指定的视角观察点云，设置一个相机位置，其中 pos_[xyz] 表示相机位置,view_[xyz]表示相机视线方向，up_[xyz]表示相机正上方向向量double pos_x, double pos_y, double pos_z,double view_x, double view_y, double view_z,double up_x, double up_y, double up_z,****************************************/// 显示类pcl::visualization::PCLVisualizer CoordinateViewer(&quot;Cloud Viewer&quot;);// 添加坐标系CoordinateViewer.addCoordinateSystem(10, Eigen::Affine3f::Identity());// 用 Affine3f 表示CoordinateViewer.addCoordinateSystem(10, 5, 5, 6);// 用 x,y,z 表示CoordinateViewer.addText3D(&quot;coor 1&quot;, pcl::PointXYZ(5,5,6), 2, 1, 0, 0, &quot;text1&quot;);CoordinateViewer.addCoordinateSystem(10, 4, 4, 4);CoordinateViewer.addPointCloud(point_cloud_ptr);CoordinateViewer.setCameraPosition(10, -10, 3, -10,10,-3, 0.1, -0.1, 1);while (!CoordinateViewer.wasStopped()) { CoordinateViewer.spinOnce();}; 生成简单几何体123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132typedef pcl::PointXYZ PointT;typedef pcl::PointCloud&lt;PointT&gt; PointCloudT;// 构造圆柱体点云PointCloudT::Ptr ConsCylinderCloud(float radius, float height, float d_degree = 0.5,float d_height = 0.05,float d_radius=0.5){ PointCloudT::Ptr cloud(new PointCloudT); for (float x = 0; x &lt;= height; x += d_height) { for (float angle = 0.0; angle &lt;= 360.0; angle += d_degree) { PointT point; point.x = x; point.y = radius * sinf(pcl::deg2rad(angle)); point.z = radius * cosf(pcl::deg2rad(angle)); cloud-&gt;points.push_back(point); } } for (float r = 0; r &lt;= radius; r += d_radius) { for (float angle = 0.0; angle &lt;= 360.0; angle += d_degree) { PointT point; point.x = 0; point.y = r * sinf(pcl::deg2rad(angle)); point.z = r * cosf(pcl::deg2rad(angle)); cloud-&gt;points.push_back(point); } } for (float r = 0; r &lt;= radius; r += d_radius) { for (float angle = 0.0; angle &lt;= 360.0; angle += d_degree) { PointT point; point.x = height; point.y = r * sinf(pcl::deg2rad(angle)); point.z = r * cosf(pcl::deg2rad(angle)); cloud-&gt;points.push_back(point); } } cloud-&gt;width = (int)cloud-&gt;points.size(); cloud-&gt;height = 1; return cloud;}PointCloudT::Ptr ConsCubeCloud(float x_length, float y_width, float z_height, float dx = 0.05, float dy = 0.05, float dz = 0.05){ float length_2 = x_length / 2; float width_2 = y_width / 2; float height_2 = z_height / 2; PointCloudT::Ptr cloud(new PointCloudT); for (float x = -length_2; x &lt;= length_2; x += dx) { for (float y = -width_2; y &lt;= width_2; y += dy) { PointT point_1; point_1.x = x; point_1.y = y; point_1.z = -height_2; PointT point_2; point_2.x = x; point_2.y = y; point_2.z = height_2; cloud-&gt;points.push_back(point_1); cloud-&gt;points.push_back(point_2); } for (float z = -height_2; z &lt;= height_2; z += dz) { PointT point_1; point_1.x = x; point_1.y = -width_2; point_1.z = z; PointT point_2; point_2.x = x; point_2.y = width_2; point_2.z = z; cloud-&gt;points.push_back(point_1); cloud-&gt;points.push_back(point_2); } } for (float y = -width_2; y &lt;= width_2; y += dy) { for (float z = -height_2; z &lt;= height_2; z += dz) { PointT point_1; point_1.x = -length_2; point_1.y = y; point_1.z = z; PointT point_2; point_2.x = length_2; point_2.y = y; point_2.z = z; cloud-&gt;points.push_back(point_1); cloud-&gt;points.push_back(point_2); } } cloud-&gt;width = (int)cloud-&gt;points.size(); cloud-&gt;height = 1; return cloud;}// 构造球体点云PointCloudT::Ptr ConsSphereCloud(float radius, float d_theta=5.0, float d_phi=5.0){ PointCloudT::Ptr cloud(new PointCloudT); for (float theta = 0.0; theta &lt;= 180.0; theta += d_theta) { for (float phi = 0.0; phi &lt;= 360.0; phi += d_phi) { PointT point; point.x = radius * sinf(pcl::deg2rad(theta)) * cosf(pcl::deg2rad(phi)); point.y = radius * sinf(pcl::deg2rad(theta)) * sinf(pcl::deg2rad(phi)); point.z = radius * cosf(pcl::deg2rad(theta)); cloud-&gt;points.push_back(point); } } cloud-&gt;width = (int)cloud-&gt;points.size(); cloud-&gt;height = 1; return cloud;}","link":"/blogs/pcl/"},{"title":"LibTorch 部署 PyTorch 模型","text":"Installing C++ Distributions of PyTorch 模型训练 用 python 来构建模型并用数据集进行训练（略）. 需要注意的是，用于训练的 python 版本的 pytorch 需要和 CPP 版本的 libtorch 版本一致！这里统一用 Stable (1.7.0) 版本. 模型保存 用 TorchScript 将训练好的模型保存为 *.pt 文件，以便通过 CPP 调用. 1234567import torchfrom torchvision.models import resnet18model = resnet18()example = torch.rand(1, 3, 224, 224)traced_script_module = torch.jit.trace(model, example)traced_script_module.save(&quot;./model/model1_resnet18.pt&quot;) 123456789101112131415161718192021import torchimport torchvision.models as modelsfrom PIL import Imageimport numpy as npimage = Image.open(&quot;./images/demo.jpg&quot;) image = image.resize((224, 224),Image.ANTIALIAS)image = np.asarray(image)image = image / 255image = torch.Tensor(image).unsqueeze_(dim=0)image = image.permute((0, 3, 1, 2)).float()model = models.resnet50(pretrained=True)model = model.eval()resnet = torch.jit.trace(model, torch.rand(1,3,224,224))# output=resnet(torch.ones(1,3,224,224))output = resnet(image)max_index = torch.max(output, 1)[1].item()print(max_index) # ImageNet1000 类的类别序resnet.save(&quot;./model/model2_resnet50.pt&quot;) VS2017+libtorch在 官网 选择 Stable (1.7.0)+Windows+LibTorch+C++ / Java+10.2, 下载Release 版本和 Debug 版本. Windows binaries do not support Java. Support is only available for Linux and MacOS. Download here for C++ (Release version):https://download.pytorch.org/libtorch/cu102/libtorch-win-shared-with-deps-1.7.0.zipDownload here for C++ (Debug version):https://download.pytorch.org/libtorch/cu102/libtorch-win-shared-with-deps-debug-1.7.0.zip 配置 下载好 libtorch-win-shared-with-deps-1.7.0.zip 和libtorch-win-shared-with-deps-debug-1.7.0.zip两个文件之后，分别解压到 release 和debug两个文件夹下. 这里先仅使用 Debug 版本. libtorch-win-shared-with-deps-debug-1.7.0.zip压缩包解压后得到如下文件: 123456789101112131415- debug - libtorch - bin - cmake - include - ... - lib - *.lib - *.pdb - *.dll - share - test - build-hash- release - ... LIB在 解决方案资源管理器 右击项目名 -&gt;属性 -&gt; 链接器 -&gt; 常规 -&gt; 附加库目录 : 将 lib 文件夹路径添加到这里: …libtorch\\lib 在解决方案资源管理器 右击项目名 -&gt;属性 -&gt; 链接器 -&gt; 输入 -&gt; 附加依赖项: 将 lib 文件名添加到这里: 1234567891011121314151617181920asmjit.libclog.liblibprotobuf-lited.libc10.libcpuinfo.liblibprotocd.libc10_cuda.libdnnl.libmkldnn.libc10d.libfbgemm.libtorch.libcaffe2_detectron_ops_gpu.libgloo.libtorch_cpu.libcaffe2_module_test_dynamic.libgloo_cuda.libtorch_cuda.libcaffe2_nvrtc.liblibprotobufd.lib INCLUDE在 解决方案资源管理器 右击项目名 -&gt;属性 -&gt;C/C++-&gt; 常规 -&gt; 附加包含目录: 将 include 文件夹路径添加到这里:…libtorch\\include…libtorch\\include\\torch\\csrc\\api\\include 解决提醒 std 冲突问题 在解决方案资源管理器 右击项目名 -&gt;属性 -&gt;C/C++-&gt; 常规 -&gt;SDL 检查-&gt; 否(/sdl-)在 解决方案资源管理器 右击项目名 -&gt;属性 -&gt;C/C++-&gt; 语言 -&gt; 符合模式 -&gt; 否 dll将 libtorch\\lib 文件夹下的所有 dll 文件都复制到解决方案生成的可执行文件 *.exe 文件所在路径.此外，如果是 debug 模式，运行时会报错：找不到 vcruntime140_1d.dll. 其实系统里一定有vcruntime140_1.dll 文件，但是没有用于调试版本的 dll 文件，可以去 &lt;www.dll-files.com&gt; 网站下载: https://www.dll-files.com/vcruntime140_1d.dll.html dll 文件可以直接放在 exe 文件相同路径下，也可以专门放在一个文件夹下，然后将这个文件夹添加到可搜索环境下:在 解决方案资源管理器 右击项目名 -&gt;属性 -&gt; 调试 -&gt; 环境-&gt;PATH=.\\dll;%PATH%. 测试 测试 libtorch1234567#include&lt;iostream&gt;#include&lt;torch/script.h&gt;int main() { torch::Tensor t1 = torch::tensor({ 10,1,2 }); std::cout &lt;&lt; t1[0] &lt;&lt; std::endl; system(&quot;pause&quot;);} 123456789101112//2 个 Tensor 计算矩阵乘法#include&lt;iostream&gt;#include&lt;torch/script.h&gt;int main() { auto t1 = torch::tensor({ 1,2,3,4,5,6,7,8,9 }).reshape({ 3,3 }); auto t2 = torch::tensor({ 1,0,2,6,1,1,5,3,2 }).reshape({ 3,3 }); auto t3 = t1.mul(t2); std::cout &lt;&lt; t3 &lt;&lt; std::endl; system(&quot;pause&quot;);} 模型导入测试1234567891011121314151617181920#include &lt;torch/script.h&gt; // One-stop header.#include &lt;iostream&gt;#include &lt;memory&gt;int main() { // Deserialize the ScriptModule from a file using torch::jit::load(). using torch::jit::script::Module; Module module = torch::jit::load(&quot;./model/model1_resnet18.pt&quot;); std::cout &lt;&lt; &quot;model load success&quot; &lt;&lt; std::endl; // Create a vector of inputs. std::vector&lt;torch::jit::IValue&gt; inputs; inputs.push_back(torch::ones({ 1, 3, 224, 224 })); // Execute the model and turn its output into a tensor. at::Tensor output = module.forward(inputs).toTensor(); std::cout &lt;&lt; output.slice(/*dim=*/1, /*start=*/0, /*end=*/5) &lt;&lt; std::endl; return 0;} 模型预测测试12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;torch/script.h&gt;#include &lt;torch/torch.h&gt;#include &lt;iostream&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui.hpp&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;vector&gt;/**************************************** * 测试模型导入是否成功，并用全零的数据对模型进行测试 ****************************************/void TorchTest() { torch::jit::script::Module module = torch::jit::load(&quot;./model/model2_resnet50.pt&quot;); std::cout &lt;&lt; &quot;Load model successful!&quot; &lt;&lt; std::endl; std::vector&lt;torch::jit::IValue&gt; inputs; inputs.push_back(torch::zeros({ 1, 3, 224, 224 })); at::Tensor output = module.forward(inputs).toTensor(); auto max_result = output.max(1, true); auto max_index = std::get&lt;1&gt;(max_result).item&lt;float&gt;(); std::cout &lt;&lt; max_index &lt;&lt; std::endl;}/**************************************** * 传入图片，对模型进行测试，得到模型预测结果 ****************************************/void Classfier(cv::Mat &amp;image) { torch::Tensor img_tensor = torch::from_blob( image.data, { 1, image.rows, image.cols, 3 }, torch::kByte); img_tensor = img_tensor.permute({ 0, 3, 1, 2 }); img_tensor = img_tensor.toType(torch::kFloat); img_tensor = img_tensor.div(255); torch::jit::script::Module module = torch::jit::load(&quot;./model/model2_resnet50.pt&quot;); torch::Tensor output = module.forward({ img_tensor }).toTensor(); auto max_result = output.max(1, true); auto max_index = std::get&lt;1&gt;(max_result).item&lt;float&gt;(); std::cout &lt;&lt; max_index &lt;&lt; std::endl;}int main() { // 对导入的模型进行简单测试 TorchTest(); // 通过导入的模型进行预测图像分类结果 cv::Mat image = cv::imread(&quot;./images/demo.jpg&quot;); cv::resize(image, image, cv::Size(224, 224)); cv::imshow(&quot;image&quot;, image); cv::waitKey(100); std::cout &lt;&lt; image.rows &lt;&lt; &quot; &quot; &lt;&lt; image.cols &lt;&lt; &quot; &quot; &lt;&lt; image.channels() &lt;&lt; std::endl; Classfier(image); return 0;} Reference 在 C++ 中加载 PYTORCH 模型 在 C++ 部署 Pytorch（Libtorch）模型的方法总结（Win10+VS2017） C++ 部署 Pytorch（Libtorch）出现问题、错误汇总 libtorch 配置 vs2017 www.dll-files.com C++ 利用 LibTorch 调用 pytorch 模型 libtorch - PyTorch 官网 C++ 调用 pytorch，LibTorch 在 win10 下的 vs 配置和 cmake 的配置","link":"/blogs/libtorch/"},{"title":"Umeyama 算法求解相似变换","text":"Kabsch–Umyama 算法是一种对齐和比较两组点之间的相似性的方法。它通过最小化点对的根平方偏差（RMSD）来找到最佳的平移，旋转和缩放。Kabsch(1976,1978) 首先描述了寻找最佳旋转的算法。Umeyama(1991) 提出了类似方法，该方法除旋转外还支持平移和缩放。 求 $c$, $\\mathbf{R}$, $\\mathbf{t}$ 使得下式最小:$$ \\frac{1}{n} \\sum_{i=1}^n \\vert\\vert y_i - (c\\mathbf{R}x_i + \\mathbf{t}) \\vert\\vert_2^2$$ 注: 该问题与 Fusiello(2015) 附录 A 中提到的扩展正交普氏分析 (Extended Orthogonal Procrustes Analysis) 实际上是同一概念。 相关文献 Kabsch, W. (1976). “A solution for the best rotation to relate two sets of vectors”. Acta Crystallographica. A32 (5): 922–923. doi:10.1107/S0567739476001873. Kabsch, W. (1978). “A discussion of the solution for the best rotation to relate two sets of vectors”. Acta Crystallographica. A34 (5): 827–828. doi:10.1107/S0567739478001680 Umeyama, S. (1991). “Least-squares estimation of transformation parameters between two point patterns”. IEEE Transactions on Pattern Analysis and Machine Intelligence. 13 (4): 376–380. doi:10.1109/34.88573. Lawrence, J. , Bernal, J. and Witzgall, C. (2019). “A Purely Algebraic Justification of the Kabsch-Umeyama Algorithm”. Journal of Research (NIST JRES), National Institute of Standards and Technology, Gaithersburg, MD. doi:10.6028/jres.124.028 A. Fusiello, F. Crosilla and F. Malapelle, “Procrustean Point-Line Registration and the NPnP Problem,” 2015 International Conference on 3D Vision, 2015, pp. 250-255, doi:10.1109/3DV.2015.35. 其他博客 Aligning point patterns with Kabsch–Umeyama algorithm Umeyama 算法 - 微博 算法实现 evo/evo/core/geometry.py#umeyama_alignment Eigen Documentation &gt;&gt; Eigen::umeyama() Eigen::umeyama 函数实现: Eigen\\src\\Geometry\\Umeyama.h https://gitlab.com/libeigen/eigen/-/blob/master/Eigen/src/Geometry/Umeyama.h#L95-L164 调用 Eigen::umeyama(): rigid_transformation3D_srt.cpp 刚体变换 (不支持缩放): https://github.com/cgraumann/umeyama-matlab 代码 C++ EigenEigen/src/Geometry/Umeyama.h >foldedlink123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169// This file is part of Eigen, a lightweight C++ template library// for linear algebra.//// Copyright (C) 2009 Hauke Heibel &lt;hauke.heibel@gmail.com&gt;//// This Source Code Form is subject to the terms of the Mozilla// Public License v. 2.0. If a copy of the MPL was not distributed// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.#ifndef EIGEN_UMEYAMA_H#define EIGEN_UMEYAMA_H// This file requires the user to include // * Eigen/Core// * Eigen/LU // * Eigen/SVD// * Eigen/Array#include &quot;./InternalHeaderCheck.h&quot;namespace Eigen { #ifndef EIGEN_PARSED_BY_DOXYGEN// These helpers are required since it allows to use mixed types as parameters// for the Umeyama. The problem with mixed parameters is that the return type// cannot trivially be deduced when float and double types are mixed.namespace internal {// Compile time return type deduction for different MatrixBase types.// Different means here different alignment and parameters but the same underlying// real scalar type.template&lt;typename MatrixType, typename OtherMatrixType&gt;struct umeyama_transform_matrix_type{ enum { MinRowsAtCompileTime = internal::min_size_prefer_dynamic(MatrixType::RowsAtCompileTime, OtherMatrixType::RowsAtCompileTime), // When possible we want to choose some small fixed size value since the result // is likely to fit on the stack. So here, min_size_prefer_dynamic is not what we want. HomogeneousDimension = int(MinRowsAtCompileTime) == Dynamic ? Dynamic : int(MinRowsAtCompileTime)+1 }; typedef Matrix&lt;typename traits&lt;MatrixType&gt;::Scalar, HomogeneousDimension, HomogeneousDimension, AutoAlign | (traits&lt;MatrixType&gt;::Flags &amp; RowMajorBit ? RowMajor : ColMajor), HomogeneousDimension, HomogeneousDimension &gt; type;};}#endif/*** \\geometry_module \\ingroup Geometry_Module** \\brief Returns the transformation between two point sets.** The algorithm is based on:* &quot;Least-squares estimation of transformation parameters between two point patterns&quot;,* Shinji Umeyama, PAMI 1991, DOI: 10.1109/34.88573** It estimates parameters \\f$ c, \\mathbf{R}, \\f$ and \\f$ \\mathbf{t} \\f$ such that* \\f{align*}* \\frac{1}{n} \\sum_{i=1}^n \\vert\\vert y_i - (c\\mathbf{R}x_i + \\mathbf{t}) \\vert\\vert_2^2* \\f}* is minimized.** The algorithm is based on the analysis of the covariance matrix* \\f$ \\Sigma_{\\mathbf{x}\\mathbf{y}} \\in \\mathbb{R}^{d \\times d} \\f$* of the input point sets \\f$ \\mathbf{x} \\f$ and \\f$ \\mathbf{y} \\f$ where * \\f$d\\f$ is corresponding to the dimension (which is typically small).* The analysis is involving the SVD having a complexity of \\f$O(d^3)\\f$* though the actual computational effort lies in the covariance* matrix computation which has an asymptotic lower bound of \\f$O(dm)\\f$ when * the input point sets have dimension \\f$d \\times m\\f$.** Currently the method is working only for floating point matrices.** \\todo Should the return type of umeyama() become a Transform?** \\param src Source points \\f$ \\mathbf{x} = \\left(x_1, \\hdots, x_n \\right) \\f$.* \\param dst Destination points \\f$ \\mathbf{y} = \\left(y_1, \\hdots, y_n \\right) \\f$.* \\param with_scaling Sets \\f$ c=1 \\f$ when &lt;code&gt;false&lt;/code&gt; is passed.* \\return The homogeneous transformation * \\f{align*}* T = \\begin{bmatrix} c\\mathbf{R} &amp; \\mathbf{t} \\\\ \\mathbf{0} &amp; 1 \\end{bmatrix}* \\f}* minimizing the residual above. This transformation is always returned as an * Eigen::Matrix.*/template &lt;typename Derived, typename OtherDerived&gt;typename internal::umeyama_transform_matrix_type&lt;Derived, OtherDerived&gt;::typeumeyama(const MatrixBase&lt;Derived&gt;&amp; src, const MatrixBase&lt;OtherDerived&gt;&amp; dst, bool with_scaling = true){ typedef typename internal::umeyama_transform_matrix_type&lt;Derived, OtherDerived&gt;::type TransformationMatrixType; typedef typename internal::traits&lt;TransformationMatrixType&gt;::Scalar Scalar; typedef typename NumTraits&lt;Scalar&gt;::Real RealScalar; EIGEN_STATIC_ASSERT(!NumTraits&lt;Scalar&gt;::IsComplex, NUMERIC_TYPE_MUST_BE_REAL) EIGEN_STATIC_ASSERT((internal::is_same&lt;Scalar, typename internal::traits&lt;OtherDerived&gt;::Scalar&gt;::value), YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_EXPLICITLY) enum { Dimension = internal::min_size_prefer_dynamic(Derived::RowsAtCompileTime, OtherDerived::RowsAtCompileTime) }; typedef Matrix&lt;Scalar, Dimension, 1&gt; VectorType; typedef Matrix&lt;Scalar, Dimension, Dimension&gt; MatrixType; typedef typename internal::plain_matrix_type_row_major&lt;Derived&gt;::type RowMajorMatrixType; const Index m = src.rows(); // dimension const Index n = src.cols(); // number of measurements // required for demeaning ... const RealScalar one_over_n = RealScalar(1) / static_cast&lt;RealScalar&gt;(n); // computation of mean const VectorType src_mean = src.rowwise().sum() * one_over_n; const VectorType dst_mean = dst.rowwise().sum() * one_over_n; // demeaning of src and dst points const RowMajorMatrixType src_demean = src.colwise() - src_mean; const RowMajorMatrixType dst_demean = dst.colwise() - dst_mean; // Eq. (38) const MatrixType sigma = one_over_n * dst_demean * src_demean.transpose(); JacobiSVD&lt;MatrixType, ComputeFullU | ComputeFullV&gt; svd(sigma); // Initialize the resulting transformation with an identity matrix... TransformationMatrixType Rt = TransformationMatrixType::Identity(m+1,m+1); // Eq. (39) VectorType S = VectorType::Ones(m); if (svd.matrixU().determinant() * svd.matrixV().determinant() &lt; 0 ) S(m-1) = -1; // Eq. (40) and (43) Rt.block(0,0,m,m).noalias() = svd.matrixU() * S.asDiagonal() * svd.matrixV().transpose(); if (with_scaling) { // Eq. (36)-(37) const Scalar src_var = src_demean.rowwise().squaredNorm().sum() * one_over_n; // Eq. (42) const Scalar c = Scalar(1)/src_var * svd.singularValues().dot(S); // Eq. (41) Rt.col(m).head(m) = dst_mean; Rt.col(m).head(m).noalias() -= c*Rt.topLeftCorner(m,m)*src_mean; Rt.block(0,0,m,m) *= c; } else { Rt.col(m).head(m) = dst_mean; Rt.col(m).head(m).noalias() -= Rt.topLeftCorner(m,m)*src_mean; } return Rt;}} // end namespace Eigen#endif // EIGEN_UMEYAMA_H C++ OpenCVestimateRigidTransform3D_srt()>folded1234567891011121314151617181920212223242526272829303132333435363738// 计算多个三维点对之间的最优相似变换矩阵 // estimate R,t s.t. a*R*src + t = dst// src,dst 为 n 行 3 列矩阵, 每行都是一个点的三维坐标 // 如果 scale==1, 则默认没有缩放, 缩放为 1; 否则使用估计的缩放因子 // https://www.cnblogs.com/wqj1212/p/3915859.html// https://github.com/opencv/opencv/blob/478663b08c2050546d06b4d3586386954343f80b/modules/video/include/opencv2/video/tracking.hpp#L258// https://github.com/opencv/opencv/blob/828304d587b3a204ebc34ce8573c3adec5a41ad2/modules/video/src/lkpyramid.cpp#L1508double estimateRigidTransform3D_srt(const cv::Mat&amp; src, const cv::Mat&amp; dst, double scale, cv::Mat&amp; R, cv::Mat&amp; t){ CV_Assert(src.rows == dst.rows); CV_Assert((src.cols == 3) &amp;&amp; (dst.cols == 3)); int n = src.rows; cv::Mat e = cv::Mat::ones(n, 1, CV_64F); cv::Mat II = cv::Mat::eye(n, n, CV_64F) - cv::Mat::ones(n, n, CV_64F) / n; cv::Mat U, Sigma, Vt; cv::SVD::compute(dst.t()*II*src, Sigma, U, Vt); cv::Mat Sigma_det = cv::Mat::eye(3, 3, CV_64F); Sigma_det.at&lt;double&gt;(2, 2) = cv::determinant(U*Vt); R = U * Sigma_det*Vt; cv::Mat AR = dst * R; double a; if (scale == 1) { a = 1; } else { a = cv::trace(dst.t()*II*dst).val[0] / cv::trace(AR.t()*II*src).val[0]; } cv::Mat c_trans; cv::reduce(a*src - AR, c_trans, 0, CV_REDUCE_AVG);// 逐列求均值 cv::Mat c = c_trans.t(); t = -R * c; cv::Mat Y = a * src - dst * R - e * c_trans; double err = cv::norm(Y) / sqrt(n); return err;} Pythonumeyama.py >foldedlink123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# umeyama function from scikit-image/skimage/transform/_geometric.pyimport numpy as npdef umeyama( src, dst, estimate_scale ): &quot;&quot;&quot;Estimate N-D similarity transformation with or without scaling. Parameters ---------- src : (M, N) array Source coordinates. dst : (M, N) array Destination coordinates. estimate_scale : bool Whether to estimate scaling factor. Returns ------- T : (N + 1, N + 1) The homogeneous similarity transformation matrix. The matrix contains NaN values only if the problem is not well-conditioned. References ---------- .. [1] &quot;Least-squares estimation of transformation parameters between two point patterns&quot;, Shinji Umeyama, PAMI 1991, DOI: 10.1109/34.88573 &quot;&quot;&quot; num = src.shape[0] dim = src.shape[1] # Compute mean of src and dst. src_mean = src.mean(axis=0) dst_mean = dst.mean(axis=0) # Subtract mean from src and dst. src_demean = src - src_mean dst_demean = dst - dst_mean # Eq. (38). A = np.dot(dst_demean.T, src_demean) / num # Eq. (39). d = np.ones((dim,), dtype=np.double) if np.linalg.det(A) &lt; 0: d[dim - 1] = -1 T = np.eye(dim + 1, dtype=np.double) U, S, V = np.linalg.svd(A) # Eq. (40) and (43). rank = np.linalg.matrix_rank(A) if rank == 0: return np.nan * T elif rank == dim - 1: if np.linalg.det(U) * np.linalg.det(V) &gt; 0: T[:dim, :dim] = np.dot(U, V) else: s = d[dim - 1] d[dim - 1] = -1 T[:dim, :dim] = np.dot(U, np.dot(np.diag(d), V)) d[dim - 1] = s else: T[:dim, :dim] = np.dot(U, np.dot(np.diag(d), V.T)) if estimate_scale: # Eq. (41) and (42). scale = 1.0 / src_demean.var(axis=0).sum() * np.dot(S, d) else: scale = 1.0 T[:dim, dim] = dst_mean - scale * np.dot(T[:dim, :dim], src_mean.T) T[:dim, :dim] *= scale return T MatlabestimateRigidTransform3D_srt.m >folded1234567891011121314151617181920212223242526272829303132333435363738394041424344% initclc;clear;close all;%% Test 坐标系 A 坐标系 Bpoint_A = [0, -2.14185, -1.1497 0,-1.6855,-1.1068 -0.24,-1.6905,-1.0969 0,-0.473,-1.146]point_B = [-0.9121385,-0.5697752,1.051605 -0.4756734,-0.5859144,1.152362 -0.5229784,-0.6114097,1.401835 0.6978357,-0.5654929,1.69446][n,~] = size(point_A)[R,t] = estimateRigidTransform3D_srt(point_A, point_B)error = R*point_A.' + t*ones(1,n) - point_B.'err = vecnorm(error)figure(1);S_transformed = R*point_A.' + t*ones(1,n);S_transformed = S_transformed.';plot3(point_A(:,1),point_A(:,2),point_A(:,3),'bd','MarkerSize',5);hold on;plot3(point_B(:,1),point_B(:,2),point_B(:,3),'bd','MarkerSize',5);hold on;plot3(S_transformed(:,1),S_transformed(:,2),S_transformed(:,3),'b*','MarkerSize',5);hold on;grid on;axis square;%% implementfunction [R, t, a] = estimateRigidTransform3D_srt(Src, Dst)% same usage as gPPnPunit_scale = (nargout &lt;3);n = size(Src,1);e = ones(n,1); II = eye(n)-((e*e')./n);[U,~,V] = svd((Dst)'*II*Src);R=U*[1 0 0; 0 1 0; 0 0 det(U*V')]*V';A = Dst; AR=A*R;if unit_scale a=1;else a = trace((A)'*II*(A))/trace(AR'*II*Src);endc = mean((a*Src-AR),1)';t = -R*c;end","link":"/blogs/umeyama/"},{"title":"Tips","text":"各类操作技巧整理 PowerShell 安装 Pscx 插件以支持命令行的完整功能, 例如 指定文件树深度 Pscx 插件官网 Win10 Powershell 实现类似 Linux 指定 tree 命令展示深度 安装 Pscx 插件1&gt; Install-Module -Name Pscx -RequiredVersion 3.2.2 -Scope CurrentUser -AllowClobber 该插件支持了一个比较完整的 tree 指令，查看文件树可以指定深度 12&gt; Show-Tree [[-Path] &lt;String[]&gt;] [[-Depth] &lt;Int32&gt;] # 命令用法&gt; Show-Tree dir -Depth 2 # 命令示例 Linux 中给 coreutils 打补丁，使得执行 cp 和 mv 指令时可以显示 进度条 给 cp 和 mv 命令添加进度条 12345678910111213141516171819# 注意尽量不要使用 root 用户操作# 下载 coreutils$ wget http://ftp.gnu.org/gnu/coreutils/coreutils-8.32.tar.xz$ tar -xJf coreutils-8.32.tar.xz$ cd coreutils-8.32/# 下载 github 上的补丁$ wget https://raw.githubusercontent.com/jarun/advcpmv/master/advcpmv-0.8-8.32.patch# 打补丁，实现进度条显示$ patch -p1 -i advcpmv-0.8-8.32.patchpatching file src/copy.cpatching file src/copy.hpatching file src/cp.cpatching file src/mv.c# 编译安装$ ./configure$ make# 将打补丁生成的 cp 和 mv 命令的二进制文件复制到 bin 目录下$ sudo cp src/cp /usr/local/bin/cp$ sudo cp src/mv /usr/local/bin/mv 接着只需要在使用 cp 和 mv 命令的时候加上 -g 参数就可以显示进度条了 为了方便起见可以在 ~/.bashrc 文件中设置 alias 12alias cp='cp -ig'alias mv='mv -ig' ubuntu 设置屏幕分辨率1$ xrandr --auto --output HDMI-0 --pos 0x0 --mode 3840x2160 --primary 将该命令加入开机启动项 12$ gnome-session-properties# 然后点击添加, 输入名称，命令，注释即可. Ubuntu 安装 hack 字体 1234567891011wget https://github.com/source-foundry/Hack/releases/download/v3.003/Hack-v3.003-ttf.zip # 下载字体文件unzip Hack-v3.003-ttf.zipsudo cp -r ttf/ /usr/share/fonts/# 下载字体配置文件sudo wget -O /etc/fonts/conf.d/45-Hack.conf https://raw.githubusercontent.com/source-foundry/Hack/master/config/fontconfig/45-Hack.conffc-cache -f -v # 清除并重新生成字体缓存和索引# fc-cache: succeeded # 终端如此显示表示刷新成功fc-list | grep &quot;Hack&quot; # 检查是否安装成功# 删除文件rm -rf ttf/rm Hack-v3.003-ttf.zip ubuntu 安装 Hack 字体 Hack 官网 source-foundry/Hack - Github 在 VS Code 中配置使用 Hack 字体 在Settings-&gt;Editor: Font Family 中修改为如下内容 1Hack, 'monospace', monospace Visual Studio 相关配置 无法查找或打开 PDB 文件 工具 -&gt; 选项 -&gt; 调试 -&gt; 常规 -&gt; 勾选 启用源服务器支持 工具 -&gt; 选项 -&gt; 调试 -&gt; 符号-&gt; 勾选 Microsoft 符号服务器 VS“无法查找或打开 PDB 文件”是怎么回事？如何解决 SDL 检查 Visual Studio 开启了 SDL 检查后，某些警告会成为错误，使程序编译不通过. 关闭SDL 检查: 属性 -&gt; 配置属性 -&gt; C/C++ -&gt; 常规 -&gt; SDL 检查: 否(/sdl-) 安全开发生命周期检查(SDL, Security Development Lifecycle) windows 安全警告与 SDL 检查 属性表文件 创建属性表 视图 -&gt; 其他窗口 -&gt; 属性管理器 -&gt;Debug|64-&gt; 右键: 添加新项目属性表 -&gt; 右键该属性表: 属性-&gt;... 导入属性表 视图 -&gt; 其他窗口 -&gt; 属性管理器 -&gt;Debug|64-&gt; 右键: 添加现有属性表 【新手教程】Visual Studio .props 文件简介 RelWithDebInfo 这种编译模式在保留 Release 模式下运行快速的前提下，又可以给特定的工程开启 Debug 模式，进行针对性的调试。这样比整个项目都采用 Debug 模式进行编译，在调试时会提高效率。 某些工程默认情况下没有配置这种编译模式，可以在 Release 模式下修改如下配置来实现这个效果. 属性 -&gt; 配置属性 -&gt; C/C++ -&gt; 常规 -&gt; 调试信息格式: 程序数据库(/Zi) 属性 -&gt; 配置属性 -&gt; C/C++ -&gt; 优化 -&gt; 优化: 已禁用(/Od) 属性 -&gt; 配置属性 -&gt; C/C++ -&gt; 优化 -&gt; 内联函数扩展: 默认值 属性 -&gt; 配置属性 -&gt; 链接器 -&gt; 调试 -&gt; 生成调试信息: 生成调试信息 (/DEBUG) Visual Studio 在 Release 模式下开启 debug 调试 Markdown以 HTML 格式插入图片并居中1234&lt;div align=center&gt; &lt;img src=&quot;./images/image1.jpg&quot; width=300&gt; &lt;img src=&quot;./images/image1.jpg&quot; width=300&gt;&lt;/div&gt; Windows 无法被 ping 通 原因是 Windows 默认开启了防火墙，可以关闭防火墙使其能够被局域网内其他设备访问，但请确保局域网内所有设备都是可信任的。 Windows 安全中心 -&gt; 防火墙和网络保护 -&gt; 专用网络 -&gt; Microsoft Defender 防火墙: 关闭 vcpkgvcpkg是一个 C++ 包管理工具, 类似于用 pip 来安装 python 的第三方包一样. Install123&gt; git clone https://github.com/Microsoft/vcpkg.git&gt; cd vcpkg&gt; ./bootstrap-vcpkg.bat Usage123&gt; vcpkg search (搜索包)&gt; vcpkg install [pkg-name] (安装包)&gt; vcpkg integrate install (将已安装的包与 Visual Studio 集成) Reference vcpkg：用于 Windows、Linux 和 macOS 的 C++ 包管理器 Vcpkg——C++ 包管理工具 vcpkg install 报错 Could not locate a complete toolset. PowerShell 无法激活 Anaconda 环境?Windows10 PowerShell无法激活 Anaconda 环境，而 CMD 可以。可能是因为 anaconda 没有被写入环境变量，且没有将 anaconda 的终端初始化为 powershell。 首先将与 anaconda 有关的 3 个路径添加到环境变量中。 123D:\\Anaconda3D:\\Anaconda3\\ScriptsD:\\Anaconda3\\Library\\bin How to activate different anaconda environment from powershell 12345678910Although Conda previously did not support PowerShell, this is now resolved in Conda 4.6.After adding `Anaconda3/Scripts/` to your `PATH` variable, you should be able to initialize Conda for use with powershell with: conda init powershellAfterwards, you can use conda normally: conda activate base 解决 Win10 PowerShell 无法激活 Anaconda 环境的问题 查看 conda 版本： 1conda --version conda 4.6以上版本内置了对 PowerShell 的支持，只需初始化一下就好了 管理员模式打开powershell: 1PS C:\\Windows\\system32&gt; conda init powershell 设置路由器当无线交换机使用 如何设置路由器当无线交换机使用 路由器上再接一个路由器如何连接设置【详解】 Matlab导出矢量图 将渲染器设置为 painters 矢量图渲染器。 12set(gcf,'renderer','painters')saveas(gcf,'./filename.pdf','pdf'); 1help saveas 通常，生成向量图形文件时，saveas 会使用 Painters 渲染器。对于一些复杂图窗，saveas 会改用 OpenGL® 渲染器。如果它使用 OpenGL 渲染器，则向量图形文件会包含嵌入式图像，这可能会限制您可在其他应用程序中编辑该图像的程度。此外，如果 saveas 使用 OpenGL 渲染器生成文件，则不支持透明度。要确保 saveas 使用 Painters 渲染器，请将图窗的 Renderer 属性设置为 ‘painters’。 文件 -&gt; 导出设置 -&gt; 渲染 -&gt; 勾选 自定义渲染器 -&gt; painters(向量格式) Matlab 导出图片模糊的解决办法 添加搜索路径12addpath(genpath('dirpath'))savepath 在 VS 中使用 pthread使用 vcpkg 包管理器安装 pthread 并与 VS2017 集成 12vcpkg install pthreadvcpkg integrate install 测试123456789101112131415161718192021222324// main.cpp#include&lt;pthread.h&gt;#include&lt;iostream&gt;#include&lt;Windows.h&gt;void* thread(void* val){ int value = *((int*)val); printf(&quot;value: %d \\n&quot;, value); while (value-- &gt; 0) { std::cout &lt;&lt; value &lt;&lt; std::endl; } return NULL;}int main(){ pthread_t tid; int value = 100; pthread_create(&amp;tid, 0, thread, &amp;value); system(&quot;pause&quot;); return 0;} Reference VS2017 配置使用 pthread.h - CSDN 心如止水_Zen: 还有更简便的方法, 下载 vcpkg 并在 PowerShell 中 cd 到所在目录, 然后执行命令 .\\vcpkg.exe install pthread 在 Visual Studio 2019 中就能直接使用 pthread 了, 不需要其他任何别的设置.","link":"/blogs/tips/"},{"title":"TinyXML2","text":"XML指可扩展标记语言(eXtensible Markup Language), 被设计用来传输和存储数据。 C++语言环境下有许多用于 XML 解析的第三方库，例如 libxml++, TinyXML2 等. awesome-cpp#xml - Github 如何选择合适的 XML 解析库: What XML parser should I use in C++? [closed] - stackoverflow. 其中 TinyXML2 是一个轻量级的 xml 解析库, 只有一个源文件 tinyxml2.cpp 和一个头文件 tinyxml2.h, 十分简单易用. 最简单的调库方法就是把头文件和和源文件添加到自己的工程中一起编译.当然也可以将 TinyXML2 单独编译成链接库供其他工程使用. 下载 从 Github 的 Release 中下载发行版tinyxml2-7.0.1.zip. leethomason/tinyxml2 - Github leethomason/tinyxml2 - Github Release tinyxml2-7.0.1.zip - Github Release 解压后得到如下文件. 1234567891011121314151617181920212223242526272829303132333435363738394041tinyxml2│ appveyor.yml│ readme.md│ tinyxml2.cpp│ tinyxml2.h│ xmltest.cpp│ ... ├─contrib│ html5-printer.cpp ├─docs // 文档│ │ index.html│ │ bc_s.png│ │ bdwn.png│ │ classes.html│ │ classtinyxml2_1_1_x_m_l_attribute-members.html│ │ ...│ └─search│ all_0.html│ all_0.js│ all_1.html│ all_1.js│ all_10.html│ all_10.js│ ... ├─resources│ │ dream.xml│ │ empty.xml│ │ ...│ └─out│ readme.txt └─tinyxml2 │ test.vcxproj │ test.vcxproj.filters │ tinyxml2.sln // 解决方案文件 │ tinyxml2.vcxproj │ tinyxml2.vcxproj.filters ├─tinyxml2-cbp │ README │ tinyxml2-cbp.cbp └─tinyxml2.xcodeproj project.pbxproj 配置 双击其中的 tinyxml2/tinyxml2/tinyxml2.sln 打开解决方案. 初始配置的 SDK 版本也许与本地版本不一致, 因此点击 项目 -&gt; 重定解决方案目标 , 选择已安装的 SDK 版本, 勾选所需项目, 点击 确定. 生成库文件 以Debug版本为例. 在 解决方案配置 下拉框中选择 Debug-Dll, 解决方案平台 选择为x64, 生成解决方案. 然后再将 解决方案配置 下拉框改为 Debug-Lib, 再生成一次. 两次操作会在解决方案文件相同路径下生成bin\\ 文件夹, 如下12345678910111213141516171819202122bin├─test│ ├─x64-Debug-Dll│ │ test.exe│ │ test.ilk│ │ test.pdb│ ││ └─x64-Debug-Lib│ test.exe│ test.ilk│ test.pdb│└─tinyxml2 ├─x64-Debug-Dll │ tinyxml2.dll │ tinyxml2.exp │ tinyxml2.ilk │ tinyxml2.lib │ tinyxml2.pdb │ └─x64-Debug-Lib tinyxml2.lib 测试官方代码 将resources\\文件夹复制到解决方案文件所在目录, 将 test 项目 设为启动项目, 开始执行. 测试库文件 另外新建解决方案, 新建工程, 将前面生成的库文件 1234567bin└─tinyxml2 └─x64-Debug-Dll tinyxml2.dll tinyxml2.lib tinyxml2.pdb 和头文件 1- tinyxml2.h 添加到工程中, 就可以调用 TinyXML-2 库了. 一个简单的用于测试的源码文件如下. 123456789101112131415161718192021222324252627282930313233343536373839//tinyxml2 测试代码#include &lt;iostream&gt;#include &quot;tinyxml2.h&quot;using namespace std;int main(){ static const char* xml = &quot;&lt;?xml version=\\&quot;1.0\\&quot; encoding=\\&quot;utf-8\\&quot; ?&gt;&quot; &quot;&lt;entries&gt;&quot; &quot;&lt;entry name=\\&quot;My First Post\\&quot; age=\\&quot;52\\&quot;&gt;I believe every human has a finite number of heartbeats. I don't intend to waste any of mine&lt;/entry&gt;&quot; &quot;&lt;entry name=\\&quot;The Second\\&quot; age=\\&quot;\\&quot;&gt;You know, being a test pilot isn't always the healthiest business in the world.&lt;/entry&gt;&quot; &quot;&lt;entry&gt;Entry&lt;/entry&gt;&quot; &quot;&lt;entry name=\\&quot;The Third\\&quot; secretdata=\\&quot;9809832\\&quot;&gt;We have an infinite amount to learn both from nature and from each other&lt;/entry&gt;&quot; &quot;&lt;entry name=\\&quot;Final Post...\\&quot; hidden=\\&quot;true\\&quot; age=\\&quot;3\\&quot;&gt;Across the sea of space, the stars are other suns.&lt;/entry&gt;&quot; &quot;&lt;/entries&gt;&quot;; tinyxml2::XMLDocument doc; doc.Parse(xml); tinyxml2::XMLHandle docHandle(&amp;doc); tinyxml2::XMLElement *entry = docHandle.FirstChildElement(&quot;entries&quot;).ToElement(); if (entry) { for (tinyxml2::XMLNode *node = entry-&gt;FirstChildElement(); node; node = node-&gt;NextSibling()) { tinyxml2::XMLElement *e = node-&gt;ToElement(); const char *name = e-&gt;Attribute(&quot;name&quot;); if (name) cout &lt;&lt; name &lt;&lt; &quot;: &quot;; cout &lt;&lt; e-&gt;GetText(); int true_age = e-&gt;IntAttribute(&quot;age&quot;) + 50; cout &lt;&lt; &quot; &quot; &lt;&lt; true_age &lt;&lt; endl; } } return 0;} 教程文档 在tinyxml2\\docs\\index.html中有关于该库的离线文档, 可以直接阅读. 文件读写12345678tinyxml2::XMLDocument doc;if (doc.LoadFile(&quot;input.xml&quot;) != 0){ cout &lt;&lt; &quot;load xml file failed&quot; &lt;&lt; endl; return;}doc.Print();doc.SaveFile(&quot;output.xml&quot;); 注意 官方 Github 仓库中不同版本的 tinyxml2 是使用不同版本的 Visual Studio 平台工具集构建的，若官方的版本与自己本地的版本不匹配可能报错，参考:error MSB8020: 无法找到 v142 的生成工具 - CSDN. 对于 VS2017+V141 toolset 使用 tinyxml2-7.0.1 就可以了, 不建议使用更高版本. tinyxml2相对于 tinyxml 重写了全部代码, 除非是为了维护老旧代码, 否则请直接使用tinyxml2. TinyXML-2既不依赖也不支持 STL, 通过返回const char* 来实现更高的内存利用效率. 参考 TinyXML-2 官网首页 leethomason/tinyxml2 - Github TinyXML2 入门教程 - CSDN C++ XML 库 TinyXML2 的基本使用 - CSDN Windows10 VS2017 C++ xml 解析（tinyxml2 库） - CSDN","link":"/blogs/tinyxml2/"},{"title":"Visual Studio 版本对应关系","text":"示例 Visual Studio 2022 v17.3.3 用于 x64 的 Microsoft (R) C/C++ 优化编译器 19.33.31629 版 版本对应关系 IDE 发布时间 工具集版本 MSC_VER MSVC++ Visual C++ 6.0 1998 V60 1200 MSVC++ 6.0 Visual Studio 2002 (version 7.0) 2002 V70 1300 MSVC++ 7.0 Visual Studio 2003 (version 7.1) 2003 V71 1310 MSVC++ 7.1 Visual Studio 2005 (version 8.0) 2005 V80 1400 MSVC++ 8.0 Visual Studio 2008 (version 9.0) 2008 V90 1500 MSVC++ 9.0 Visual Studio 2010 (version 10.0) 2010 V100 1600 MSVC++ 10.0 Visual Studio 2012 (version 11.0) 2012 V110 1700 MSVC++ 11.0 Visual Studio 2013 (version 12.0) 2013 V120 1800 MSVC++ 12.0 Visual Studio 2015 (version 14.0) 2015 V140 1900 MSVC++ 14.0 Visual Studio 2017 (versions 15.0 + 15.1 + 15.2) 2017 V141 1910 MSVC++ 14.1 Visual Studio 2017 (version 15.3) V141 1911 MSVC++ 14.11 Visual Studio 2017 (version 15.5) V141 1912 MSVC++ 14.12 Visual Studio 2017 (Version 15.6) V141 1913 MSVC++ 14.13 Visual Studio 2017 (version 15.7) V141 1914 MSVC++ 14.14 Visual Studio 2017 (version 15.8) V141 1915 MSVC++ 14.15 Visual Studio 2017 (version 15.9) V141 1916 MSVC++ 14.16 Visual Studio 2019 (version 16.0) 2019 V142 1920 MSVC++ 14.20 Visual Studio 2019 (version 16.1) V142 1921 MSVC++ 14.21 Visual Studio 2019 (version 16.2) V142 1922 MSVC++ 14.22 Visual Studio 2019 (version 16.3) V142 1923 MSVC++ 14.23 Visual Studio 2019 (version 16.4) V142 1924 MSVC++ 14.24 Visual Studio 2019 (version 16.5) V142 1925 MSVC++ 14.25 Visual Studio 2019 (version 16.6) V142 1926 MSVC++ 14.26 Visual Studio 2019 (version 16.7) V142 1927 MSVC++ 14.27 Visual Studio 2019 (versions 16.8 + 16.9) V142 1928 MSVC++ 14.28 Visual Studio 2019 (versions 16.10 + 16.11) V142 1929 MSVC++ 14.29 Visual Studio 2022 (version 17.0) 2022 V143 1930 MSVC++ 14.30 Visual Studio 2022 (version 17.1) V143 1931 MSVC++ 14.31 Visual Studio 2022 (version 17.2) V143 1932 MSVC++ 14.32 Visual Studio 2022 (version 17.3) V143 1933 MSVC++ 14.33 Visual Studio 2022 (version 17.4) V143 1934 MSVC++ 14.34 https://learn.microsoft.com/zh-cn/cpp/preprocessor/predefined-macros?view=msvc-170 https://en.wikipedia.org/wiki/Microsoft_Visual_C++","link":"/blogs/visualstudio/"},{"title":"WinSCP 局域网文件传输","text":"WinSCP 是一个 Windows 环境下使用的 SSH 的开源图形化 SFTP 客户端，同时支持 SCP 协议。它的主要功能是在本地与远程计算机间安全地复制文件，并且可以直接编辑文件。WinSCP 既可以管理远程 VPS 主机，也可以管理路由器，网络机顶盒等，只要远程设备能 ssh 连接即可。官网：https://winscp.net/eng/docs/lang:chs 被远程的 PC 下载 OpenSSH-Win64.zip，并解压到本地； 在 C:\\Program Files 文件夹中新建 OpenSSH 文件夹，并将（1）中解压的所有文件 copy 到 OpenSSH 文件夹中，此处都需要 Administrator 的权限 ；注：实际上这里 OpenSSH 的解压目录可以不放在 C 盘，就无需管理员权限 管理员权限运行 cmd，切换到： cd C:\\ProgramFiles\\OpenSSH 这个文件夹 , 然后 运行以下命令：powershell.exe -ExecutionPolicy Bypass -File install-sshd.ps1 添加规则：控制面板 -&gt; 系统和安全 -&gt;Windows 防火墙 -&gt; 高级设置 -&gt; 入栈规则 -&gt;”新建规则”：选择“端口 (O)”-&gt; “TCP”, 特定本地端口设置为 22 -&gt; “允许连接”-&gt; 默认全选，下一步 -&gt; 名称： sshd ，完成。 注：新建规则的名称一定要是 sshd 启动 OpenSSH 相关服务：“此电脑”上右击，选择“管理”，在“服务和应用程序”中选择“服务”，在右侧的所有服务中找到“OpenSSH Authentication Agent”和“OpenSSH SSH Server”，右击并在“属性”中将启动类型修改为“自动”，点击确定。注：除了将启动类型修改为自动之外，还需要启动一下这两个服务，否则就要重启电脑，让这两个服务开机自启动 本地 PC 安装 WinSCP: https://winscp.net/eng/download.php 打开 WinSCP:文件协议：SFTP主机名：就是被远程那台 PC 的 IP端口号：22用户名和密码：就是被远程那台 PC 的用户名和密码 点击“登录”。 注意事项 以上设置的两台 PC 是在同一网络内，比如校园网 (校园 VPN 可以轻松实现)。 参考： https://blog.csdn.net/qccz123456/article/details/80345999 关于“文件’’…\\putty.exe’没有找到”的错误解决方法： 下载： putty.exe ，并放到 WinSCP 安装位置中的 PuTTY 文件夹下 打开 WinSCP，选择“选项”-&gt;“选项”-&gt; 集成 -&gt; 应用程序，修改 PuTTY/Terminal 客户端路径为 putty.exe 所在的路径 -&gt; 确定。 参考 本文主要转载自: win10 使用 WinSCP 远程另一台 Win10 - 博客园 WinSCP 使用教程 - CSDN","link":"/blogs/winscp/"},{"title":"VS2017 输出 dll、lib 文件","text":"为了更好地保护程序源码, 同时开放合适的接口供用户调用进行二次开发,在项目开发的时候应当遵循接口与实现分离的设计模式, 最终提供给用户的是 .dll 和.lib库文件以及相应的 .h/.hpp 头文件, 这些文件辅以必要的示例代码、文档、工具等组成一个完整的 SDK. 软件开发工具包 (Software Development Kit, SDK) 一般都是一些软件工程师为特定的软件包、软件框架、硬件平台、操作系统等建立应用软件时的开发工具的集合。软件开发工具广义上指辅助开发某一类软件的相关文档、范例和工具的集合。——《百度百科：软件开发工具包》 本文档记录在 win10 x64 系统上通过 VS2017 为C++ 项目 封装 SDK 的相关操作. 文件组织结构1234567- SolutionDir(解决方案文件夹) - solution.sln(解决方案文件) - ProjectDir(项目文件夹) - project.vcxproj - src(源文件夹) - include(头文件夹) - TestDir(测试项目文件夹) VS 生成库文件 简单地要生成 .dll/.lib 库文件只需要在项目属性页中修改配置类型即可, 一般的项目设置为 应用程序(exe), 若要输出动态库或静态库只需修改该项设置即可, 如图. 属性配置 为了项目管理上的简洁、高效, 这里建立专门的配置用于生成库文件, 该配置与项目运行的配置解耦, 即可通过简单地切换不同配置来选择生成 库文件 (.dll/.lib) 还是生成 可执行文件(.exe). 新建解决方案配置: 生成 -&gt; 配置管理器 -&gt; 活动解决方案配置 -&gt; 新建 -&gt; 命名:Debug-Dll-&gt; 从此处复制设置:Debug-&gt; 勾选: 创建新的项目配置 -&gt; 确定. 一个解决方案配置可以设置相应的项目配置, 然后在切换解决方案配置时自动生效. 对应的项目配置可以作如下更改. 修改输出目录 12$(SolutionDir)\\SDK\\$(Platform)\\Debug\\DLL\\ $(SolutionDir)\\SDK\\$(Platform)\\Debug\\LIB\\ 分别生成如下文件: 12sdk_sln\\\\SDK\\x64\\Debug\\DLL\\sdk_proj.dll sdk_sln\\\\SDK\\x64\\Debug\\LIB\\sdk_proj.lib Notice 配置生成库文件后, 只能点击 生成 -&gt; 生成解决方案, 或者右键项目并生成该项目, 但不能运行也不能调试, 因为库文件不能直接运行, 只能被其他可执行文件调用. 常见的报错信息是: 12无法启动程序“*.dll”. *.dll 不是有效的 Win32 应用程序。 发布 SDK 的时候需要附上头文件(include), 但可以不用提供源文件(src) Reference visual studio lib 和 dll 的编译生成与调用 - 知乎专栏 VS2017 生成一个简单的 DLL 文件 和 LIB 文件——C 语言 lib 和 dll 的区别、生成以及使用详解 C++ “接口”与“实现”分离的两种方法 C++ 封装 SDK 的一种方法(接口与实现分离)","link":"/blogs/vs_export_dll_lib/"},{"title":"在 Qt 界面上显示点云","text":"要在 Qt 的 GUI 界面上显示点云, 需要首先放置一个 QVTKWidget 控件, 然后通过 C++ 代码往该控件上显示点云.但一般直接下载安装的 PCL 预编译的 3rdParty/VTK 没有该控件, 需要自己下载源码重新编译. Visual Studio 2017 Qt 5.12.10 PCL 1.8.1 VTK 8.0.0 下载编译 VTK下载的 VTK 版本必须和原来 PCL 预编译的版本一致. 首先将 PCL 自带的 VTK 包 %PCL_ROOT%/3rdParty/VTK 重命名为 %PCL_ROOT%/3rdParty/VTK-bak 作为备份; 下载 vtk-v8.0.0 - gitlab 的源码并解压到...unpack_path/vtk-v8.0.0; 打开 CMake-Gui, 设置 Where is the source code: ...unpack_path/vtk-v8.0.0 Where to build the binaries: ...unpack_path/vtk-v8.0.0/build; 点击Add Entry, 添加CMAKE_DEBUG_POSTFIX, 类型为STRING, 其值设置为-gd. 这样 debug 模式编译出的库文件名会带一个-gd, 以便与 Release 模式的库文件进行区分; 点击Configure: Visual studio 15 2017 Win64, x64. 上一步 Configure 完成后, 更改 CMake 的配置: BUILD_SHARED_LIBS BUILD_TESTING BUILD_EXAMPLES VTK_GROUP_QT VTK_RENDERING_BACKEND: OpenGL CMAKE_INSTALL_PREFIX: %PCL_ROOT%/3rdParty/VTK. 点击 configure, 若出现错误, 将VTK_QT_VERSION 设为 5, 再 Configure. 修改如下配置后继续 Configure: QT_QMAKE_EXECUTABLE: D:/Qt/Qt5.12.10/5.12.10/msvc2017_64/bin/qmake.exe VTK_QT_VERSION: 5 Qt5_DIR: D:/Qt/Qt5.12.10/5.12.10/msvc2017_64/lib/cmake/Qt5 Qt5Core_DIR: D:/Qt/Qt5.12.10/5.12.10/msvc2017_64/lib/cmake/Qt5Core Qt5Gui_DIR: D:/Qt/Qt5.12.10/5.12.10/msvc2017_64/lib/cmake/Qt5Gui Qt5OpenGL_DIR: D:/Qt/Qt5.12.10/5.12.10/msvc2017_64/lib/cmake/Qt5OpenGL Qt5Sql_DIR: D:/Qt/Qt5.12.10/5.12.10/msvc2017_64/lib/cmake/Qt5Sql Qt5UiPlugin_DIR: D:/Qt/Qt5.12.10/5.12.10/msvc2017_64/lib/cmake/Qt5UiPlugin Qt5Widgets_DIR: D:/Qt/Qt5.12.10/5.12.10/msvc2017_64/lib/cmake/Qt5Widgets 如无错误(可能有 CMake Deprecation Warning, 不重要的话就不理它), 点击Generate, 然后Open Project, 通过 VS 打开. 在 VS 中点击 生成 -&gt; 批生成: 勾选 ALL_BUILD,Debug,x64,ALL_BUILD,Release,x64,INSTALL,Debug,x64,INSTALL,Release,x64, 点击生成, 等待… 在 Powershell 查看之前备份的预编译的 VTK 与新生成的 VTK 库文件: 12PS D:\\PCL\\3rdParty&gt; tree /f /a VTK &gt;&gt; VTK.txtPS D:\\PCL\\3rdParty&gt; tree /f /a VTK-bak &gt;&gt; VTK-bak.txt 用在线文本比对网站 https://www.diffchecker.com/diff 对比分析两个库文件, 发现自己编译的库比安装 PCL 时预编译的库多了大量 VTK/bin/*.dll, 以及部分头文件(.h) 和静态库文件(.lib). 因此在配置 PCL 的时候要注意把 VTK 配置好. 123456789vtkGUISupportQtOpenGL-8.0.libvtkGUISupportQtSQL-8.0.libvtkGUISupportQt-8.0.libvtkRenderingGL2PS-8.0.libvtkViewsQt-8.0.libvtkRenderingVolumeOpenGL-8.0.libvtkRenderingQt-8.0.libvtkRenderingOpenGL-8.0.libvtkRenderingLIC-8.0.lib 把编译得到的 D:\\PCL\\3rdParty\\VTK\\plugins\\designer\\QVTKWidgetPlugin.dll 复制到 Qt 安装路径下D:\\Qt\\Qt5.12.10\\5.12.10\\msvc2017_64\\plugins\\designer\\QVTKWidgetPlugin.dll, 注意这里只要 Release 版本即可, 不要放置 debug 版本的 dll. 例程 Qt Designer 打开 ui 文件, 在 ui 界面拖拽放置一个 qvtkWidget 控件, 并在菜单工具栏添加 File-&gt;Open. 编译完成后可以通过 Open 打开点云*.pcd 文件并在界面上显示. 例程: https://github.com/siyouluo/Storage/tree/master/vs_qt_pcl 例程打包下载: https://github.com/siyouluo/Storage/releases/download/v1.0.0/vs_qt_pcl.zip 123&gt; mkdir build&gt; cd build&gt; cmake .. -A x64 -T v141 -DQt5_DIR=D:/ProgramFiles/Qt5.12.10/5.12.10/msvc2017_64/lib/cmake/Qt5 Refer 主要参考: Qt+PCL+VS 实现点云 Gui 界面显示 辅助参考: VTK 学习（一）Window 10+ qt 5.14.2 + vtk8.2.0 安装配置过程（Cmake）","link":"/blogs/vs_qt_pcl/"},{"title":"书签","text":"Linux 命令大全搜索工具，内容包含 Linux 命令手册、详解、学习、搜集。 Gitee 极速下载 现代 C++ 教程：高速上手 C++ 11/14/17/20 CMake 菜谱（CMake Cookbook 中文版） cpp 中文参考手册 | Github C++ 中文参考手册 https://cplusplus.com/ C++ 学习 chengxumiaodaren/cpp-learning | Github 521xueweihan/HelloGitHub - 分享 GitHub 上有趣、入门级的开源项目 开源中国 OSCHINA Microsoft’s C++ Standard Library | Github Microsoft 技术文档 Microsoft C++、C 和汇编程序文档 在线编程 C++ shell 在线编程 Coliru 图说设计模式 Eigen 库 https://eigen.tuxfamily.org https://gitlab.com/libeigen/eigen 四元数与三维旋转 Krasjet | Github amusi/Amusi-Note LTSLAM: learn slam step by step - Github","link":"/blogs/mark/"},{"title":"Git&#x2F;Github 笔记","text":"各类操作技巧整理 全局配置（操作一次即可）12$ git config --global user.email &quot;you@example.com&quot; # 添加全局配置$ git config --global user.name &quot;Your Name&quot; 1$ ssh-keygen -t rsa -C &quot;you@example.com&quot; # 生成 ssh 密钥对（公钥和私钥） 1234567891011121314151617181920Generating public/private rsa key pair.Enter file in which to save the key (/home/lsy/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/lsy/.ssh/id_rsa.Your public key has been saved in /home/lsy/.ssh/id_rsa.pub.The key fingerprint is:SHA256:fovO3yeP8R4GoJLq6R8r6TuyE1W8cZY7NDPjLsTnpRo siyouluo@qq.comThe key's randomart image is:+---[RSA 2048]----+| . . || + X || o B *. || . +.=... || . .o+S+ . || . .Eo+ . || ....+. . . o || o.+..+ o o.=.. || .**=o.+.o o=+ |+----[SHA256]-----+ 12$ cat ~/.ssh/id_rsa.pub # 在 GitHub 网站上个人设置里添加如下公钥ssh-rsa AAAAB3 ******** 局部配置（对单个仓库的操作）1234567891011121314$ git init # 初始化仓库 $ git remote add origin &lt;remote url&gt; # 将本地仓库与远程仓库进行关联（对每个仓库操作一次即可）$ git add &lt;filename&gt; # 暂存文件$ git commit -m &quot;commit message&quot; # 提交到本地仓库$ git branch -M main$ git push -u origin main # 推送到远程仓库 对象计数中: 3, 完成.Delta compression using up to 16 threads.压缩对象中: 100% (2/2), 完成.写入对象中: 100% (3/3), 3.55 KiB | 3.55 MiB/s, 完成.Total 3 (delta 0), reused 0 (delta 0)To &lt;remote url&gt; * [new branch] main -&gt; main分支 'main' 设置为跟踪来自 'origin' 的远程分支 'main'。 案例 案例一: 压缩 commit 历史 如果在本地修改文件后，进行了多次提交，但实际上每个提交只是小修，算不上一个完整的版本，我希望把多个提交合并为一个提交（即删除中间若干步骤的提交历史），但保留最后版本的文件 123456789101112lsy@ubuntu1804:~$ git log --oneline516f335 第二版6004a9a 小修 3c53a436 小修 2178d8c9 小修 17f57867 第一版lsy@ubuntu1804:~$ git reset --soft 7f57867 # 把提交历史回退到第一版，但本地文件仍然是第二版（中间三次小修都被合并到第二版的修改）lsy@ubuntu1804:~$ git log --oneline7f57867 第一版lsy@ubuntu1804:~$ git commit -m &quot; 第二版 &quot; # 重新提交第二版，中间若干次小修的文件内容被合并到最后一次提交lsy@ubuntu1804:~$ git push origin HEAD --force # 如果中间的提交曾 push 到了 GitHub, 那么执行该命令把本地记录强行同步到 GitHub（即把 GitHub 上的小修版本的提交记录也删除） 注意: 如果是多用户同时维护该代码库，那么本地操作尽量不要影响其他人的工作. 所以请谨慎提交! 案例二: 从文件中读取内容作为 commit message首先编写 commit_msg.md 文件作为 commit message，然后在 commit 时使用 -F 来指定该文件. 1$ git commit -F commit_msg.md 案例三：从远端拉取仓库并保持关联1git clone git@github.com:&lt;...&gt;/&lt;...&gt;.git 案例四 修改本地分支名，跟踪远程分支1234git branch -m main &lt;BRANCH&gt; # 将 main 分支更名为 &lt;BRANCH&gt;git fetch origingit branch -u origin/&lt;BRANCH&gt; &lt;BRANCH&gt; # 让本地分支 &lt;BRANCH&gt; 跟踪远程分支 origin/&lt;BRANCH&gt;, 二者无需同名git remote set-head origin -a 案例五 本地创建仓库推送到远端1234567echo &quot;# tools&quot; &gt;&gt; README.mdgit initgit add README.mdgit commit -m &quot;first commit&quot;git branch -M main # 这会将当前分支重命名为 maingit remote add origin git@github.com:siyouluo/tools.gitgit push -u origin main 案例六 推送本地仓库到远端123git remote add origin git@github.com:siyouluo/tools.gitgit branch -M maingit push -u origin main 案例七 权限问题 Windows 系统上安装了Git+TortoiseGit，生成ssh key 并添加到 Github 后无效，在克隆仓库时报错:Please make sure you have the correct access rights and the repository exists 解决办法: 删除 C:\\Users\\SiyouLuo\\.ssh 文件夹下的全部文件; 在 Git Bash 中设置用户名 / 邮箱: 设置用户名: git config --global user.name &quot;Luo Siyou&quot; 设置用户名邮箱: git config --global user.email &quot;siyouluo@qq.com&quot; 查看设置: git config --list 生成密钥对: ssh-keygen -t rsa -C &quot;siyouluo@qq.com&quot;, 密钥直接存放在 C:\\Users\\SiyouLuo\\.ssh 文件夹下即可. 将公钥添加到 Github 中的 SSH keys 中. 然后在 Terminal/Git Bash/TortoiseGit 中都可以克隆仓库了.(注意，私有库需使用 git@github.com:xxx 类型的 url ) 参考 Git Cheat Sheet 中文版 - Github 用工具思路来规范化 git commit message Angular Git Commit Guidelines git commit 中输入 message 的几种方式","link":"/blogs/git/"}],"tags":[{"name":"resume","slug":"resume","link":"/tags/resume/"},{"name":"vtk","slug":"vtk","link":"/tags/vtk/"},{"name":"ceres","slug":"ceres","link":"/tags/ceres/"},{"name":"clash","slug":"clash","link":"/tags/clash/"},{"name":"cuda","slug":"cuda","link":"/tags/cuda/"},{"name":"g2o","slug":"g2o","link":"/tags/g2o/"},{"name":"cmake","slug":"cmake","link":"/tags/cmake/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"icarus","slug":"icarus","link":"/tags/icarus/"},{"name":"darknet","slug":"darknet","link":"/tags/darknet/"},{"name":"yolo","slug":"yolo","link":"/tags/yolo/"},{"name":"levmar","slug":"levmar","link":"/tags/levmar/"},{"name":"LM优化","slug":"LM优化","link":"/tags/LM%E4%BC%98%E5%8C%96/"},{"name":"opencv","slug":"opencv","link":"/tags/opencv/"},{"name":"license","slug":"license","link":"/tags/license/"},{"name":"onnx","slug":"onnx","link":"/tags/onnx/"},{"name":"qt","slug":"qt","link":"/tags/qt/"},{"name":"gui","slug":"gui","link":"/tags/gui/"},{"name":"pcl","slug":"pcl","link":"/tags/pcl/"},{"name":"libtorch","slug":"libtorch","link":"/tags/libtorch/"},{"name":"Umeyama","slug":"Umeyama","link":"/tags/Umeyama/"},{"name":"Sim(3)","slug":"Sim-3","link":"/tags/Sim-3/"},{"name":"xml","slug":"xml","link":"/tags/xml/"},{"name":"tinyxml2","slug":"tinyxml2","link":"/tags/tinyxml2/"},{"name":"msvc","slug":"msvc","link":"/tags/msvc/"},{"name":"vs","slug":"vs","link":"/tags/vs/"},{"name":"WinSCP","slug":"WinSCP","link":"/tags/WinSCP/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"dll","slug":"dll","link":"/tags/dll/"},{"name":"lib","slug":"lib","link":"/tags/lib/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"github","slug":"github","link":"/tags/github/"}],"categories":[{"name":"库","slug":"库","link":"/categories/%E5%BA%93/"},{"name":"工具","slug":"工具","link":"/categories/%E5%B7%A5%E5%85%B7/"},{"name":"优化库","slug":"库/优化库","link":"/categories/%E5%BA%93/%E4%BC%98%E5%8C%96%E5%BA%93/"},{"name":"深度学习","slug":"深度学习","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"}],"pages":[]}